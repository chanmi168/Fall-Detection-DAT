{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stage2_ArchDesignStudio.ipynb","provenance":[],"collapsed_sections":["amhwi5lZJA5V"],"authorship_tag":"ABX9TyOn/a8GYIoFJV7tUKKo5tXT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nswy3ke-TUyA","colab_type":"text"},"source":["# Import packages and get authenticated"]},{"cell_type":"code","metadata":{"id":"dR0gs1Ya0xmy","colab_type":"code","outputId":"d190f2b4-8ad6-43cd-fb38-afc2745adead","executionInfo":{"status":"ok","timestamp":1585579964466,"user_tz":-480,"elapsed":2856,"user":{"displayName":"MICHAEL CHAN","photoUrl":"","userId":"10621351606155040584"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DD6EM010PDWn","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","import pandas as pd\n","pd.set_option('display.max_columns', 500)\n","from tqdm import tqdm_notebook as tqdm\n","from IPython.display import display\n","import os\n","import sys\n","sys.path.append('/content/drive/My Drive/中研院/repo/')\n","\n","from utilities import *\n","from models import *\n","from dataset_util import *\n","from training_util import *\n","from eval_util import *\n","\n","import time\n","import datetime\n","from datetime import datetime\n","import json\n","\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.rc( 'savefig', facecolor = 'white' )\n","\n","from sklearn.decomposition import PCA\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwW5pmvqVMhg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"amhwi5lZJA5V","colab_type":"text"},"source":["# functions developed"]},{"cell_type":"code","metadata":{"id":"jb6CCtPOfoxO","colab_type":"code","colab":{}},"source":["# # validated, the implementation is correct\n","# def contextExapansion(x, win_size, win_overlap, step_n):\n","#   # size of x: torch.Size([batch_size, channel_n, input_size])\n","#   # size of x_seq: torch.Size([step_n, batch_size, channel_n, win_size])\n","\n","#   batch_size = x.size()[0]\n","#   channel_n = x.size()[1]\n","#   input_size = x.size()[2]\n","\n","#   x_seq = torch.ones((step_n, batch_size, channel_n, win_size), dtype=torch.double)\n","#   timesteps = np.asarray(range(win_size))\n","#   for i in range(step_n):\n","#     indices = i*win_size*win_overlap+timesteps\n","#     x_seq[i, :, :, :] = x[:,:,indices]\n","#   return x_seq\n","\n","# def labelExapansion(y, step_n):\n","#   # size of y: torch.Size([batch_size, 1])\n","#   # size of y_seq: torch.Size([batch_size, step_n])\n","\n","#   batch_size = y.size()[0]\n","\n","#   y_seq = torch.ones((step_n, batch_size), dtype=torch.double)\n","#   timesteps = np.asarray(range(win_size))\n","#   for i in range(step_n):\n","#     y_seq[i, :] = y\n","#   return y_seq\n","\n","# win_size=22\n","# win_overlap=0.5\n","# step_n = 5\n","# x = torch.zeros((16,3,66), dtype=torch.double)\n","# y = torch.zeros((16,), dtype=torch.double)\n","# x_seq = contextExapansion(x, win_size, win_overlap, step_n)\n","# y_seq = labelExapansion(y, step_n)\n","# print(x.size(), x_seq.size(), y_seq.size(), y.size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8FqrD37E4tI","colab_type":"code","colab":{}},"source":["# # validated, the implementation is correct\n","# def contextExapansion_v2(x, win_size, win_stride, step_n):\n","#   # size of x: torch.Size([batch_size, channel_n, input_size])\n","#   # size of x_seq: torch.Size([step_n, batch_size, channel_n, win_size])\n","\n","#   batch_size = x.size()[0]\n","#   channel_n = x.size()[1]\n","#   input_size = x.size()[2]\n","\n","#   x_seq = torch.ones((step_n, batch_size, channel_n, win_size), dtype=torch.double)\n","#   timesteps = np.asarray(range(win_size))\n","#   for i in range(step_n):\n","#     indices = i*win_stride+timesteps\n","#     x_seq[i, :, :, :] = x[:,:,indices]\n","#   return x_seq\n","\n","# def labelExapansion(y, step_n):\n","#   # size of y: torch.Size([batch_size, 1])\n","#   # size of y_seq: torch.Size([batch_size, step_n])\n","\n","#   batch_size = y.size()[0]\n","\n","#   y_seq = torch.ones((step_n, batch_size), dtype=torch.double)\n","#   timesteps = np.asarray(range(win_size))\n","#   for i in range(step_n):\n","#     y_seq[i, :] = y\n","#   return y_seq\n","\n","# win_size=24\n","# win_stride=7\n","# step_n = 7\n","# x = torch.zeros((16,3,66), dtype=torch.double)\n","# y = torch.zeros((16,), dtype=torch.double)\n","# x_seq = contextExapansion_v2(x, win_size, win_stride, step_n)\n","# y_seq = labelExapansion(y, step_n)\n","# print(x.size(), x_seq.size(), y_seq.size(), y.size())\n","# # print(x_seq)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOWRU-84_8_y","colab_type":"code","colab":{}},"source":["\n","# # fall classifier neural network (fc layers)\n","# class ClassClassifier_lstm(nn.Module):\n","#   def __init__(self, num_classes=2, hiddenDim=16, input_dim=50, steps_n=5):\n","#       super(ClassClassifier_lstm, self).__init__()\n","#       self.lstm = nn.LSTM(         # if use nn.RNN(), it hardly learns\n","#         input_size=input_dim,\n","#         hidden_size=hiddenDim,         # rnn hidden unit\n","#         num_layers=2,           # number of rnn layer\n","#         batch_first=False,       # input & output will has not batch size as 1st dimension. e.g. (time_step, time_step, input_size)\n","#         bidirectional=True,\n","#       )\n","#       self.fc1 = nn.Linear(steps_n*hiddenDim*2, 10)\n","#       self.fc2 = nn.Linear(10, num_classes)\n","#       self.relu = nn.ReLU(inplace=False)\n","#       self.fc3 = nn.Linear(steps_n*hiddenDim*2, num_classes)\n","\n","#       # self.lsm = nn.LogSoftmax(dim=1)\n","      \n","#   def forward(self, x):\n","#     debug = False\n","#     # Input: (seq_len, batch, input_size)\n","#     # Output: (seq_len, batch, num_directions * hidden_size)\n","#     out1_seq, (h_n, h_c) = self.lstm(x)\n","#     out1_seq = out1_seq.transpose(0,1)\n","#     out1_seq = out1_seq.reshape(out1_seq.size()[0],-1)\n","\n","#     out2 = self.relu(self.fc1(out1_seq))\n","#     out3 = self.fc2(out2)\n","#     # out3 = self.fc3(out1_seq)\n","\n","#     if debug:\n","#       print('ClassClassifier_lstm')\n","#       print('out1_seq size:', out1_seq.size())\n","#       print('out2 size:', out2.size())\n","#       print('out3 size:', out3.size())\n","\n","#     return out3\n","\n","# # domain classifier neural network (fc layers)\n","# class DomainClassifier_lstm(nn.Module):\n","#   def __init__(self, num_classes=2, hiddenDim=16, input_dim=50, steps_n=5):\n","#       super(DomainClassifier_lstm, self).__init__()\n","#       self.lstm = nn.LSTM(         # if use nn.RNN(), it hardly learns\n","#         input_size=input_dim,\n","#         hidden_size=hiddenDim,         # rnn hidden unit\n","#         num_layers=2,           # number of rnn layer\n","#         batch_first=False,       # input & output will has not batch size as 1st dimension. e.g. (time_step, time_step, input_size)\n","#         bidirectional=True,\n","#       )\n","#       self.fc1 = nn.Linear(steps_n*hiddenDim*2, 10)\n","#       self.fc2 = nn.Linear(10, num_classes)\n","#       self.relu = nn.ReLU(inplace=False)\n","#       # self.lsm = nn.LogSoftmax(dim=1)\n","      \n","#   def forward(self, x, constant):\n","#     debug = False\n","\n","#     x = GradReverse.grad_reverse(x.float(), constant)\n","\n","#     out1_seq, (h_n, h_c) = self.lstm(x)\n","#     out1_seq = out1_seq.transpose(0,1)\n","#     out1_seq = out1_seq.reshape(out1_seq.size()[0],-1)\n","#     # print('out1_seq', out1_seq)\n","\n","#     out2 = self.relu(self.fc1(out1_seq))\n","#     out3 = self.fc2(out2)\n","#     # out3 = self.lsm(self.fc2(out2))\n","#     # print('out3', out3)\n","\n","#     if debug:\n","#       print('DomainClassifier_lstm')\n","#       print('out1_seq size:', out1_seq.size())\n","#       print('out2 size:', out2.size())\n","#       print('out3 size:', out3.size())\n","      \n","#     return out3\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tVO5_IcnVys","colab_type":"code","colab":{}},"source":["# # Convolutional neural network (two convolutional layers)\n","# class CnnLstm(nn.Module):\n","#   def __init__(self, device, class_N=2, channel_n=16, dropout=0.5, hiddenDim_f=5, hiddenDim_y=5, hiddenDim_d=5, win_size=22, win_overlap=0.5, step_n=5):\n","#       super(CnnLstm, self).__init__()\n","#       self.win_size = win_size\n","#       self.win_overlap = win_overlap\n","#       self.step_n = step_n\n","#       self.feature_extractor = FeatureExtractor(input_dim=win_size, channel_n=channel_n).to(device).float()\n","\n","#       cnn_layer1_dim = (win_size+2*2-1*(3-1)-1)+1\n","#       pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n","#       cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n","#       pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n","#       self.feature_out_dim = int(pool_layer2_dim*channel_n*2)\n","\n","#       # lstm_out_seq size: torch.Size([step_n, batch_size, hiddenDim*2])\n","#       self.lstm = nn.LSTM(         # if use nn.RNN(), it hardly learns\n","#         input_size=self.feature_out_dim,\n","#         hidden_size=hiddenDim_f,         # rnn hidden unit\n","#         num_layers=2,           # number of rnn layer\n","#         batch_first=False,       # input & output will has not batch size as 1st dimension. e.g. (time_step, batch, input_size)\n","#         bidirectional=True,\n","#         dropout=dropout\n","#       ).to(device).float()\n","\n","\n","#       # self.class_classifier = ClassClassifier_lstm(num_classes=2, hiddenDim=hiddenDim_y, input_dim=hiddenDim_f*2, steps_n=step_n).to(device).float()\n","#       # self.domain_classifier = DomainClassifier_lstm(num_classes=2, hiddenDim=hiddenDim_d, input_dim=hiddenDim_f*2, steps_n=step_n).to(device).float()\n","#       self.class_classifier = ClassClassifier_lstm(num_classes=2, hiddenDim=hiddenDim_y, input_dim=self.feature_out_dim, steps_n=step_n).to(device).float()\n","#       self.domain_classifier = DomainClassifier_lstm(num_classes=2, hiddenDim=hiddenDim_d, input_dim=self.feature_out_dim, steps_n=step_n).to(device).float()\n","      \n","\n","      \n","#   def forward(self, x):\n","#     # size of x: torch.Size([batch_size, channel_n, input_size])\n","#     # size of x_seq: torch.Size([step_n, batch_size, channel_n, win_size])\n","#     debug = False\n","#     x_seq = contextExapansion(x, self.win_size, self.win_overlap, self.step_n).to(device).float()\n","#     # aaa = x_seq[0,0,:,:].cpu().numpy().T\n","#     # bbb = x_seq[1,0,:,:].cpu().numpy().T\n","\n","#     # for i in range(5):\n","#     #   plt.subplot(5, 1, i+1)\n","#     #   plt.plot(x_seq[i,0,:,:].cpu().numpy().T)\n","#     #   plt.title('t={}'.format(i))\n","#     #   # plt.ylabel('t=0')\n","#     # plt.show()\n","\n","#     feature_out_seq = torch.ones((self.step_n, x.size()[0], self.feature_out_dim), dtype=torch.float).to(device)\n","\n","#     for t in range(self.step_n):\n","#       # Input: (N, C_in, L_in)\n","#       # Output: (N, L_out=self.feature_out_dim*C_out)\n","#       feature_out_seq[t,:,:] = self.feature_extractor(x_seq[t,:,:,:])\n","    \n","#     lstm_out_seq = feature_out_seq\n","#     # Input: (seq_len, batch, input_size)\n","#     # Output: (seq_len, batch, num_directions * hidden_size)\n","#     # lstm_out_seq, (h_n, h_c) = self.lstm(feature_out_seq, None)\n","\n","#     # print(lstm_out_seq)\n","#     # sys.exit()\n","#     class_output = self.class_classifier(lstm_out_seq)\n","#     domain_output = self.domain_classifier(lstm_out_seq, 1)\n","\n","#     if debug:\n","#       print('CnnLstm')\n","#       print('x size:', x.size())\n","#       print('x_seq size:', x_seq.size())\n","#       print('feature_out_seq size:', feature_out_seq.size())\n","\n","#       print('lstm_out_seq size:', lstm_out_seq.size())\n","#       print('class_output size:', class_output.size())\n","#       print('domain_output size:', domain_output.size())\n","\n","#     lstm_out_seq = lstm_out_seq.transpose(0,1)\n","#     lstm_out_seq = lstm_out_seq.reshape(lstm_out_seq.size()[0],-1)\n","\n","#     # print('lstm_out_seq', lstm_out_seq)\n","#     return lstm_out_seq, class_output, domain_output\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJn8YBlofouQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpitQXMDlURn","colab_type":"code","colab":{}},"source":["# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","# # device = torch.device('cpu')\n","# print('show GPU device name:', torch.cuda.get_device_name(0))\n","# model_1 = FeatureExtractor(input_dim=66).to(device).float()\n","\n","# # test_input = torch.randn((8, 3, 66), dtype=torch.double)\n","\n","# # test_input = test_input.to(device)\n","#     # labels = labels.to(device).long()\n","\n","# feature_out = model_1(test_input)\n","# print('show model_1 output size:', feature_out.size())\n","\n","# feature_out.data.detach().cpu().numpy()\n","\n","# feature_out_dim =  feature_out.size()[1]\n","# model_2 = ClassClassifier(num_classes=2, input_dim=feature_out_dim).to(device).float()\n","# model_3 = DomainClassifier(num_classes=2, input_dim=feature_out_dim).to(device).float()\n","\n","# model_2_out = model_2(feature_out)\n","# print('show model_2 output size:', model_2_out.size())\n","\n","# model_3_out = model_3(feature_out, 1)\n","# print('show model_3 output size:', model_3_out.size())\n","\n","# model_4 = CascadedModel(model_1, model_2)\n","# # model_4 = nn.Sequential(model_1, model_2)\n","\n","# print('model_4 output size', model_4(test_input).size())\n","\n","# dann = DannModel(device, class_N=2, domain_N=2, channel_n=5, input_dim=66).to(device).float()\n","# feature_out, class_output, domain_output = dann(test_input)\n","# print('dann output size', feature_out.size(), class_output.size(), domain_output.size())\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ah2MW37CCWtR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1avdeEhyCWrS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mNIrQ3McJFn0","colab_type":"text"},"source":["\n","# testing performance"]},{"cell_type":"code","metadata":{"id":"9QdNcq3kZLHg","colab_type":"code","outputId":"115224d3-e5d9-4b95-ae78-a3f7a91083bf","executionInfo":{"status":"ok","timestamp":1585579968792,"user_tz":-480,"elapsed":614,"user":{"displayName":"MICHAEL CHAN","photoUrl":"","userId":"10621351606155040584"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["win_size = 18\n","\n","cnn_layer1_dim = (win_size+2*2-1*(3-1)-1)+1\n","pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n","cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n","pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n","\n","print('win_size, cnn_layer1_dim, pool_layer1_dim, cnn_layer2_dim, pool_layer2_dim size:', win_size, cnn_layer1_dim, pool_layer1_dim, cnn_layer2_dim, pool_layer2_dim)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["win_size, cnn_layer1_dim, pool_layer1_dim, cnn_layer2_dim, pool_layer2_dim size: 18 20 10.0 12.0 6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8lu43fzrNDrN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":683},"outputId":"505bfe76-4d99-4b9f-fed1-e04794627587","executionInfo":{"status":"ok","timestamp":1585579978388,"user_tz":-480,"elapsed":1758,"user":{"displayName":"MICHAEL CHAN","photoUrl":"","userId":"10621351606155040584"}}},"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","# print('show GPU device name:', torch.cuda.get_device_name(0))\n","\n","batch_size = 253\n","axis_dim = 3\n","input_size = 66\n","test_input = torch.randn((batch_size, axis_dim, input_size), dtype=torch.double).to(device)\n","print('test_input size:', test_input.size())\n","\n","channel_n = 4\n","# model = CnnLstm(device, class_N=2, channel_n=channel_n, dropout=0.5, hiddenDim_f=5, hiddenDim_y=5, hiddenDim_d=5, win_size=22, win_stride=11, step_n=5).to(device)\n","model = CnnLstm(device, class_N=2, channel_n=channel_n, dropout=0.5, hiddenDim_f=5, hiddenDim_y=5, hiddenDim_d=5, win_size=18, win_stride=6, step_n=9).to(device)\n","print(model)\n","lstm_out_seq, class_output, domain_output = model(test_input)\n","\n","dann = DannModel(device, class_N=2, domain_N=2, channel_n=channel_n, input_dim=66).to(device).float()\n","\n","print(lstm_out_seq.size())\n","print('show lstm_out_seq, class_output, domain_output size:', lstm_out_seq.size(), class_output.size(), domain_output.size())\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["cpu\n","test_input size: torch.Size([253, 3, 66])\n","FeatureExtractor_total_params: 168\n","CnnLstm_total_params: 28794\n","CnnLstm(\n","  (feature_extractor): FeatureExtractor(\n","    (layer1): Sequential(\n","      (0): Conv1d(3, 4, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","    (layer2): Sequential(\n","      (0): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","  )\n","  (class_classifier): ClassClassifier_lstm(\n","    (lstm): LSTM(48, 5, num_layers=2, dropout=0.5, bidirectional=True)\n","    (fc1): Linear(in_features=90, out_features=10, bias=True)\n","    (fc2): Linear(in_features=10, out_features=2, bias=True)\n","    (relu): ReLU()\n","    (fc3): Linear(in_features=90, out_features=2, bias=True)\n","  )\n","  (domain_classifier): DomainClassifier_lstm(\n","    (lstm): LSTM(48, 5, num_layers=2, dropout=0.5, bidirectional=True)\n","    (fc4): Linear(in_features=432, out_features=50, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","    (relu): ReLU()\n","    (fc5): Linear(in_features=50, out_features=2, bias=True)\n","  )\n",")\n","FeatureExtractor_total_params: 168\n","DannModel_total_params: 748\n","torch.Size([253, 432])\n","show lstm_out_seq, class_output, domain_output size: torch.Size([253, 432]) torch.Size([253, 2]) torch.Size([253, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MjvZC1mDEOYz","colab_type":"code","outputId":"a61459bf-12cd-4f06-dcb3-e5cdfe59e400","executionInfo":{"status":"ok","timestamp":1585582687878,"user_tz":-480,"elapsed":206667,"user":{"displayName":"MICHAEL CHAN","photoUrl":"","userId":"10621351606155040584"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1SMbbKoHXSgADadbJZEbaPjVutZfgpfpz"}},"source":["# optimal\n","\n","# tasks_list = [('UMAFall_waist', 'UPFall_belt')]\n","# tasks_list = [('UPFall_belt', 'UMAFall_waist')]\n","# tasks_list = [('UPFall_belt', 'UMAFall_waist')]\n","tasks_list = [('UMAFall_ankle', 'UPFall_ankle')]\n","# tasks_list = [('UMAFall_wrist', 'UPFall_wrist')]\n","# tasks_list = [('UMAFall_leg', 'UPFall_rightpocket')]\n","\n","CV_n = 3\n","num_epochs = 10\n","extractor_type = 'CNNLSTM'\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","\n","training_params = {\n","  'classes_n': 2,\n","  'CV_n': CV_n,\n","  'num_epochs': num_epochs,\n","  'channel_n': 16,\n","  'batch_size': 16,\n","  'learning_rate': 0.001,\n","  'extractor_type': extractor_type,\n","  'device': device,\n","  'dropout': 0.5,\n","  'hiddenDim_f': 5,\n","  'hiddenDim_y': 5,\n","  'hiddenDim_d': 5,\n","  'win_size': 18,\n","  'win_stride': 6,\n","  'step_n': 9,\n","  }\n","\n","# for i, training_params in enumerate(training_params_list):\n","df_performance_table = pd.DataFrame('', index=['source', 'DANN', 'target', 'domain'], columns=[])\n","\n","for task_item in tasks_list:\n","  start_time = time.time()\n","\n","  (src_name, tgt_name) = task_item\n","\n","  inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz_LOO/'\n","  outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO_testing/{}_{}/'.format(src_name, tgt_name)\n","  if not os.path.exists(outputdir):\n","      os.makedirs(outputdir)\n","  print('outputdir for stage2 output:', outputdir)\n","\n","  df_performance_table = performance_table(df_performance_table, src_name, tgt_name, training_params, inputdir, outputdir)\n","\n","  time_elapsed = time.time() - start_time\n","  print('time elapsed:', time_elapsed)\n","  df_performance_table.loc['time_elapsed'] = time_elapsed\n","\n","  df_outputdir = outputdir\n","\n","  print('df_performance_table saved at', df_outputdir)\n","  df_performance_table.to_csv(df_outputdir+'df_performance_table_optimal.csv', encoding='utf-8')\n","\n","  display(df_performance_table)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"l6KnxpN4ecTM","colab_type":"code","outputId":"ae90ef25-7817-4174-b445-7e7d2373fd6a","executionInfo":{"status":"ok","timestamp":1585578044955,"user_tz":-480,"elapsed":136272,"user":{"displayName":"MICHAEL CHAN","photoUrl":"","userId":"10621351606155040584"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["display(df_performance_table)"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UMAFall_ankle_UPFall_ankle</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>source</th>\n","      <td>0.333±0.109</td>\n","    </tr>\n","    <tr>\n","      <th>DANN</th>\n","      <td>0.263±0.245</td>\n","    </tr>\n","    <tr>\n","      <th>target</th>\n","      <td>0.838±0.046</td>\n","    </tr>\n","    <tr>\n","      <th>domain</th>\n","      <td>0.794±0.328</td>\n","    </tr>\n","    <tr>\n","      <th>time_elapsed</th>\n","      <td>134.21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             UMAFall_ankle_UPFall_ankle\n","source                      0.333±0.109\n","DANN                        0.263±0.245\n","target                      0.838±0.046\n","domain                      0.794±0.328\n","time_elapsed                     134.21"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"wBWFQ68-CWo8","colab_type":"code","colab":{}},"source":["# # training_params = {\n","# #   'classes_n': 2,\n","# #   'CV_n': 2,\n","# #   'num_epochs': 10,\n","# #   'channel_n': 4,\n","# #   'batch_size': 32,\n","# #   'learning_rate': 0.01,\n","# #   'extractor_type': 'CNN',}\n","# training_params = {\n","#   'classes_n': 2,\n","#   'CV_n': 2,\n","#   'num_epochs': 10,\n","#   'channel_n': 4,\n","#   'batch_size': 32,\n","#   'learning_rate': 0.01,\n","#   'extractor_type': 'CNNLSTM',\n","#   'dropout': 0,\n","#   'hiddenDim_f': 5,\n","#   'hiddenDim_y': 5,\n","#   'hiddenDim_d': 5,\n","#   'win_size': 22,\n","#   'win_overlap': 0.5,\n","#   'step_n': 5,\n","#   }\n","\n","# tasks_list = [('UMAFall_leg', 'UPFall_rightpocket')]\n","# (src_name, tgt_name) = tasks_list[0]\n","# inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz_LOO/'\n","# outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO_testing/{}_{}/'.format(src_name, tgt_name)\n","\n","# source_outputs = BaselineModel_fitting_2(training_params, src_name, tgt_name, inputdir, outputdir+'source/')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eUtQpb4JRCy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PEJIJK9wJRAs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tbn2zdvRJQ96","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvZq_sZhJQ6y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"soPxNFfuJRx3","colab_type":"text"},"source":["# fixing DannModel_fitting WIP"]},{"cell_type":"code","metadata":{"id":"84EbLjuPCWms","colab_type":"code","colab":{}},"source":["\n","# def DannModel_fitting(training_params, src_name, tgt_name, inputdir, outputdir): \n","\n","#   if not os.path.exists(outputdir):\n","#       os.makedirs(outputdir)\n","\n","#   classes_n = training_params['classes_n']\n","#   CV_n = training_params['CV_n']\n","#   num_epochs = training_params['num_epochs']\n","#   channel_n = training_params['channel_n']\n","#   batch_size = training_params['batch_size']\n","#   learning_rate = training_params['learning_rate']\n","\n","#   df_performance = pd.DataFrame(0, index=np.arange(CV_n), \n","#                                 columns=['i_CV',\n","#                                         'train_src_class_loss','train_tgt_class_loss','train_src_domain_loss','train_tgt_domain_loss', \n","#                                         'train_src_class_acc','train_tgt_class_acc','train_domain_acc',\n","#                                         'val_src_class_loss','val_tgt_class_loss','val_src_domain_loss','val_tgt_domain_loss',\n","#                                         'val_src_class_acc','val_tgt_class_acc','val_domain_acc'])\n","\n","#   src_dataset_name = src_name.split('_')[0]\n","#   src_sensor_loc = src_name.split('_')[1]\n","\n","#   tgt_dataset_name = tgt_name.split('_')[0]\n","#   tgt_sensor_loc = tgt_name.split('_')[1]\n","\n","#   src_inputdir = inputdir + '{}/{}/'.format(src_dataset_name, src_sensor_loc)\n","#   tgt_inputdir = inputdir + '{}/{}/'.format(tgt_dataset_name, tgt_sensor_loc)\n","\n","\n","#   for i_CV in range(CV_n):\n","#     print('------------------------------Working on i_CV {}------------------------------'.format(i_CV))\n","#     # 1. prepare dataset\n","#     src_train_loader, src_val_loader = get_UMAFall_loader(src_inputdir, i_CV, batch_size, learning_rate)\n","#     tgt_train_loader, tgt_val_loader = get_UPFall_loader(tgt_inputdir, i_CV, batch_size, learning_rate)\n","\n","#     # the model expect the same input dimension for src and tgt data\n","#     src_train_size = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","#     src_val_size = src_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","\n","#     tgt_train_size = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","#     tgt_val_size = tgt_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","\n","#     src_input_dim = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n","#     tgt_input_dim = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n","\n","#     # 2. prepare model\n","#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","#     # loss and optimizer\n","#     class_criterion = nn.CrossEntropyLoss()\n","#     domain_criterion = nn.CrossEntropyLoss()\n","\n","#     # 3. fit the model\n","#     total_step = len(src_train_loader)\n","\n","#     train_loss_avg_epochs = np.zeros(num_epochs)\n","#     train_src_class_acc_epochs = np.zeros(num_epochs)\n","#     train_tgt_class_acc_epochs = np.zeros(num_epochs)\n","#     train_domain_acc = np.zeros(num_epochs)\n","#     val_loss_avg_epochs = np.zeros(num_epochs)\n","#     val_src_class_acc_epochs = np.zeros(num_epochs)\n","#     val_tgt_class_acc_epochs = np.zeros(num_epochs)\n","#     val_domain_acc = np.zeros(num_epochs)\n","\n","#     df_performance.loc[i_CV,'i_CV'] = i_CV\n","#     model = DannModel(device, class_N=classes_n, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n","#     model_name = model.__class__.__name__\n","#     train_size = src_train_size+tgt_train_size\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n","\n","#     model_output_diagnosis_trainval(model, src_train_loader, tgt_train_loader, src_val_loader, tgt_val_loader, device, '_epoch{}'.format(0), i_CV, outputdir)\n","#     model_features_diagnosis_trainval(model, src_train_loader, tgt_train_loader, src_val_loader, tgt_val_loader, device, '_epoch{}'.format(0), i_CV, outputdir)\n","\n","#     for epoch in range(num_epochs):\n","#       fitting_outputs = train_epoch_dann(src_train_loader, tgt_train_loader, src_train_size, tgt_train_size, device, \n","#                                           model, \n","#                                           class_criterion, domain_criterion, optimizer, epoch)\n","      \n","#       train_loss_avg, src_class_loss_avg, tgt_class_loss_avg, src_domain_loss_avg, tgt_domain_loss_avg, src_class_acc, tgt_class_acc, domain_acc = fitting_outputs\n","\n","#       train_loss_avg_epochs[epoch] = train_loss_avg\n","#       train_src_class_acc_epochs[epoch] = src_class_acc\n","#       train_tgt_class_acc_epochs[epoch] = tgt_class_acc\n","#       train_domain_acc[epoch] = domain_acc\n","#       df_performance.loc[i_CV,['train_src_class_loss','train_tgt_class_loss','train_src_domain_loss','train_tgt_domain_loss', \n","#                                 'train_src_class_acc','train_tgt_class_acc','train_domain_acc']] = [src_class_loss_avg, tgt_class_loss_avg, src_domain_loss_avg, tgt_domain_loss_avg, src_class_acc, tgt_class_acc, domain_acc]\n","\n","#       val_outputs = val_epoch_dann(src_val_loader, tgt_val_loader, src_val_size, tgt_val_size, device, \n","#                                       model,\n","#                                       class_criterion, domain_criterion, epoch)\n","\n","#       val_loss_avg, src_class_loss_avg, tgt_class_loss_avg, src_domain_loss_avg, tgt_domain_loss_avg, src_class_acc, tgt_class_acc, domain_acc = val_outputs\n","\n","#       val_loss_avg_epochs[epoch] = val_loss_avg\n","#       val_src_class_acc_epochs[epoch] = src_class_acc\n","#       val_tgt_class_acc_epochs[epoch] = tgt_class_acc\n","#       val_domain_acc[epoch] = domain_acc\n","\n","#       # 4. store the performance of the model at the last epoch\n","#       df_performance.loc[i_CV,['val_src_class_loss','val_tgt_class_loss','val_src_domain_loss','val_tgt_domain_loss', \n","#                                 'val_src_class_acc','val_tgt_class_acc','val_domain_acc']] = [src_class_loss_avg, tgt_class_loss_avg, src_domain_loss_avg, tgt_domain_loss_avg, src_class_acc, tgt_class_acc, domain_acc]\n","    \n","#     dann_learning_diagnosis(num_epochs, train_loss_avg_epochs, val_loss_avg_epochs, \\\n","#     train_src_class_acc_epochs, val_src_class_acc_epochs, \\\n","#     train_tgt_class_acc_epochs, val_tgt_class_acc_epochs, \\\n","#     train_domain_acc, val_domain_acc, i_CV, outputdir)\n","    \n","#     print('-----------------Exporting pytorch model-----------------')\n","#     loaded_model = DannModel(device, class_N=classes_n, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n","#     export_model(model, loaded_model, outputdir+'model_CV{}'.format(i_CV))\n","\n","#     print('-----------------Evaluating trained model-----------------')\n","#     model_output_diagnosis_trainval(loaded_model, src_train_loader, tgt_train_loader, src_val_loader, tgt_val_loader, device, '_epoch{}'.format(epoch), i_CV, outputdir)\n","#     model_features_diagnosis_trainval(loaded_model, src_train_loader, tgt_train_loader, src_val_loader, tgt_val_loader, device, '_epoch{}'.format(epoch), i_CV, outputdir)\n","\n","#   # 5. export model performance as df\n","#   print('---------------Exporting model performance---------------')\n","#   export_perofmance(df_performance, CV_n, outputdir)\n","\n","#   print('val_src_class_acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_src_class_acc'], df_performance.loc['std']['val_src_class_acc']))\n","#   print('val_tgt_class_acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_tgt_class_acc'], df_performance.loc['std']['val_tgt_class_acc']))\n","#   print('val_domain_acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_domain_acc'], df_performance.loc['std']['val_domain_acc']))\n","\n","#   # print('=========================================================')\n","\n","#   # 6. export notebook parameters as dict\n","#   # datetime object containing current date and time\n","#   print('--------------Exporting notebook parameters--------------')\n","#   now = datetime.now()\n","#   dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n","#   samples_n = src_train_size + src_val_size\n","\n","#   param_dict = {\n","#       'CV_n': CV_n,\n","#       'samples_n': samples_n,\n","#       'classes_n': classes_n,\n","#       'model_name': model_name,\n","#       'src_dataset_name': src_dataset_name,\n","#       'tgt_dataset_name': tgt_dataset_name,\n","#       'src_sensor_loc': src_sensor_loc,\n","#       'tgt_sensor_loc': tgt_sensor_loc,\n","#       'date': dt_string,\n","#       'num_epochs': num_epochs,\n","#       'channel_n': channel_n,\n","#       'batch_size': batch_size,\n","#       'learning_rate': learning_rate,\n","#       'input_dim': (batch_size, src_train_loader.dataset.data.size()[1], src_train_loader.dataset.data.size()[2]),\n","#       'output_dim': 2,\n","#       'label_dim': src_train_loader.dataset.labels[0:batch_size].data.detach().cpu().numpy().shape,\n","#   }\n","#   print(param_dict)\n","\n","#   with open(outputdir+'notebook_param.json', 'w') as fp:\n","#     json.dump(param_dict, fp)\n","\n","#   print('val_tgt_class_acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_tgt_class_acc'], df_performance.loc['std']['val_tgt_class_acc']))\n","#   print('val_domain_acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_domain_acc'], df_performance.loc['std']['val_domain_acc']))\n","\n","#   return (df_performance.loc['mean']['val_tgt_class_acc'], df_performance.loc['std']['val_tgt_class_acc']), (df_performance.loc['mean']['val_domain_acc'], df_performance.loc['std']['val_domain_acc'])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGUsfWNDCWkq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oy_4AJnWCWiR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1e5p1K_-pVsH","colab_type":"code","colab":{}},"source":["# import os\n","# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","# import torchvision.models\n","# import collections\n","# import math\n","# import sys\n","\n","# class lstmnet(nn.Module):\n","#     r\"\"\"lstmnet is a simple recurrent neural network that contains one \n","#     hidden layer of 64 nodes with 3 time steps by default. It expects \n","#     an input of 3D tensor with a dimension (batch, time_step, \n","#     input_size). The output will be a 2D tensor with a dimension (N, 2).\n","\n","#     Args:\n","#         - None. The variables used for each sub-layer are hard-coded\n","#     Shape:\n","#         - Input: :math:`(batch, time_step, input_size)`\n","#         - Output: :math:`(batch, output_size)`\n","#     Examples::\n","#         >>> m = lstmnet()\n","#         >>> batchSize = 16\n","#         >>> featDim = 10\n","#         >>> timeStep = 3\n","#         >>> input = torch.randn(batchSize, timeStep, featDim)\n","#         >>> output = m(input)\n","#         >>> output.size()\n","#             (16, 2)\n","#     \"\"\"\n","#     def __init__(self, inputDim=10, hiddenDim=64, outputDim=2, ):\n","#         super(lstmnet, self).__init__()\n","#         self.outputDim = outputDim\n","\n","#         self.lstm = nn.LSTM(         # if use nn.RNN(), it hardly learns\n","#             input_size=int((inputDim-2)/3),\n","#             hidden_size=hiddenDim,         # rnn hidden unit\n","#             num_layers=2,           # number of rnn layer\n","#             batch_first=True,       # input & output will has batch size as 1st dimension. e.g. (batch, time_step, input_size)\n","#             bidirectional=True,\n","#             dropout=0.5\n","#         )\n","\n","#         self.fc1 = nn.Linear(hiddenDim*2+2, 25)\n","#         self.fc2 = nn.Linear(25, outputDim)\n","#         self.relu = nn.ReLU(inplace=False)\n","#         self.lsm = nn.LogSoftmax(dim=1)\n","# #         self.bn = nn.BatchNorm1d(10)\n","\n","#     def forward(self, x):\n","#       # x shape (time_step, batch, input_size, channel_n), float tensor\n","#       # r_out shape (time_step, batch, lstm_output_size)\n","#       # h_n shape (n_layers, batch, hidden_size)\n","#       # h_c shape (n_layers, batch, hidden_size)\n","#       # out shape (batch, output_size)\n","#       x = x.float()\n","\n","#       timestep_n = x.size()[0]\n","#       batch_n = x.size()[1]\n","#       input_size = x.size()[2]\n","#       out1_size = x.size()[2]\n","#       channel_n =  x.size()[3]\n","      \n","#       out1 = torch.randn(timestep_n, , , dtype=torch.double)\n","\n","#       # None represents zero initial hidden state, so don't have to implement initHidden\n","#       for timestep in range(timestep_n:\n","#         out1[timestep,:,:,:] = self.layer1(x[timestep,:,:,:])\n","\n","\n","#         out_freq_x, (h_n, h_c) = self.lstm(x[:,:,:], None)\n","#         out_freq_y, (h_n, h_c) = self.lstm(x[:,:,100:200], None)\n","#         out_freq_z, (h_n, h_c) = self.lstm(x[:,:,200:300], None)\n","        \n","#         out_flstm = out_freq_x + out_freq_y + out_freq_z # torch.Size([16, 5, 128])\n","# #         print('size of out_flstm is ', out_flstm.size())\n","\n","#         out_cat = torch.cat((out_flstm, x[:,:,-2:]), 2)\n","# #         out_cat = out_flstm\n","\n","#         out = torch.randn(x.size()[0], x.size()[1], self.outputDim, dtype=torch.double)\n","\n","#         # in this implementation, outputs from all timesteps are used for loss and back prop\n","#         for timestep in range(out_cat.size()[1]):\n","#             out_step = self.relu(self.fc1(out_cat[:, timestep, :]))\n","#             out_step = self.fc2(out_step)\n","# #             out_step = self.fc(out_cat[timestep, :, :])\n","#             out[:, timestep, :] = self.lsm(out_step)\n","            \n","#         debug = False\n","#         if debug == True:\n","#             print('-----------------------------')\n","#             print('size of x is ', x.size())\n","#             print('size of out_freq_x is ', out_freq_x.size())\n","#             print('size of h_n is ', h_n.size())\n","#             print('size of h_c is ', h_c.size())\n","#             print('size of out_cat is ', out_cat.size())\n","#             print('size of out_step is ', out_step.size())\n","#             print('size of out is ', out.size())\n","#             print('-----------------------------')\n","#             sys.exit()\n","\n","#         return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQXX-AwxpTuf","colab_type":"code","colab":{}},"source":["# # Convolutional neural network (two convolutional layers)\n","# class ConvNet2(nn.Module):\n","#     def __init__(self, class_N=2, channel_n=16, input_dim=10, p=0.5):\n","#         super(ConvNet2, self).__init__()\n","#         self.layer1 = nn.Sequential(\n","#             nn.Conv1d(3, channel_n, kernel_size=3, stride=1, padding=2),\n","#             nn.BatchNorm1d(channel_n),\n","#             nn.ReLU(),\n","#             nn.MaxPool1d(kernel_size=2, stride=2))\n","#         self.layer2 = nn.Sequential(\n","#             nn.Conv1d(channel_n, channel_n, kernel_size=3, stride=1, padding=2),\n","#             nn.BatchNorm1d(channel_n),\n","#             nn.ReLU(),\n","#             nn.MaxPool1d(kernel_size=2, stride=2))\n","#         # self.layer3 = nn.Sequential(\n","#         #     nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=2),\n","#         #     nn.BatchNorm1d(64),\n","#         #     nn.ReLU(),\n","#         #     nn.MaxPool1d(kernel_size=2, stride=2))\n","        \n","#         cnn_layer1_dim = (input_dim+2*2-1*(3-1)-1)+1\n","#         pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n","\n","#         # cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n","#         # pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n","\n","#         # cnn_layer3_dim = (pool_layer2_dim+2*2-1*(3-1)-1)+1\n","#         # pool_layer3_dim = (cnn_layer3_dim-1*(2-1)-1)/2+1\n","\n","#         # print('cnn_layer1_dim:', cnn_layer1_dim)\n","#         # print('pool_layer1_dim:', pool_layer1_dim)\n","#         # print('cnn_layer2_dim:', cnn_layer2_dim)\n","#         # print('pool_layer2_dim:', pool_layer2_dim)\n","#         # print('cnn_layer3_dim:', cnn_layer3_dim)\n","#         # print('pool_layer3_dim:', pool_layer3_dim)\n","#         # fc_dim = int(((((input_dim)+2*2-1)/2+2*2-1)/2+2*2-1)/2*64)\n","#         self.fc1 = nn.Linear(int(pool_layer1_dim)*channel_n, 50)\n","#         self.drop_out = nn.Dropout(p=0)\n","#         self.fc2 = nn.Linear(50, class_N)\n","        \n","#     def forward(self, x):\n","#       out1 = self.layer1(x.float())\n","#       # print('out1 size:', out1.size())\n","#       # out2 = self.layer2(out1)\n","#       # print('out2 size:', out2.size())\n","#       # out3 = self.layer3(out2)\n","#       # print('out3 size:', out3.size())\n","#       # print('out2 size:', out2.size())\n","#       out1 = out1.reshape(out1.size(0), -1)\n","#       # print('out2 size:', out2.size())\n","#       out1 = self.drop_out(out1)\n","#       out2 = self.fc1(out1)\n","#       out3 = self.fc2(out2)\n","#       # print('x, out1, out2, out 3, out4 size',  x.size(), out1.size(), out2.size(), out3.size(), out4.size())\n","#       return out1, out3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLJNv0EXEfH-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QuLbnqA6Xwgm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7yCS6WL4kSGL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqlC22yVW6hp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5zQmLdUGkBw","colab_type":"code","colab":{}},"source":["# def train_epoch(train_loader, train_size, device, model, criterion, optimizer, epoch):\n","#   total_train_loss = 0\n","#   train_TPTF = 0\n","#   debug = False\n","#   for i, (data, labels) in enumerate(train_loader):\n","\n","#     data = data.to(device)\n","#     labels = labels.to(device).long()\n","\n","#     # Forward pass\n","#     # feature_out, class_out = model(data)\n","#     feature_out, class_out, _ = model(data)\n","\n","#     train_loss = criterion(class_out, labels)\n","\n","#     # Backward and optimize\n","#     optimizer.zero_grad()\n","#     train_loss.backward()\n","#     optimizer.step()\n","\n","#     # total_train_loss += train_loss.data.numpy()\n","#     total_train_loss += train_loss.data.detach().cpu().numpy()\n","#     out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n","#     train_pred = np.argmax(out_sigmoid, 1)\n","#     train_TPTF += (train_pred==labels.data.detach().cpu().numpy()).sum()\n","\n","#     #######################\n","#     if debug:\n","#       print('Epoch [{}/{}] Step [{}/{}]:'\n","#             'train_loss={:.5f} train_acc={:.5f}'\n","#             .format(epoch + 1,\n","#                     20,\n","#                     i + 1,\n","#                     len(train_loader),\n","#                     train_loss,\n","#                     (train_pred==labels.data.detach().cpu().numpy()).sum()))\n","#     #######################\n","                \n","#   train_loss = total_train_loss/train_size\n","#   train_acc = train_TPTF/train_size\n","\n","#   return train_loss, train_acc\n","\n","# def val_epoch(val_loader, val_size, device, model, criterion, optimizer, epoch):\n","#   total_val_loss = 0\n","#   val_TPTF = 0\n","#   debug = False\n","  \n","#   for i, (data, labels) in enumerate(val_loader):\n","#     data = data.to(device)\n","#     labels = labels.to(device).long()\n","    \n","#     #Forward pass\n","#     # feature_out, class_out = model(data)\n","#     feature_out, class_out, _ = model(data)\n","#     val_loss = criterion(class_out, labels)\n","    \n","#     total_val_loss += val_loss.data.detach().cpu().numpy()\n","#     out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n","#     val_pred = np.argmax(out_sigmoid, 1)\n","#     val_TPTF += (val_pred==labels.data.detach().cpu().numpy()).sum()\n","\n","#     #######################\n","#     if debug:\n","#       print('Epoch [{}/{}] Step [{}/{}]:'\n","#             'val_loss={:.5f} val_acc={:.5f}'\n","#             .format(epoch + 1,\n","#                     20,\n","#                     i + 1,\n","#                     len(val_loader),\n","#                     val_loss,\n","#                     (val_pred==labels.data.detach().cpu().numpy()).sum()))\n","#     #######################\n","\n","#   val_loss = total_val_loss/val_size\n","#   val_acc = val_TPTF/val_size\n","\n","#   return val_loss, val_acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3-u-rG8Gj_d","colab_type":"code","colab":{}},"source":["# def ConvNet2Model_fitting(training_params, src_name, tgt_name, inputdir, outputdir): \n","#   show_train_log = False\n","\n","#   if not os.path.exists(outputdir):\n","#       os.makedirs(outputdir)\n","      \n","#   classes_n = training_params['classes_n']\n","#   CV_n = training_params['CV_n']\n","#   num_epochs = training_params['num_epochs']\n","#   channel_n = training_params['channel_n']\n","#   batch_size = training_params['batch_size']\n","#   learning_rate = training_params['learning_rate']\n","#   dropout_p = training_params['dropout_p']\n","\n","#   df_performance = pd.DataFrame(columns=['i_CV',\n","#                                           'train_loss','train_acc','val_loss','val_acc', 'tgt_val_loss', 'tgt_val_acc'])\n","\n","#   src_dataset_name = src_name.split('_')[0]\n","#   src_sensor_loc = src_name.split('_')[1]\n","\n","#   tgt_dataset_name = tgt_name.split('_')[0]\n","#   tgt_sensor_loc = tgt_name.split('_')[1]\n","\n","#   src_inputdir = inputdir + '{}/{}/'.format(src_dataset_name, src_sensor_loc)\n","#   tgt_inputdir = inputdir + '{}/{}/'.format(tgt_dataset_name, tgt_sensor_loc)\n","\n","\n","#   for i_CV in range(CV_n):\n","#     # 1. prepare dataset\n","#     src_train_loader, src_val_loader = get_UMAFall_loader(src_inputdir, i_CV, batch_size, learning_rate)\n","#     tgt_train_loader, tgt_val_loader = get_UPFall_loader(tgt_inputdir, i_CV, batch_size, learning_rate)\n","\n","#     # the model expect the same input dimension for src and tgt data\n","#     src_train_size = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","#     src_val_size = src_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","\n","#     tgt_train_size = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","#     tgt_val_size = tgt_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n","\n","#     src_input_dim = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n","#     tgt_input_dim = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n","\n","#     # 2. prepare model\n","#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","#     # loss and optimizer\n","#     # criterion = nn.CrossEntropyLoss()\n","#     class_criterion = nn.CrossEntropyLoss()\n","#     # domain_criterion = nn.CrossEntropyLoss()\n","\n","\n","#     # 3. fit the model\n","#     total_step = len(src_train_loader)\n","\n","#     train_loss_avg_epochs = np.zeros(num_epochs)\n","#     train_class_acc_epochs = np.zeros(num_epochs)\n","#     val_src_loss_avg_epochs = np.zeros(num_epochs)\n","#     val_src_class_acc_epochs = np.zeros(num_epochs)\n","#     val_tgt_loss_avg_epochs = np.zeros(num_epochs)\n","#     val_tgt_class_acc_epochs = np.zeros(num_epochs)\n","\n","#     for epoch in range(num_epochs):\n","\n","#       # if training_mode == 'source':\n","#       # model = BaselineModel(device, class_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n","#       # model = ConvNet2(class_N=2, channel_n=16, input_dim=66, p=dropout_p).to(device).float()\n","#       model = DannModel(device, class_N=2, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n","#       model_name = model.__class__.__name__\n","#       optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n","#       # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","#       train_loss, train_acc = train_epoch(src_train_loader, src_train_size, device, model, class_criterion, optimizer, epoch)\n","#       train_loss_avg_epochs[epoch] = train_loss\n","#       train_class_acc_epochs[epoch] = train_acc\n","\n","#       val_loss, val_acc = val_epoch(src_val_loader, src_val_size, device, model, class_criterion, optimizer, epoch)\n","#       val_src_loss_avg_epochs[epoch] = val_loss\n","#       val_src_class_acc_epochs[epoch] = val_acc\n","\n","#       tgt_val_loss, tgt_val_acc = val_epoch(tgt_val_loader, tgt_val_size, device, model, class_criterion, optimizer, epoch)\n","#       val_tgt_loss_avg_epochs[epoch] = tgt_val_loss\n","#       val_tgt_class_acc_epochs[epoch] = tgt_val_acc\n","\n","#       if show_train_log:\n","#         print('Epoch {}'.format(epoch))\n","#         print('Train Loss: {:.6f}, Train ACC: {:.6f}, Val loss = {:.6f}, Val ACC: {:.6f}'.\n","#               format(train_loss, train_acc, val_loss, val_acc))\n","#         print('Target Val loss = {:.6f}, Val ACC: {:.6f}'.format(tgt_val_loss, tgt_val_acc))\n","\n","#       # 4. store the performance of the model at the last epoch\n","#       df_performance.loc[i_CV] = [i_CV, train_loss, train_acc, val_loss, val_acc, tgt_val_loss, tgt_val_acc]\n","    \n","#     fig = plt.figure(figsize=(10, 3), dpi=80)\n","#     ax1 = fig.add_subplot(1, 2, 1)\n","#     ax1.set_title('loss_avg_epochs')\n","#     ax1.set_xlabel('epoch')\n","#     ax1.plot(np.arange(num_epochs), train_loss_avg_epochs, color='blue', label='train')\n","#     ax1.plot(np.arange(num_epochs), val_src_loss_avg_epochs, color='red', label='val_src')\n","#     ax1.plot(np.arange(num_epochs), val_tgt_loss_avg_epochs, color='green', label='val_tgt')\n","#     ax1.legend(loc=\"upper right\")\n","#     ax2 = fig.add_subplot(1, 2, 2)\n","#     ax2.set_title('class_acc_epochs')\n","#     ax2.set_xlabel('epoch')\n","#     ax2.plot(np.arange(num_epochs), train_class_acc_epochs, color='blue', label='train')\n","#     ax2.plot(np.arange(num_epochs), val_src_class_acc_epochs, color='red', label='val_src')\n","#     ax2.plot(np.arange(num_epochs), val_tgt_class_acc_epochs, color='green', label='val_tgt')\n","#     ax2.legend(loc=\"upper right\")\n","#     plt.show()\n","\n","\n","#     print('=================Exporting pytorch model=================')\n","#     # loaded_model = ConvNet2(class_N=2, channel_n=16, input_dim=66, p=dropout_p).to(device).float()\n","#     loaded_model = DannModel(device, class_N=2, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n","#     export_model(model, loaded_model, outputdir+'model_CV{}'.format(i_CV))\n","#     print('=========================================================')\n","\n","#   # 5. export model performance as df\n","#   print('===============Exporting model performance===============')\n","#   export_perofmance(df_performance, CV_n, outputdir)\n","\n","#   print('src val loss: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_loss'], df_performance.loc['std']['val_loss']))\n","#   print('src val acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_acc'], df_performance.loc['std']['val_acc']))\n","  \n","#   print('tgt val loss: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['tgt_val_loss'], df_performance.loc['std']['tgt_val_loss']))\n","#   print('tgt val acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['tgt_val_acc'], df_performance.loc['std']['tgt_val_acc']))\n","\n","#   print('=========================================================')\n","\n","#   # 6. export notebook parameters as dict\n","#   # datetime object containing current date and time\n","#   print('==============Exporting notebook parameters==============')\n","#   now = datetime.now()\n","#   dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n","#   samples_n = src_train_size + src_val_size\n","\n","#   param_dict = {\n","#       'CV_n': CV_n,\n","#       'samples_n': samples_n,\n","#       'classes_n': classes_n,\n","#       'model_name': model_name,\n","#       'dataset_name': src_dataset_name,\n","#       'sensor_loc': src_sensor_loc,\n","#       'date': dt_string,\n","#       'batch_size': batch_size,\n","#       'input_dim': (batch_size, src_train_loader.dataset.data.size()[1], src_train_loader.dataset.data.size()[2]),\n","#       'output_dim': src_train_loader.dataset.labels[0:batch_size].data.detach().cpu().numpy().shape,\n","#       'label_dim': CV_n,\n","#   }\n","#   print(param_dict)\n","\n","#   with open(outputdir+'notebook_param.json', 'w') as fp:\n","#     json.dump(param_dict, fp)\n","#   print('=========================================================')\n","\n","#   return (df_performance.loc['mean']['val_acc'], df_performance.loc['std']['val_acc']), (df_performance.loc['mean']['tgt_val_acc'], df_performance.loc['std']['tgt_val_acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gfQua3gGj83","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwNPLlA8HoWr","colab_type":"code","colab":{}},"source":["# # tasks_list = [('UMAFall_wrist', 'UPFall_wrist')]\n","# tasks_list = [('UMAFall_waist', 'UPFall_belt')]\n","\n","# # optimal_training_params = {\n","# #     'classes_n': 2,\n","# #     'CV_n': 5,\n","# #     'num_epochs': 3,\n","# #     'channel_n': 32,\n","# #     'batch_size': 1,\n","# #     'learning_rate': 0.01}\n","\n","# training_params = {\n","#     'classes_n': 2,\n","#     'CV_n': 5,\n","#     'num_epochs': 20,\n","#     'channel_n': 2,\n","#     'batch_size': 1,\n","#     'learning_rate': 0.01,\n","#     'dropout_p': 0.2}\n","\n","# for task_item in tasks_list:\n","#   (src_name, tgt_name) = task_item\n","\n","#   inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n","#   outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_archdesign_18hz/{}_{}/'.format(src_name, tgt_name)\n","#   if not os.path.exists(outputdir):\n","#       os.makedirs(outputdir)\n","#   print('outputdir for stage2 output:', outputdir)\n","  \n","#   source_outputs = ConvNet2Model_fitting(training_params, src_name, tgt_name, inputdir, outputdir+'source/')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3FUoXUwbHoS4","colab_type":"code","colab":{}},"source":["# source_outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A66bXfcDHoP8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mfs_IpRkHoLm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRx6_kUvHoIE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDVBXu0i4ZNB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r2Z4tKb2_0Nq","colab_type":"text"},"source":["# Start CV training and validation in a big phat loop (to be deprecated)"]},{"cell_type":"code","metadata":{"id":"vZlGwYngxAhw","colab_type":"code","colab":{}},"source":["# def model_fitting(CV_n, classes_n, sensor_loc, dataset_name, inputdir): \n","#   # it's big phat loop i don't like it qq\n","#   df_performance = pd.DataFrame(columns=['i_CV','train_loss','train_acc','val_loss','val_acc'])\n","\n","#   for i_CV in range(CV_n):\n","#     # 1. prepare dataset\n","#     train_inputdir = inputdir+'/CV{}/train'.format(i_CV)\n","#     val_inputdir = inputdir+'/CV{}/val'.format(i_CV)\n","\n","#     train_data = data_loader('data', train_inputdir).transpose(2,1,0)\n","#     val_data = data_loader('data', val_inputdir).transpose(2,1,0)\n","\n","#     train_labels = data_loader('labels', train_inputdir)\n","#     val_labels = data_loader('labels', val_inputdir)\n","\n","#     train_i_sub = data_loader('i_sub', train_inputdir)\n","#     val_i_sub = data_loader('i_sub', val_inputdir)\n","\n","#     print('train_data shape:', train_data.shape)\n","#     print('val_data shape:', val_data.shape)\n","\n","#     train_size = train_labels.shape[0]\n","#     val_size = val_labels.shape[0]\n","#     input_dim = train_data.shape[2]\n","\n","#     # convert labels from multi-class activities to binary (fall/ADL)\n","#     train_labels_binary = ((train_labels==10)|(train_labels==11)|(train_labels==12)).astype(int)\n","#     val_labels_binary = ((val_labels==10)|(val_labels==11)|(val_labels==12)).astype(int)\n","\n","#     train_dataset = FallDataset(train_data, train_labels_binary)\n","#     val_dataset = FallDataset(val_data, val_labels_binary)\n","#     # data loader\n","#     batch_size = 4\n","#     learning_rate = 0.001\n","\n","#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","#                                               batch_size=batch_size, \n","#                                               shuffle=True)\n","\n","#     val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n","#                                               batch_size=batch_size, \n","#                                               shuffle=False)\n","\n","#     # 2. prepare model\n","#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","#     model = ConvNet(num_classes=classes_n, input_dim=input_dim).to(device).float()\n","\n","#     # loss and optimizer\n","#     criterion = nn.CrossEntropyLoss()\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","#     # test model on a batch\n","#     try:\n","#       out = model(train_dataset.data[0:batch_size,:,:])\n","#       model_outdim = out.data.numpy().shape\n","#     except:\n","#       print('Warning: model cannot read input')\n","\n","#     print('{} model architecture: '.format(model.__class__.__name__))\n","#     print(model)\n","\n","\n","#     # 3. fit the model\n","#     num_epochs = 10\n","#     total_step = len(train_loader)\n","#     for epoch in range(num_epochs):\n","#       total_train_loss = 0\n","#       train_TPTF = 0\n","#       for i, (data, labels) in enumerate(train_loader):\n","#         data = data.to(device)\n","#         labels = labels.to(device).long()\n","\n","#         # Forward pass\n","#         outputs = model(data)\n","#         train_loss = criterion(outputs, labels)\n","#         total_train_loss += train_loss.data.numpy()\n","        \n","#         out_sigmoid = torch.sigmoid(outputs).data.numpy()\n","#         train_pred = np.argmax(out_sigmoid, 1)\n","#         train_TPTF += (train_pred==labels.data.numpy()).sum()\n","#         # train_pred = print(np.argmax(F.sigmoid(outputs))\n","\n","\n","#         # Backward and optimize\n","#         optimizer.zero_grad()\n","#         train_loss.backward()\n","#         optimizer.step()\n","\n","#         # if (i+1) % 5 == 0:\n","#         #     print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.8f}' \n","#         #             .format(epoch+1, num_epochs, i+1, total_step, train_loss.data.numpy()/labels.size()[0]))\n","\n","#       total_val_loss = 0\n","#       val_TPTF = 0\n","#       for i, (data, labels) in enumerate(val_loader):\n","#         data = data.to(device)\n","#         labels = labels.to(device).long()\n","        \n","#         #Forward pass\n","#         val_outputs = model(data)\n","#         val_loss = criterion(val_outputs, labels)\n","#         total_val_loss += val_loss.data.numpy()\n","\n","#         out_sigmoid = torch.sigmoid(val_outputs).data.numpy()\n","#         val_pred = np.argmax(out_sigmoid, 1)\n","#         val_TPTF += (val_pred==labels.data.numpy()).sum()\n","#         # print(val_TPTF, len(val_loader))\n","          \n","#       train_loss = total_train_loss/train_size\n","#       train_acc = train_TPTF/train_size\n","#       val_loss = total_val_loss/val_size\n","#       val_acc = val_TPTF/val_size\n","\n","\n","#       print('Epoch {}'.format(epoch+1))\n","#       print('Train Loss: {:.6f}, Train ACC: {:.6f}, Val loss = {:.6f}, Val ACC: {:.6f}'.\n","#             format(train_loss, train_acc, val_loss, val_acc))\n","    \n","#     # 4. store the performance of the model at the last epoch\n","#     df_performance.loc[i_CV] = [i_CV, train_loss, train_acc, val_loss, val_acc]\n","\n","#   outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput/{}/{}/'.format(dataset_name, sensor_loc)\n","#   if not os.path.exists(outputdir):\n","#       os.makedirs(outputdir)\n","#   print('outputdir for stage2 output:', outputdir)\n","\n","#   # 5. export model performance as df\n","#   export_perofmance(df_performance, CV_n, outputdir)\n","\n","#   # 6. export notebook parameters as dict\n","#   # datetime object containing current date and time\n","#   now = datetime.now()\n","#   dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n","#   samples_n = train_size + val_size\n","\n","#   param_dict = {\n","#       'CV_n': CV_n,\n","#       'samples_n': samples_n,\n","#       'classes_n': classes_n,\n","#       'model_name': model.__class__.__name__,\n","#       'dataset_name': dataset_name,\n","#       'sensor_loc': sensor_loc,\n","#       'date': dt_string,\n","#       'batch_size': batch_size,\n","#       'input_dim': (batch_size, train_dataset.data.size()[1], train_dataset.data.size()[2]),\n","#       'output_dim': train_dataset.labels[0:batch_size].data.numpy().shape,\n","#       'label_dim': CV_n,\n","#   }\n","#   print(param_dict)\n","\n","#   with open(outputdir+'notebook_param.json', 'w') as fp:\n","#     json.dump(param_dict, fp)\n","\n","#   export_model(model, classes_n, input_dim, device, outputdir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"me8Xckeynq79","colab_type":"code","colab":{}},"source":["# datasets_sensor_dict = {\n","#     'UMAFall': ['waist', 'wrist', 'leg', 'chest', 'ankle'],\n","#     'UPFall': ['wrist', 'rightpocket', 'neck', 'belt', 'ankle']\n","# }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XuNFe4Q_oOyE","colab_type":"code","colab":{}},"source":["# inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed/{}/{}/'.format(dataset_name, sensor_loc)\n","# classes_n = 2\n","# CV_n = 5\n","\n","# for key in datasets_sensor_dict.keys():\n","#   dataset_name = key\n","#   for sensor_loc in datasets_sensor_dict[dataset_name]:\n","#     model_fitting(CV_n, classes_n, sensor_loc, dataset_name, inputdir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4I2Bn31oZ0l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PT0nxNaGqxim","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnK88jJ3kXd3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTuPZryA0XDr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5BIaUPJ-0XBz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWcFYNkc1S12","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}