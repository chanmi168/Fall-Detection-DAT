{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Isjqqa84yJv-"
   },
   "source": [
    "**stage3_model_eval**. This notebook evaluates the trained model\n",
    "\n",
    "**Edit**<br/>\n",
    "\n",
    "**TODO**<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1585238820612,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "dR0gs1Ya0xmy",
    "outputId": "7cd142ac-9bd4-44c1-db43-2b84b7e35cdf"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFk7y6uzVQ2s"
   },
   "source": [
    "# Get user inputs\n",
    "In ipython notebook, these are hardcoded. In production python code, use parsers to provide these inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Js2lmEUEVQ-G"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FD_DAT')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--training_params_file', metavar='training_params_file', help='training_params_file',\n",
    "                    default='training_params_list.json')\n",
    "parser.add_argument('--tasks_list', metavar='tasks_list', help='a list of all tasks',\n",
    "                    default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "parser.add_argument('--variable_name', metavar='variable_name', help='key in training_params to be displayed on plot',\n",
    "                    default='HP_name')\n",
    "parser.add_argument('--debug_F1', metavar='debug_F1', help='debug F1',\n",
    "                    default='False')\n",
    "\n",
    "\n",
    "\n",
    "# parser.add_argument('--src_names', metavar='src_names', help='a list of src_names',\n",
    "#                     default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "# parser.add_argument('--tgt_names', metavar='tgt_names', help='a list of tgt_names',\n",
    "#                     default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "\n",
    "# checklist 2: comment first line, uncomment second line seizures_FN\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_diffCV',\n",
    "#                           '--output_folder', '../../data_mic/stage3/test',\n",
    "\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_WithoutNormal_18hz_5fold_UPFall_UMAFall_cross-config_diffCV',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_diffCV_earlystop',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/test',\n",
    "args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_HPsearch',\n",
    "                          '--output_folder', '../../data_mic/stage3/test',\n",
    "#                           '--training_params_file', 'training_params_list_fixed.json',\n",
    "                          '--training_params_file', 'training_params_list_HPsearch.json',\n",
    "#                           '--tasks_list', 'UMAFall_chest-UPFall_neck UMAFall_wrist-UPFall_wrist UMAFall_waist-UPFall_belt UMAFall_leg-UPFall_rightpocket UMAFall_ankle-UPFall_ankle',\n",
    "                          '--tasks_list', 'UMAFall_wrist-UPFall_wrist',\n",
    "                          '--variable_name', 'HP_name',\n",
    "                          '--debug_F1', 'True',])\n",
    "\n",
    "#                           '--src_names', 'UPFall_neck UPFall_wrist UPFall_belt UPFall_rightpocket UPFall_ankle',\n",
    "#                           '--tgt_names', 'UMAFall_chest UMAFall_wrist UMAFall_waist UMAFall_leg UMAFall_ankle'])\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = home+'/project_FDDAT/'\n",
    "input_folder = args.input_folder\n",
    "output_folder = args.output_folder\n",
    "training_params_file = args.training_params_file\n",
    "\n",
    "tasks_list = []\n",
    "for item in args.tasks_list.split(' '):\n",
    "    tasks_list.append((item.split('-')[0], item.split('-')[1]))\n",
    "    \n",
    "# src_domains = args.src_names.split(' ')\n",
    "# tgt_domains = args.tgt_names.split(' ')\n",
    "variable_name = args.variable_name\n",
    "\n",
    "if args.debug_F1=='True':\n",
    "    debug_F1 = True\n",
    "else:\n",
    "    debug_F1 = False\n",
    "\n",
    "\n",
    "inputdir = input_folder + '/'\n",
    "outputdir = output_folder + '/'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stage2/'+training_params_file) as json_file:\n",
    "    training_params_list = json.load(json_file)\n",
    "\n",
    "# TODO: need to fix once training_params_list is fixed\n",
    "# training_params_list.pop(-2)\n",
    "training_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_task_metric(df_temp, metric_name, outputdir):\n",
    "#     source_means = df_temp.loc['source',df_temp.columns != 'average'].apply(get_mean).values\n",
    "#     DANN_means = df_temp.loc['DANN',df_temp.columns != 'average'].apply(get_mean).values\n",
    "#     task_names = df_temp.columns[df_temp.columns != 'average']\n",
    "\n",
    "#     fig = plt.figure(figsize=(5, 5), dpi=dpi)\n",
    "#     ax = fig.add_subplot(1, 1, 1)\n",
    "#     ax.scatter(source_means, DANN_means, s=40, marker='o')\n",
    "#     ax_xlim = ax.get_xlim()\n",
    "#     ax_ylim = ax.get_ylim()\n",
    "#     ax.plot([0, 1], [0, 1], c=\".3\", linewidth=1, alpha=0.4)\n",
    "#     ax.set_title('{}'.format(metric_name.split('_')[1]), fontsize=20)\n",
    "#     ax.set_xlabel('source_means', fontsize=15)\n",
    "#     ax.set_ylabel('DANN_means', fontsize=15)   # relative to plt.rcParams['font.size']\n",
    "#     ax.set_xlim(min(ax_xlim[0], ax_ylim[0]), max(ax_xlim[1], ax_ylim[1]))\n",
    "#     ax.set_ylim(min(ax_xlim[0], ax_ylim[0]), max(ax_xlim[1], ax_ylim[1]))\n",
    "\n",
    "#     for i, txt in enumerate(task_names):\n",
    "#         ax.annotate(txt, (source_means[i], DANN_means[i]), fontsize=10, textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "#     fig.savefig(outputdir+'scatter_{}.png'.format(metric_name.split('_')[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric_keys = ['df_acc', 'df_sensitivity', 'df_precision', 'df_F1']\n",
    "metric_names = ['acc', 'sensitivity', 'precision', 'F1','PAD']\n",
    "training_setting_list = ['source', 'DANN', 'target', 'improvement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_task_name_list = []\n",
    "for training_params in training_params_list:\n",
    "#     dict_task_name_list.append('N_ch={}'.format(training_params['channel_n']))\n",
    "    dict_task_name_list.append(training_params['HP_name'])\n",
    "    training_params['rep_n'] = 5\n",
    "    training_params['CV_n'] = 5\n",
    "\n",
    "dict_task_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HP_name\\t\\tchannel_n')\n",
    "for training_params in training_params_list:\n",
    "    print('{}\\t\\t{}'.format(training_params['HP_name'], training_params['channel_n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_task_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_list = dict( zip(df_metric_keys,[[], [], [], []]))\n",
    "training_types = ['source','dann','target']\n",
    "\n",
    "dict_task_all = {}\n",
    "for task_item in tasks_list:\n",
    "    (src_name, tgt_name) = task_item\n",
    "    print(task_item)\n",
    "    \n",
    "    dict_list = []\n",
    "    for _ in range(len(dict_task_name_list)):\n",
    "        dict_list.append({}) \n",
    "    \n",
    "    \n",
    "    dict_task = dict( zip( dict_task_name_list,dict_list ) )\n",
    "\n",
    "    training_type = 'source'\n",
    "    for training_params in training_params_list:\n",
    "        df_list = []\n",
    "        for i_rep in range(training_params['rep_n']):\n",
    "            df_inputdir = inputdir+src_name+'_'+tgt_name+'/{}/{}/rep{}/df_performance.csv'.format(training_params['HP_name'],training_type,i_rep)\n",
    "            df = pd.read_csv(df_inputdir, index_col=0).iloc[0:training_params['CV_n']][['val_tgt_acc','val_tgt_sensitivity','val_tgt_precision','val_tgt_F1','PAD','total_loss']]\n",
    "            df = df.rename(columns={'val_tgt_acc':'acc','val_tgt_sensitivity':'sensitivity','val_tgt_precision':'precision','val_tgt_F1':'F1','total_loss':'loss'})\n",
    "            df_list.append(df)\n",
    "        \n",
    "        dict_task[training_params['HP_name']]['performance_{}'.format(training_type)] = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "    training_type = 'dann'\n",
    "    for training_params in training_params_list:\n",
    "        df_list = []\n",
    "        for i_rep in range(training_params['rep_n']):\n",
    "            df_inputdir = inputdir+src_name+'_'+tgt_name+'/{}/{}/rep{}/df_performance.csv'.format(training_params['HP_name'],training_type,i_rep)\n",
    "            df = pd.read_csv(df_inputdir, index_col=0).iloc[0:training_params['CV_n']][['val_tgt_acc','val_tgt_sensitivity','val_tgt_precision','val_tgt_F1','PAD','total_loss']]\n",
    "            df = df.rename(columns={'val_tgt_acc':'acc','val_tgt_sensitivity':'sensitivity','val_tgt_precision':'precision','val_tgt_F1':'F1','total_loss':'loss'})\n",
    "            df_list.append(df)\n",
    "\n",
    "        dict_task[training_params['HP_name']]['performance_{}'.format(training_type)] = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "\n",
    "    training_type = 'target'\n",
    "    for training_params in training_params_list:\n",
    "        df_list = []\n",
    "        for i_rep in range(training_params['rep_n']):\n",
    "            df_inputdir = inputdir+src_name+'_'+tgt_name+'/{}/{}/rep{}/df_performance.csv'.format(training_params['HP_name'],training_type,i_rep)\n",
    "            df = pd.read_csv(df_inputdir, index_col=0).iloc[0:training_params['CV_n']][['val_src_acc','val_src_sensitivity','val_src_precision','val_src_F1','PAD','total_loss']]\n",
    "            df = df.rename(columns={'val_src_acc':'acc','val_src_sensitivity':'sensitivity','val_src_precision':'precision','val_src_F1':'F1','total_loss':'loss'})\n",
    "            df_list.append(df)\n",
    "\n",
    "        dict_task[training_params['HP_name']]['performance_{}'.format(training_type)] = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "    dict_task_all[src_name+'_'+tgt_name] = dict_task        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {'Green': '#3cb44b', \n",
    "              'Sunglow': '#FFD43B',\n",
    "              'Red': '#e6194b', \n",
    "              'Blue': '#0082c8', \n",
    "\n",
    "              'Teal': '#008080', \n",
    "\n",
    "              'Maroon': '#800000', \n",
    "              'Navy': '#000080', \n",
    "              'Mint': '#aaffc3', \n",
    "              'Yellow': '#ffe119', \n",
    "\n",
    "              'Orange': '#f58231', \n",
    "              'Purple': '#911eb4', \n",
    "              'Cyan': '#46f0f0', \n",
    "              'Magenta': '#e6194b', \n",
    "              'Lime': '#d2f53c', \n",
    "              'Pink': '#fabebe', \n",
    "              'Lavender': '#e6beff', \n",
    "\n",
    "              'Brown': '#aa6e28', \n",
    "              'Mint': '#aaffc3', \n",
    "              'Olive': '#808000', \n",
    "              'Coral': '#ffd8b1',  \n",
    "              'Grey': '#808080', \n",
    "#               'Lavender': '#e6beff', \n",
    "             }\n",
    "colornames = list(color_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_metric = 'loss'\n",
    "\n",
    "def plot_metrics(task_name, metric_names, key, dict_task, variable_name, training_params_list, outputdir, plt_optimal=False):\n",
    "    fontsize_label = {\n",
    "        'subtitle': 20,\n",
    "        'axtitle': 17,\n",
    "        'xytitle': 17,\n",
    "        'annotate':6,\n",
    "    }\n",
    "    \n",
    "    dann_color = 'Blue'\n",
    "    tgt_color = 'Green'\n",
    "    \n",
    "    dict_task_HP = dict_task[key]\n",
    "    variable_value = next(training_params for training_params in training_params_list if training_params['HP_name'] == key)[variable_name]\n",
    "    \n",
    "    fig = plt.figure(figsize=(len(metric_names)*5, 5), dpi=100+len(metric_names)*5)\n",
    "    fig.suptitle('{}\\n({}={})'.format(task_name,variable_name,variable_value), fontsize=fontsize_label['subtitle'], y=1.12)\n",
    "\n",
    "    dann_mean_optimal_metric = dict_task_HP['performance_dann'][optimal_metric].values.mean()\n",
    "\n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        source_dpt = dict_task_HP['performance_source'][metric_name].values\n",
    "        dann_dpt = dict_task_HP['performance_dann'][metric_name].values\n",
    "        target_dpt = dict_task_HP['performance_target'][metric_name].values\n",
    "\n",
    "        ax = fig.add_subplot(1, len(metric_names), i+1)\n",
    "        ax.scatter(source_dpt, dann_dpt, s=40, marker='o', alpha=0.5, c=color_dict[dann_color])\n",
    "#         ax.set_xlabel('source({:.4f}±{:.4f})'.format(np.nanmean(source_dpt),np.nanstd(source_dpt)), fontsize=fontsize_label['xytitle'])\n",
    "#         ax.set_ylabel('DANN({:.4f}±{:.4f})'.format(np.nanmean(dann_dpt),np.nanstd(dann_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[dann_color])\n",
    "        ax.set_xlabel('source({:.4f}±{:.4f})'.format(np.mean(source_dpt),np.std(source_dpt)), fontsize=fontsize_label['xytitle'])\n",
    "        ax.set_ylabel('DANN({:.4f}±{:.4f})'.format(np.mean(dann_dpt),np.std(dann_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[dann_color])\n",
    "\n",
    "        ax_r = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax_r.scatter(source_dpt, target_dpt, s=40, marker='o', alpha=0.5, c=color_dict[tgt_color])\n",
    "#         ax_r.set_ylabel('target({:.4f}±{:.4f})'.format(np.nanmean(target_dpt),np.nanstd(target_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[tgt_color]) \n",
    "        ax_r.set_ylabel('target({:.4f}±{:.4f})'.format(np.mean(target_dpt),np.std(target_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[tgt_color]) \n",
    "\n",
    "        if metric_name == 'PAD':\n",
    "            ax_xlim = ax.get_xlim()\n",
    "            ax_ylim = ax.get_ylim()\n",
    "            ax_r_xlim = ax_r.get_xlim()\n",
    "            ax_r_ylim = ax_r.get_ylim()\n",
    "            x_min = min(ax_xlim+ax_r_xlim)\n",
    "            x_max = max(ax_xlim+ax_r_xlim)\n",
    "            y_min = min(ax_ylim+ax_r_ylim)\n",
    "            y_max = max(ax_ylim+ax_r_ylim)\n",
    "            ax.plot([x_min, x_max], [y_min, y_max], c=\".3\", linewidth=1, alpha=0.4)\n",
    "            ax.set_xlim(x_min,x_max)\n",
    "            ax.set_ylim(y_min,y_max)\n",
    "            ax_r.set_ylim(y_min,y_max)\n",
    "\n",
    "        else:\n",
    "            ax.plot([0, 1], [0, 1], c=\".3\", linewidth=1, alpha=0.4)\n",
    "            ax.set_xlim(0,1)\n",
    "            ax.set_ylim(0,1)\n",
    "            ax_r.set_ylim(0,1)\n",
    "        \n",
    "        for i in range(source_dpt.shape[0]):\n",
    "            ax.annotate(i, (source_dpt[i], dann_dpt[i]),alpha=0.9,fontsize=fontsize_label['annotate'], c=color_dict[dann_color])\n",
    "            ax_r.annotate(i, (source_dpt[i], target_dpt[i]),alpha=0.9,fontsize=fontsize_label['annotate'], c=color_dict[tgt_color])\n",
    "\n",
    "#         ax.set_title('{}({:+.4f} / {:+.4f})'.format(metric_name,np.nanmean(dann_dpt)-np.nanmean(source_dpt),np.nanmean(target_dpt)-np.nanmean(source_dpt)), fontsize=fontsize_label['axtitle'])\n",
    "        ax.set_title('{}({:+.4f} / {:+.4f})'.format(metric_name,np.mean(dann_dpt)-np.mean(source_dpt),np.mean(target_dpt)-np.mean(source_dpt)), fontsize=fontsize_label['axtitle'])\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig_folder = outputdir+task_name\n",
    "    if not os.path.exists(fig_folder):\n",
    "        os.makedirs(fig_folder)\n",
    "    if plt_optimal:\n",
    "        fig_dir = fig_folder+'/scatter_{}_optimal.png'.format(key)\n",
    "    else:\n",
    "        fig_dir = fig_folder+'/scatter_{}.png'.format(key)\n",
    "\n",
    "    fig.savefig(fig_dir, bbox_inches = \"tight\")\n",
    "\n",
    "    return dann_mean_optimal_metric, fig_dir\n",
    "\n",
    "\n",
    "\n",
    "for task_name, dict_task in dict_task_all.items():\n",
    "    dann_mean_optimal = 0\n",
    "    fig_dir_list = []\n",
    "    for key in dict_task.keys():\n",
    "        dann_mean, fig_dir = plot_metrics(task_name, ['F1'], key, dict_task, variable_name, training_params_list, outputdir)\n",
    "        if dann_mean_optimal > dann_mean: # find the lowest loss\n",
    "            dann_mean_optimal = dann_mean\n",
    "            key_optimal = key\n",
    "        fig_dir_list.append(fig_dir)\n",
    "\n",
    "    _, fig_dir = plot_metrics(task_name, ['F1'], key_optimal, dict_task, variable_name, training_params_list, outputdir, plt_optimal=True)\n",
    "    fig_dir_list.append(fig_dir)\n",
    "\n",
    "    aggregate_plots(fig_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_plots(fig_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_plots(fig_dir_list):\n",
    "    col_n = 8\n",
    "\n",
    "    images = [Image.open(x) for x in fig_dir_list]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = max(widths)*col_n\n",
    "    total_height = max(heights)*math.ceil(len(images)/col_n)\n",
    "    # max_height = max(heights)\n",
    "\n",
    "    # new_im = Image.new('RGB', (total_width, max_height))\n",
    "    fig_agg = Image.new('RGB', (total_width, total_height), (255, 255, 255, 0))\n",
    "\n",
    "    x_offset = 0\n",
    "    for i, im in enumerate(images):\n",
    "        x_offset = i%col_n\n",
    "        y_offset = math.floor(i/col_n)\n",
    "        fig_agg.paste(im, (x_offset*im.size[0],y_offset*im.size[1]))\n",
    "        \n",
    "    fig_agg.save(fig_dir_list[0].split('scatter')[0]+'HPsearch_agg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_checker_each(dict_task_HP):\n",
    "    for key in dict_task_HP.keys():\n",
    "        arr_sens = dict_task_HP[key]['sensitivity'].values\n",
    "        arr_prec = dict_task_HP[key]['precision'].values\n",
    "        arr_F1 = dict_task_HP[key]['F1'].values\n",
    "\n",
    "        test_F1 = 2*(arr_sens*arr_prec)/(arr_sens+arr_prec)\n",
    "        print('arr_sens:', arr_sens)\n",
    "        print('arr_prec:', arr_prec)\n",
    "        print('arr_F1:', arr_F1)\n",
    "        print('test_F1:', test_F1)\n",
    "        sys.exit()\n",
    "        if np.nansum(np.abs(test_F1-arr_F1)) > 0.00001:\n",
    "            print('***      F1 for a CV, a rep computed incorrectly in {}     ***'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_checker_mean(dict_df):\n",
    "    for column_name in dict_df['sensitivity'].columns.values:\n",
    "        for row_name in dict_df['sensitivity'].index.values:\n",
    "            float_sens = float(dict_df['sensitivity'].loc[row_name, column_name].split('±')[0])\n",
    "            float_prec = float(dict_df['precision'].loc[row_name, column_name].split('±')[0])\n",
    "            float_F1 = float(dict_df['F1'].loc[row_name, column_name].split('±')[0])\n",
    "\n",
    "            test_F1 = 2*(float_sens*float_prec)/(float_sens+float_prec)\n",
    "\n",
    "            if np.abs(float_F1-test_F1) > 0.00001:\n",
    "                print('***      mean F1 for all CV, all rep computed incorrectly in {}     ***'.format(key))\n",
    "                # # print('float_sens:', float_sens)\n",
    "                # # print('float_prec:', float_prec)\n",
    "                # # print('float_F1:', float_F1)\n",
    "                # # print('test_F1:', test_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_F1 = True\n",
    "\n",
    "dict_df_all = {}\n",
    "\n",
    "\n",
    "for task_name, dict_task in dict_task_all.items():\n",
    "    df = pd.DataFrame(columns=list(dict_task.keys()),index=['source','DANN','target'])\n",
    "    dict_df = dict( zip(metric_names,[df.copy(), df.copy(), df.copy(), df.copy(), df.copy()]))\n",
    "\n",
    "    for key in dict_task.keys():\n",
    "        dict_task_HP = dict_task[key]\n",
    "        \n",
    "        if debug_F1:\n",
    "            F1_checker_each(dict_task_HP)\n",
    "\n",
    "        for i, metric_name in enumerate(metric_names):\n",
    "            source_dpt = dict_task_HP['performance_source'][metric_name].values\n",
    "            dann_dpt = dict_task_HP['performance_dann'][metric_name].values\n",
    "            target_dpt = dict_task_HP['performance_target'][metric_name].values\n",
    "            \n",
    "            dict_df[metric_name].loc['source', key] = '{:.4f}±{:.4f}'.format(np.nanmean(source_dpt),np.nanstd(source_dpt))\n",
    "            dict_df[metric_name].loc['DANN', key] = '{:.4f}±{:.4f}'.format(np.nanmean(dann_dpt),np.nanstd(dann_dpt))\n",
    "            dict_df[metric_name].loc['target', key] = '{:.4f}±{:.4f}'.format(np.nanmean(target_dpt),np.nanstd(target_dpt))\n",
    "\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "    df_outputdir = outputdir+task_name\n",
    "    if not os.path.exists(df_outputdir):\n",
    "        os.makedirs(df_outputdir)\n",
    "        \n",
    "    writer = pd.ExcelWriter(df_outputdir+'/allmetrics.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        print(task_name, metric_name)\n",
    "        display(dict_df[metric_name])\n",
    "        dict_df[metric_name].to_excel(writer, sheet_name=metric_name)\n",
    "        \n",
    "        if debug_F1:\n",
    "            F1_checker_mean(dict_df)\n",
    "\n",
    "    writer.save()\n",
    "\n",
    "    dict_df_all[task_name] = dict_df.copy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpLLbTjGTbZ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9U8wu607JSd_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGazHVhBVcgi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9043,
     "status": "ok",
     "timestamp": 1583160936030,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "T-tecuc6VeSO",
    "outputId": "cb7a97f6-e894-4a5f-f6bf-46665460f9a2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1582718354886,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "HV0r2Gh0Vykf",
    "outputId": "cfb26497-8ab0-4b67-ba06-19b92c9bab5b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnK88jJ3kXd3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTuPZryA0XDr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BIaUPJ-0XBz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWcFYNkc1S12"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOgrts3TNOi6xV9nChueHe9",
   "collapsed_sections": [
    "bQTp--k3JmHs",
    "fomnNHfFG02o",
    "bfJv1bL3G38c"
   ],
   "name": "stage3_model_eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (FD_DAT)",
   "language": "python",
   "name": "fd_dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
