{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Isjqqa84yJv-"
   },
   "source": [
    "**stage3_model_eval**. This notebook evaluates the trained model\n",
    "\n",
    "**Edit**<br/>\n",
    "\n",
    "**TODO**<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1585238820612,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "dR0gs1Ya0xmy",
    "outputId": "7cd142ac-9bd4-44c1-db43-2b84b7e35cdf"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFk7y6uzVQ2s"
   },
   "source": [
    "# Get user inputs\n",
    "In ipython notebook, these are hardcoded. In production python code, use parsers to provide these inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Js2lmEUEVQ-G"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FD_DAT')\n",
    "parser.add_argument('--input_dir', metavar='input_dir', help='input_dir',\n",
    "                    default='../')\n",
    "parser.add_argument('--stage1_folder', metavar='stage1_folder', help='stage1_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--stage2_folder', metavar='stage2_folder', help='stage2_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--training_params_file', metavar='training_params_file', help='training_params_file',\n",
    "                    default='training_params_list.json')\n",
    "parser.add_argument('--tasks_list', metavar='tasks_list', help='a list of all tasks',\n",
    "                    default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "parser.add_argument('--variable_name', metavar='variable_name', help='key in training_params to be displayed on plot',\n",
    "                    default='HP_name')\n",
    "parser.add_argument('--debug_F1', metavar='debug_F1', help='debug F1',\n",
    "                    default='False')\n",
    "\n",
    "\n",
    "\n",
    "# parser.add_argument('--src_names', metavar='src_names', help='a list of src_names',\n",
    "#                     default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "# parser.add_argument('--tgt_names', metavar='tgt_names', help='a list of tgt_names',\n",
    "#                     default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "\n",
    "# checklist 2: comment first line, uncomment second line seizures_FN\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_diffCV',\n",
    "#                           '--output_folder', '../../data_mic/stage3/test',\n",
    "\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_WithoutNormal_18hz_5fold_UPFall_UMAFall_cross-config_diffCV',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_diffCV_earlystop',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/test',\n",
    "\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_HPsearch',\n",
    "args = parser.parse_args(['--input_dir', '../../Data/{}/ImpactWindow_Resample/18hz/{}/',\n",
    "                          '--stage1_folder', '../../data_mic/stage1/preprocessed_18hz_5fold',\n",
    "                          '--stage2_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_HPsearch', \n",
    "                          '--output_folder', '../../data_mic/stage3/test',\n",
    "                          '--training_params_file', 'training_params_list_HPsearch.json',\n",
    "#                           '--training_params_file', 'training_params_list_HPsearch.json',\n",
    "#                           '--tasks_list', 'UMAFall_chest-UPFall_neck UMAFall_wrist-UPFall_wrist UMAFall_waist-UPFall_belt UMAFall_leg-UPFall_rightpocket UMAFall_ankle-UPFall_ankle',\n",
    "                          '--tasks_list', 'UMAFall_chest-UPFall_neck UMAFall_leg-UPFall_rightpocket',\n",
    "                          '--variable_name', 'HP_name',])\n",
    "#                           '--debug_F1', 'True',])\n",
    "\n",
    "#                           '--src_names', 'UPFall_neck UPFall_wrist UPFall_belt UPFall_rightpocket UPFall_ankle',\n",
    "#                           '--tgt_names', 'UMAFall_chest UMAFall_wrist UMAFall_waist UMAFall_leg UMAFall_ankle'])\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_FDDAT/data_mic/stage2/modeloutput_18hz_5fold_UMAFall_cross-pos_loss_earlystop_HPsearch/UMAFall_ankle_UMAFall_chest/HP_24/source/rep1/class_out_diagnosis_CV4_epoch14.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = home+'/project_FDDAT/'\n",
    "input_dir = args.input_dir\n",
    "stage1_folder = args.stage1_folder\n",
    "stage2_folder = args.stage2_folder\n",
    "output_folder = args.output_folder\n",
    "training_params_file = args.training_params_file\n",
    "\n",
    "tasks_list = []\n",
    "for item in args.tasks_list.split(' '):\n",
    "    tasks_list.append((item.split('-')[0], item.split('-')[1]))\n",
    "    \n",
    "# src_domains = args.src_names.split(' ')\n",
    "# tgt_domains = args.tgt_names.split(' ')\n",
    "variable_name = args.variable_name\n",
    "\n",
    "# if args.debug_F1=='True':\n",
    "#     debug_F1 = True\n",
    "# else:\n",
    "#     debug_F1 = False\n",
    "\n",
    "\n",
    "inputdir_stage1 = stage1_folder + '/'\n",
    "inputdir_stage2 = stage2_folder + '/'\n",
    "outputdir = output_folder + '/'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../stage2/'+training_params_file) as json_file:\n",
    "#     training_params_list = json.load(json_file)\n",
    "\n",
    "# # TODO: need to fix once training_params_list is fixed\n",
    "# # training_params_list.pop(-2)\n",
    "# training_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_mode = 'dann'\n",
    "\n",
    "# src_name = 'UMAFall_ankle'\n",
    "# tgt_name = 'UPFall_ankle'\n",
    "\n",
    "# i_rep = 0\n",
    "# i_CV = 0\n",
    "# stage2_outdir = home+'/project_FDDAT/data_mic/stage2/test/{}_{}/HP_fixed/{}/rep{}/tgt_class_sigmoid_CV{}.npz'.format(src_name, tgt_name, training_mode, i_rep, i_CV)\n",
    "\n",
    "# tgt_class_output = np.load(stage2_outdir, allow_pickle=True)['data']\n",
    "# tgt_class_sigmoid = tgt_class_output[:,0]\n",
    "# tgt_DataNameList_idx = tgt_class_output[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_DataNameList_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_name = 'HP_22'\n",
    "# inputdir_stage2+'{}_{}/{}/rep{}/src_class_sigmoid_CV{}.npz'.format(src_name, tgt_name, HP_name, i_rep, i_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir_stage2.format(src_name.split('_')[0],tgt_name.split('_')[0])\n",
    "# src_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mode = 'dann'\n",
    "\n",
    "def get_df_DataNameList(data_name, input_dir):\n",
    "    sensor_loc = data_name.split('_')[1]\n",
    "    dataset_name = data_name.split('_')[0]\n",
    "\n",
    "    DataNameList_inputdir = input_dir+'IP_{}_DataNameList_{}.csv'\n",
    "    DataNameList_inputdir = DataNameList_inputdir.format(dataset_name, sensor_loc, dataset_name, sensor_loc)\n",
    "\n",
    "    impact_inputdir = input_dir.format(dataset_name, sensor_loc)\n",
    "\n",
    "    df_DataNameList = pd.read_csv(DataNameList_inputdir)\n",
    "    return df_DataNameList\n",
    "\n",
    "\n",
    "def get_model_output(src_name, tgt_name, training_mode, i_rep, i_CV):\n",
    "    HP_name = 'HP_0'\n",
    "    \n",
    "#     model_outputdir = inputdir_stage2.format(src_name.split('_')[0],tgt_name.split('_')[0])\n",
    "#     stage2_outdir = home+'/project_FDDAT/data_mic/stage2/test/{}_{}/HP_fixed/{}/rep{}/src_class_sigmoid_CV{}.npz'.format(src_name, tgt_name, training_mode, i_rep, i_CV)\n",
    "    stage2_outdir = inputdir_stage2+'{}_{}/{}/{}/rep{}/src_class_sigmoid_CV{}.npz'.format(src_name, tgt_name, HP_name, training_mode, i_rep, i_CV)\n",
    "    model_output_src = np.load(stage2_outdir, allow_pickle=True)['data']\n",
    "\n",
    "#     stage2_outdir = home+'/project_FDDAT/data_mic/stage2/test/{}_{}/HP_fixed/{}/rep{}/tgt_class_sigmoid_CV{}.npz'.format(src_name, tgt_name, training_mode, i_rep, i_CV)\n",
    "    stage2_outdir = inputdir_stage2+'{}_{}/{}/{}/rep{}/tgt_class_sigmoid_CV{}.npz'.format(src_name, tgt_name, HP_name, training_mode, i_rep, i_CV)\n",
    "    model_output_tgt = np.load(stage2_outdir, allow_pickle=True)['data']\n",
    "    \n",
    "    return model_output_src, model_output_tgt\n",
    "\n",
    "def df_DataNameList_expand(i_rep, i_CV, df_DataNameList, DataNameList_idx, class_sigmoid):\n",
    "    col_name = 'rep{}_CV{}'.format(i_rep, i_CV)\n",
    "    df_DataNameList[col_name] = ''\n",
    "    df_DataNameList.loc[DataNameList_idx, [col_name]] = class_sigmoid\n",
    "    return df_DataNameList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "src_name = tasks_list[0][0]\n",
    "tgt_name = tasks_list[0][1]\n",
    "\n",
    "i_rep = 0\n",
    "i_CV = 0\n",
    "\n",
    "df_DataNameList_src = get_df_DataNameList(src_name, input_dir)\n",
    "df_DataNameList_tgt = get_df_DataNameList(tgt_name, input_dir)\n",
    "\n",
    "for i_rep in range(5):\n",
    "    for i_CV in range(5):\n",
    "        model_output_src, model_output_tgt = get_model_output(src_name, tgt_name, training_mode, i_rep, i_CV)\n",
    "        class_sigmoid_src = model_output_src[:,0]\n",
    "        DataNameList_idx_src = model_output_src[:,1]\n",
    "        class_sigmoid_tgt = model_output_tgt[:,0]\n",
    "        DataNameList_idx_tgt = model_output_tgt[:,1]\n",
    "        \n",
    "        df_DataNameList_src = df_DataNameList_expand(i_rep, i_CV, df_DataNameList_src, DataNameList_idx_src, class_sigmoid_src)\n",
    "        df_DataNameList_tgt = df_DataNameList_expand(i_rep, i_CV, df_DataNameList_tgt, DataNameList_idx_tgt, class_sigmoid_tgt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_DataNameList_src)\n",
    "\n",
    "df_DataNameList_src.to_csv(\"df_DataNameList_src.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_inputdir = inputdir + '{}/{}/rep{}/'.format(src_name.split('_')[0], src_name.split('_')[1], i_rep)\n",
    "tgt_inputdir = inputdir + '{}/{}/rep{}/'.format(tgt_name.split('_')[0], tgt_name.split('_')[1], i_rep)\n",
    "\n",
    "\n",
    "\n",
    "# for i_CV in range(CV_n):\n",
    "i_CV = 0\n",
    "print('------------------------------Working on i_CV {}------------------------------'.format(i_CV))\n",
    "# 1. prepare dataset\n",
    "\n",
    "batch_size = training_params['batch_size']\n",
    "learning_rate = training_params['learning_rate']\n",
    "training_params['use_WeightedRandomSampler'] = False\n",
    "src_train_loader, src_val_loader, src_train_loader_eval = get_data_loader(src_inputdir, i_CV, batch_size, learning_rate, training_params)\n",
    "tgt_train_loader, tgt_val_loader, tgt_train_loader_eval = get_data_loader(tgt_inputdir, i_CV, batch_size, learning_rate, training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_val_loader.dataset.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5), dpi=80)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# ax.plot(tgt_class_sigmoid[:,0],'.b', label='src_domain_sigmoid', markersize=3)\n",
    "\n",
    "\n",
    "# ax3 = fig.add_subplot(4, 2, ax_idx[2])\n",
    "ax.plot(tgt_class_sigmoid[:,0],'.b', label='tgt_class_sigmoid', markersize=3)\n",
    "ax.plot(tgt_class_sigmoid[:,0].round(),'b', alpha=0.5, label='tgt_class_decision')\n",
    "ax.plot(tgt_val_loader.dataset.labels,'r', alpha=0.5, label='tgt_class_labels')\n",
    "# ax3.set_title('tgt_class_sigmoid (adl=0, fall=1)')\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_class_sigmoid[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOgrts3TNOi6xV9nChueHe9",
   "collapsed_sections": [
    "bQTp--k3JmHs",
    "fomnNHfFG02o",
    "bfJv1bL3G38c"
   ],
   "name": "stage3_model_eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (FD_DAT)",
   "language": "python",
   "name": "fd_dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
