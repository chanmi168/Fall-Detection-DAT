{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Isjqqa84yJv-"
   },
   "source": [
    "**stage3_model_eval**. This notebook evaluates the trained model\n",
    "\n",
    "**Edit**<br/>\n",
    "\n",
    "**TODO**<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1585238820612,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "dR0gs1Ya0xmy",
    "outputId": "7cd142ac-9bd4-44c1-db43-2b84b7e35cdf"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFk7y6uzVQ2s"
   },
   "source": [
    "# Get user inputs\n",
    "In ipython notebook, these are hardcoded. In production python code, use parsers to provide these inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Js2lmEUEVQ-G"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FD_DAT')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--training_params_file', metavar='training_params_file', help='training_params_file',\n",
    "                    default='training_params_list.json')\n",
    "parser.add_argument('--tasks_list', metavar='tasks_list', help='a list of all tasks',\n",
    "                    default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "parser.add_argument('--variable_name', metavar='variable_name', help='key in training_params to be displayed on plot',\n",
    "                    default='HP_name')\n",
    "parser.add_argument('--debug_F1', metavar='debug_F1', help='debug F1',\n",
    "                    default='False')\n",
    "\n",
    "\n",
    "\n",
    "# parser.add_argument('--src_names', metavar='src_names', help='a list of src_names',\n",
    "#                     default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "# parser.add_argument('--tgt_names', metavar='tgt_names', help='a list of tgt_names',\n",
    "#                     default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "\n",
    "# checklist 2: comment first line, uncomment second line seizures_FN\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_diffCV',\n",
    "#                           '--output_folder', '../../data_mic/stage3/test',\n",
    "\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_WithoutNormal_18hz_5fold_UPFall_UMAFall_cross-config_diffCV',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_diffCV_earlystop',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/test',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UPFall_UMAFall_cross-config_HPsearch',\n",
    "#                           '--output_folder', '../../data_mic/stage3/test',\n",
    "# #                           '--training_params_file', 'training_params_list_fixed.json',\n",
    "#                           '--training_params_file', 'training_params_list_HPsearch.json',\n",
    "# #                           '--tasks_list', 'UMAFall_chest-UPFall_neck UMAFall_wrist-UPFall_wrist UMAFall_waist-UPFall_belt UMAFall_leg-UPFall_rightpocket UMAFall_ankle-UPFall_ankle',\n",
    "#                           '--tasks_list', 'UMAFall_chest-UPFall_neck UMAFall_leg-UPFall_rightpocket',\n",
    "#                           '--variable_name', 'HP_name',\n",
    "#                           '--debug_F1', 'True',])\n",
    "\n",
    "args = parser.parse_args(['--input_folder', '../../data_mic/stage2/modeloutput_18hz_5fold_UMAFall_cross-pos_loss_earlystop_revision',\n",
    "                          '--output_folder', '../../data_mic/stage3/UMAFall_cross-pos_loss_earlystop_revision',\n",
    "#                           '--training_params_file', 'training_params_list_fixed.json',\n",
    "                          '--training_params_file', 'training_params_list_fixed_revision.json',\n",
    "#                           '--tasks_list', 'UMAFall_chest-UPFall_neck UMAFall_wrist-UPFall_wrist UMAFall_waist-UPFall_belt UMAFall_leg-UPFall_rightpocket UMAFall_ankle-UPFall_ankle',\n",
    "                          '--tasks_list', 'UMAFall_chest-UMAFall_waist UMAFall_chest-UMAFall_wrist UMAFall_chest-UMAFall_ankle UMAFall_waist-UMAFall_wrist UMAFall_waist-UMAFall_ankle UMAFall_waist-UMAFall_chest UMAFall_wrist-UMAFall_ankle UMAFall_wrist-UMAFall_waist UMAFall_wrist-UMAFall_chest UMAFall_ankle-UMAFall_chest UMAFall_ankle-UMAFall_waist UMAFall_ankle-UMAFall_wrist',\n",
    "                          '--variable_name', 'HP_name',\n",
    "                          '--debug_F1', 'True',])\n",
    "\n",
    "#                           '--src_names', 'UPFall_neck UPFall_wrist UPFall_belt UPFall_rightpocket UPFall_ankle',\n",
    "#                           '--tgt_names', 'UMAFall_chest UMAFall_wrist UMAFall_waist UMAFall_leg UMAFall_ankle'])\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = home+'/project_FDDAT/'\n",
    "input_folder = args.input_folder\n",
    "output_folder = args.output_folder\n",
    "training_params_file = args.training_params_file\n",
    "\n",
    "tasks_list = []\n",
    "for item in args.tasks_list.split(' '):\n",
    "    tasks_list.append((item.split('-')[0], item.split('-')[1]))\n",
    "    \n",
    "# src_domains = args.src_names.split(' ')\n",
    "# tgt_domains = args.tgt_names.split(' ')\n",
    "variable_name = args.variable_name\n",
    "\n",
    "if args.debug_F1=='True':\n",
    "    debug_F1 = True\n",
    "else:\n",
    "    debug_F1 = False\n",
    "\n",
    "\n",
    "inputdir = input_folder + '/'\n",
    "outputdir = output_folder + '/'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data_mic/stage3/UMAFall_cross-pos_loss_earlystop_revision/'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'HP_name': 'HP_fixed',\n",
       "  'classes_n': 2,\n",
       "  'channel_n': 4,\n",
       "  'batch_size': 4,\n",
       "  'learning_rate': 0.001,\n",
       "  'λ': 1,\n",
       "  'dropout': 0.5,\n",
       "  'show_diagnosis_plt': True,\n",
       "  'use_WeightedRandomSampler': True,\n",
       "  'ADL_only': True}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../stage2/'+training_params_file) as json_file:\n",
    "    training_params_list = json.load(json_file)\n",
    "\n",
    "# TODO: need to fix once training_params_list is fixed\n",
    "# training_params_list.pop(-2)\n",
    "training_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_task_metric(df_temp, metric_name, outputdir):\n",
    "#     source_means = df_temp.loc['source',df_temp.columns != 'average'].apply(get_mean).values\n",
    "#     DANN_means = df_temp.loc['DANN',df_temp.columns != 'average'].apply(get_mean).values\n",
    "#     task_names = df_temp.columns[df_temp.columns != 'average']\n",
    "\n",
    "#     fig = plt.figure(figsize=(5, 5), dpi=dpi)\n",
    "#     ax = fig.add_subplot(1, 1, 1)\n",
    "#     ax.scatter(source_means, DANN_means, s=40, marker='o')\n",
    "#     ax_xlim = ax.get_xlim()\n",
    "#     ax_ylim = ax.get_ylim()\n",
    "#     ax.plot([0, 1], [0, 1], c=\".3\", linewidth=1, alpha=0.4)\n",
    "#     ax.set_title('{}'.format(metric_name.split('_')[1]), fontsize=20)\n",
    "#     ax.set_xlabel('source_means', fontsize=15)\n",
    "#     ax.set_ylabel('DANN_means', fontsize=15)   # relative to plt.rcParams['font.size']\n",
    "#     ax.set_xlim(min(ax_xlim[0], ax_ylim[0]), max(ax_xlim[1], ax_ylim[1]))\n",
    "#     ax.set_ylim(min(ax_xlim[0], ax_ylim[0]), max(ax_xlim[1], ax_ylim[1]))\n",
    "\n",
    "#     for i, txt in enumerate(task_names):\n",
    "#         ax.annotate(txt, (source_means[i], DANN_means[i]), fontsize=10, textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "#     fig.savefig(outputdir+'scatter_{}.png'.format(metric_name.split('_')[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric_keys = ['df_acc', 'df_sensitivity', 'df_precision', 'df_F1']\n",
    "# metric_names = ['acc', 'sensitivity', 'precision', 'F1','PAD']\n",
    "metric_names = ['sensitivity', 'specificity', 'precision', 'F1','PAD']\n",
    "training_setting_list = ['source', 'DANN', 'target', 'improvement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HP_fixed']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_task_name_list = []\n",
    "for training_params in training_params_list:\n",
    "#     dict_task_name_list.append('N_ch={}'.format(training_params['channel_n']))\n",
    "    dict_task_name_list.append(training_params['HP_name'])\n",
    "    training_params['rep_n'] = 5\n",
    "    training_params['CV_n'] = 5\n",
    "\n",
    "dict_task_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP_name\t\tchannel_n\n",
      "HP_fixed\t\t4\n"
     ]
    }
   ],
   "source": [
    "print('HP_name\\t\\tchannel_n')\n",
    "for training_params in training_params_list:\n",
    "    print('{}\\t\\t{}'.format(training_params['HP_name'], training_params['channel_n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UMAFall_chest', 'UMAFall_waist')\n",
      "('UMAFall_chest', 'UMAFall_wrist')\n",
      "('UMAFall_chest', 'UMAFall_ankle')\n",
      "('UMAFall_waist', 'UMAFall_wrist')\n",
      "('UMAFall_waist', 'UMAFall_ankle')\n",
      "('UMAFall_waist', 'UMAFall_chest')\n",
      "('UMAFall_wrist', 'UMAFall_ankle')\n",
      "('UMAFall_wrist', 'UMAFall_waist')\n",
      "('UMAFall_wrist', 'UMAFall_chest')\n",
      "('UMAFall_ankle', 'UMAFall_chest')\n",
      "('UMAFall_ankle', 'UMAFall_waist')\n",
      "('UMAFall_ankle', 'UMAFall_wrist')\n"
     ]
    }
   ],
   "source": [
    "df_task_list = dict( zip(df_metric_keys,[[], [], [], []]))\n",
    "training_types = ['source','dann','target']\n",
    "\n",
    "dict_task_all = {}\n",
    "for task_item in tasks_list:\n",
    "    (src_name, tgt_name) = task_item\n",
    "    print(task_item)\n",
    "    \n",
    "    dict_list = []\n",
    "    for _ in range(len(dict_task_name_list)):\n",
    "        dict_list.append({}) \n",
    "    \n",
    "    dict_task = dict( zip( dict_task_name_list,dict_list ) )\n",
    "\n",
    "    try:\n",
    "        training_type = 'source'\n",
    "        for training_params in training_params_list:\n",
    "            df_list = []\n",
    "            for i_rep in range(training_params['rep_n']):\n",
    "                df_inputdir = inputdir+src_name+'_'+tgt_name+'/{}/{}/rep{}/df_performance.csv'.format(training_params['HP_name'],training_type,i_rep)\n",
    "                df = pd.read_csv(df_inputdir, index_col=0).iloc[0:training_params['CV_n']][['val_tgt_acc','val_tgt_sensitivity','val_tgt_precision','val_tgt_F1','PAD','total_loss']]\n",
    "                df = df.rename(columns={'val_tgt_acc':'acc','val_tgt_sensitivity':'sensitivity','val_tgt_precision':'precision','val_tgt_F1':'F1','total_loss':'loss'})\n",
    "                df_list.append(df)\n",
    "\n",
    "            dict_task[training_params['HP_name']]['performance_{}'.format(training_type)] = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "        training_type = 'dann'\n",
    "        for training_params in training_params_list:\n",
    "            df_list = []\n",
    "            for i_rep in range(training_params['rep_n']):\n",
    "                df_inputdir = inputdir+src_name+'_'+tgt_name+'/{}/{}/rep{}/df_performance.csv'.format(training_params['HP_name'],training_type,i_rep)\n",
    "                df = pd.read_csv(df_inputdir, index_col=0).iloc[0:training_params['CV_n']][['val_tgt_acc','val_tgt_sensitivity','val_tgt_precision','val_tgt_F1','PAD','total_loss']]\n",
    "                df = df.rename(columns={'val_tgt_acc':'acc','val_tgt_sensitivity':'sensitivity','val_tgt_precision':'precision','val_tgt_F1':'F1','total_loss':'loss'})\n",
    "                df_list.append(df)\n",
    "\n",
    "            dict_task[training_params['HP_name']]['performance_{}'.format(training_type)] = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "        training_type = 'target'\n",
    "        for training_params in training_params_list:\n",
    "            df_list = []\n",
    "            for i_rep in range(training_params['rep_n']):\n",
    "                df_inputdir = inputdir+src_name+'_'+tgt_name+'/{}/{}/rep{}/df_performance.csv'.format(training_params['HP_name'],training_type,i_rep)\n",
    "                df = pd.read_csv(df_inputdir, index_col=0).iloc[0:training_params['CV_n']][['val_src_acc','val_src_sensitivity','val_src_precision','val_src_F1','PAD','total_loss']]\n",
    "                df = df.rename(columns={'val_src_acc':'acc','val_src_sensitivity':'sensitivity','val_src_precision':'precision','val_src_F1':'F1','total_loss':'loss'})\n",
    "                df_list.append(df)\n",
    "\n",
    "            dict_task[training_params['HP_name']]['performance_{}'.format(training_type)] = pd.concat(df_list,ignore_index=True)\n",
    "\n",
    "        dict_task_all[src_name+'_'+tgt_name] = dict_task\n",
    "        \n",
    "    except:\n",
    "        print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>PAD</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.944814</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>1.996108</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.858093</td>\n",
       "      <td>0.000190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.922075</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>1.957799</td>\n",
       "      <td>0.001585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc  sensitivity  precision       F1      PAD     loss\n",
       "0 0.975000     0.939394   1.000000 0.968750 1.944814 0.000839\n",
       "1 0.981250     1.000000   0.953846 0.976378 1.996108 0.000327\n",
       "2 1.000000     1.000000   1.000000 1.000000 1.858093 0.000190\n",
       "3 1.000000     1.000000   1.000000 1.000000 1.922075 0.000311\n",
       "4 0.920000     0.828571   1.000000 0.906250 1.957799 0.001585"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['UMAFall_chest_UMAFall_waist', 'UMAFall_chest_UMAFall_wrist', 'UMAFall_chest_UMAFall_ankle', 'UMAFall_waist_UMAFall_wrist', 'UMAFall_waist_UMAFall_ankle', 'UMAFall_waist_UMAFall_chest', 'UMAFall_wrist_UMAFall_ankle', 'UMAFall_wrist_UMAFall_waist', 'UMAFall_wrist_UMAFall_chest', 'UMAFall_ankle_UMAFall_chest', 'UMAFall_ankle_UMAFall_waist', 'UMAFall_ankle_UMAFall_wrist'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_task_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {'Green': '#3cb44b', \n",
    "              'Sunglow': '#FFD43B',\n",
    "              'Red': '#e6194b', \n",
    "              'Blue': '#0082c8', \n",
    "\n",
    "              'Teal': '#008080', \n",
    "\n",
    "              'Maroon': '#800000', \n",
    "              'Navy': '#000080', \n",
    "              'Mint': '#aaffc3', \n",
    "              'Yellow': '#ffe119', \n",
    "\n",
    "              'Orange': '#f58231', \n",
    "              'Purple': '#911eb4', \n",
    "              'Cyan': '#46f0f0', \n",
    "              'Magenta': '#e6194b', \n",
    "              'Lime': '#d2f53c', \n",
    "              'Pink': '#fabebe', \n",
    "              'Lavender': '#e6beff', \n",
    "\n",
    "              'Brown': '#aa6e28', \n",
    "              'Mint': '#aaffc3', \n",
    "              'Olive': '#808000', \n",
    "              'Coral': '#ffd8b1',  \n",
    "              'Grey': '#808080', \n",
    "#               'Lavender': '#e6beff', \n",
    "             }\n",
    "colornames = list(color_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_plots(fig_dir_list):\n",
    "    col_n = 8\n",
    "\n",
    "    images = [Image.open(x) for x in fig_dir_list]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = max(widths)*col_n\n",
    "    total_height = max(heights)*math.ceil(len(images)/col_n)\n",
    "    # max_height = max(heights)\n",
    "\n",
    "    # new_im = Image.new('RGB', (total_width, max_height))\n",
    "    fig_agg = Image.new('RGB', (total_width, total_height), (255, 255, 255, 0))\n",
    "\n",
    "    x_offset = 0\n",
    "    for i, im in enumerate(images):\n",
    "        x_offset = i%col_n\n",
    "        y_offset = math.floor(i/col_n)\n",
    "        fig_agg.paste(im, (x_offset*im.size[0],y_offset*im.size[1]))\n",
    "        \n",
    "    fig_agg.save(fig_dir_list[0].split('scatter')[0]+'HPsearch_agg.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_metric = 'F1'\n",
    "optimal_metric = 'loss'\n",
    "display_metric = ['F1']\n",
    "\n",
    "def plot_metrics(task_name, metric_names, key, dict_task, variable_name, training_params_list, outputdir, plt_optimal=False):\n",
    "    fontsize_label = {\n",
    "        'subtitle': 20,\n",
    "        'axtitle': 17,\n",
    "        'xytitle': 17,\n",
    "        'annotate':6,\n",
    "    }\n",
    "    \n",
    "    dann_color = 'Blue'\n",
    "    tgt_color = 'Green'\n",
    "    \n",
    "    dict_task_HP = dict_task[key]\n",
    "    variable_value = next(training_params for training_params in training_params_list if training_params['HP_name'] == key)[variable_name]\n",
    "    \n",
    "    fig = plt.figure(figsize=(len(metric_names)*5, 5), dpi=100+len(metric_names)*5)\n",
    "    fig.suptitle('{}\\n({}={})'.format(task_name,variable_name,variable_value), fontsize=fontsize_label['subtitle'], y=1.12)\n",
    "\n",
    "    dann_mean_optimal_metric = dict_task_HP['performance_dann'][optimal_metric].values.mean()\n",
    "\n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        source_dpt = dict_task_HP['performance_source'][metric_name].values\n",
    "        dann_dpt = dict_task_HP['performance_dann'][metric_name].values\n",
    "#         display(dict_task_HP['performance_dann'])\n",
    "#         sys.exit()\n",
    "        target_dpt = dict_task_HP['performance_target'][metric_name].values\n",
    "\n",
    "        ax = fig.add_subplot(1, len(metric_names), i+1)\n",
    "        ax.scatter(source_dpt, dann_dpt, s=40, marker='o', alpha=0.5, c=color_dict[dann_color])\n",
    "#         ax.set_xlabel('source({:.4f}±{:.4f})'.format(np.nanmean(source_dpt),np.nanstd(source_dpt)), fontsize=fontsize_label['xytitle'])\n",
    "#         ax.set_ylabel('DANN({:.4f}±{:.4f})'.format(np.nanmean(dann_dpt),np.nanstd(dann_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[dann_color])\n",
    "        ax.set_xlabel('source({:.4f}±{:.4f})'.format(np.mean(source_dpt),np.std(source_dpt)), fontsize=fontsize_label['xytitle'])\n",
    "        ax.set_ylabel('DANN({:.4f}±{:.4f})'.format(np.mean(dann_dpt),np.std(dann_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[dann_color])\n",
    "\n",
    "        ax_r = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax_r.scatter(source_dpt, target_dpt, s=40, marker='o', alpha=0.5, c=color_dict[tgt_color])\n",
    "#         ax_r.set_ylabel('target({:.4f}±{:.4f})'.format(np.nanmean(target_dpt),np.nanstd(target_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[tgt_color]) \n",
    "        ax_r.set_ylabel('target({:.4f}±{:.4f})'.format(np.mean(target_dpt),np.std(target_dpt)), fontsize=fontsize_label['xytitle'], c=color_dict[tgt_color]) \n",
    "\n",
    "        if metric_name == 'PAD':\n",
    "            ax_xlim = ax.get_xlim()\n",
    "            ax_ylim = ax.get_ylim()\n",
    "            ax_r_xlim = ax_r.get_xlim()\n",
    "            ax_r_ylim = ax_r.get_ylim()\n",
    "            x_min = min(ax_xlim+ax_r_xlim)\n",
    "            x_max = max(ax_xlim+ax_r_xlim)\n",
    "            y_min = min(ax_ylim+ax_r_ylim)\n",
    "            y_max = max(ax_ylim+ax_r_ylim)\n",
    "            ax.plot([x_min, x_max], [y_min, y_max], c=\".3\", linewidth=1, alpha=0.4)\n",
    "            ax.set_xlim(x_min,x_max)\n",
    "            ax.set_ylim(y_min,y_max)\n",
    "            ax_r.set_ylim(y_min,y_max)\n",
    "\n",
    "        else:\n",
    "            ax.plot([0, 1], [0, 1], c=\".3\", linewidth=1, alpha=0.4)\n",
    "            ax.set_xlim(0,1)\n",
    "            ax.set_ylim(0,1)\n",
    "            ax_r.set_ylim(0,1)\n",
    "        \n",
    "        for i in range(source_dpt.shape[0]):\n",
    "            ax.annotate(i, (source_dpt[i], dann_dpt[i]),alpha=0.9,fontsize=fontsize_label['annotate'], c=color_dict[dann_color])\n",
    "            ax_r.annotate(i, (source_dpt[i], target_dpt[i]),alpha=0.9,fontsize=fontsize_label['annotate'], c=color_dict[tgt_color])\n",
    "\n",
    "#         ax.set_title('{}({:+.4f} / {:+.4f})'.format(metric_name,np.nanmean(dann_dpt)-np.nanmean(source_dpt),np.nanmean(target_dpt)-np.nanmean(source_dpt)), fontsize=fontsize_label['axtitle'])\n",
    "        ax.set_title('{}({:+.4f} / {:+.4f})'.format(metric_name,np.mean(dann_dpt)-np.mean(source_dpt),np.mean(target_dpt)-np.mean(source_dpt)), fontsize=fontsize_label['axtitle'])\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig_folder = outputdir+task_name\n",
    "    if not os.path.exists(fig_folder):\n",
    "        os.makedirs(fig_folder)\n",
    "    if plt_optimal:\n",
    "        fig_dir = fig_folder+'/scatter_{}_optimal.png'.format(key)\n",
    "    else:\n",
    "        fig_dir = fig_folder+'/scatter_{}.png'.format(key)\n",
    "\n",
    "    fig.savefig(fig_dir, bbox_inches = \"tight\")\n",
    "    pyplot.close(fig)\n",
    "\n",
    "    return dann_mean_optimal_metric, fig_dir\n",
    "\n",
    "\n",
    "for task_name, dict_task in dict_task_all.items():\n",
    "    if optimal_metric == 'loss':\n",
    "        dann_mean_optimal = 100000\n",
    "    elif optimal_metric == 'F1':\n",
    "        dann_mean_optimal = 0\n",
    "    fig_dir_list = []\n",
    "    for key in dict_task.keys():\n",
    "        dann_mean, fig_dir = plot_metrics(task_name, display_metric, key, dict_task, variable_name, training_params_list, outputdir)\n",
    "        if (optimal_metric=='loss' and dann_mean_optimal>dann_mean) or (optimal_metric=='F1' and dann_mean_optimal<dann_mean): # find the lowest loss\n",
    "            dann_mean_optimal = dann_mean\n",
    "            key_optimal = key\n",
    "        fig_dir_list.append(fig_dir)\n",
    "\n",
    "    _, fig_dir = plot_metrics(task_name, display_metric, key_optimal, dict_task, variable_name, training_params_list, outputdir, plt_optimal=True)\n",
    "    fig_dir_list.append(fig_dir)\n",
    "\n",
    "    aggregate_plots(fig_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_checker_each(dict_task_HP):\n",
    "    for key in dict_task_HP.keys():\n",
    "        arr_sens = dict_task_HP[key]['sensitivity'].values\n",
    "        arr_prec = dict_task_HP[key]['precision'].values\n",
    "        arr_F1 = dict_task_HP[key]['F1'].values\n",
    "\n",
    "        test_F1 = 2*(arr_sens*arr_prec)/(arr_sens+arr_prec)\n",
    "        print('arr_sens:', arr_sens)\n",
    "        print('arr_prec:', arr_prec)\n",
    "        print('arr_F1:', arr_F1)\n",
    "        print('test_F1:', test_F1)\n",
    "#         sys.exit()\n",
    "        if np.nansum(np.abs(test_F1-arr_F1)) > 0.00001:\n",
    "            print('***      F1 for a CV, a rep computed incorrectly in {}     ***'.format(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_checker_mean(dict_df):\n",
    "    for column_name in dict_df['sensitivity'].columns.values:\n",
    "        for row_name in dict_df['sensitivity'].index.values:\n",
    "            float_sens = float(dict_df['sensitivity'].loc[row_name, column_name].split('±')[0])\n",
    "            float_prec = float(dict_df['precision'].loc[row_name, column_name].split('±')[0])\n",
    "            float_F1 = float(dict_df['F1'].loc[row_name, column_name].split('±')[0])\n",
    "\n",
    "            test_F1 = 2*(float_sens*float_prec)/(float_sens+float_prec)\n",
    "\n",
    "            if np.abs(float_F1-test_F1) > 0.00001:\n",
    "                print('***      mean F1 for all CV, all rep computed incorrectly in {}     ***'.format(key))\n",
    "                # # print('float_sens:', float_sens)\n",
    "                # # print('float_prec:', float_prec)\n",
    "                # # print('float_F1:', float_F1)\n",
    "                # # print('test_F1:', test_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_sens: [0.97560976 0.92307692 0.81481481 0.96428571 1.         0.94444444\n",
      " 1.         0.97142857 1.         0.95081967 1.         0.89534884\n",
      " 0.88888889 1.         1.         1.         1.         1.\n",
      " 1.         0.88888889 0.93939394 0.91935484 1.         0.92592593\n",
      " 1.        ]\n",
      "arr_prec: [1.         1.         1.         1.         1.         1.\n",
      " 0.96774194 0.97142857 1.         1.         0.96       0.97468354\n",
      " 1.         0.92       0.95238095 1.         0.97222222 0.98550725\n",
      " 1.         0.94117647 1.         1.         1.         0.96153846\n",
      " 0.97222222]\n",
      "arr_F1: [0.98765432 0.96       0.89795918 0.98181818 1.         0.97142857\n",
      " 0.98360656 0.97142857 1.         0.97478992 0.97959184 0.93333333\n",
      " 0.94117647 0.95833333 0.97560976 1.         0.98591549 0.99270073\n",
      " 1.         0.91428571 0.96875    0.95798319 1.         0.94339623\n",
      " 0.98591549]\n",
      "test_F1: [0.98765432 0.96       0.89795918 0.98181818 1.         0.97142857\n",
      " 0.98360656 0.97142857 1.         0.97478992 0.97959184 0.93333333\n",
      " 0.94117647 0.95833333 0.97560976 1.         0.98591549 0.99270073\n",
      " 1.         0.91428571 0.96875    0.95798319 1.         0.94339623\n",
      " 0.98591549]\n",
      "arr_sens: [1.         0.8974359  0.88888889 0.96428571 1.         1.\n",
      " 0.8        0.91428571 1.         1.         1.         1.\n",
      " 0.81481481 1.         0.95       0.48780488 1.         0.98529412\n",
      " 1.         0.66666667 0.93939394 0.93548387 1.         1.\n",
      " 0.54285714]\n",
      "arr_prec: [0.97619048 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.96       0.98850575\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.98305085 1.         0.96428571\n",
      " 1.        ]\n",
      "arr_F1: [0.98795181 0.94594595 0.94117647 0.98181818 1.         1.\n",
      " 0.88888889 0.95522388 1.         1.         0.97959184 0.99421965\n",
      " 0.89795918 1.         0.97435897 0.6557377  1.         0.99259259\n",
      " 1.         0.8        0.96875    0.95867769 1.         0.98181818\n",
      " 0.7037037 ]\n",
      "test_F1: [0.98795181 0.94594595 0.94117647 0.98181818 1.         1.\n",
      " 0.88888889 0.95522388 1.         1.         0.97959184 0.99421965\n",
      " 0.89795918 1.         0.97435897 0.6557377  1.         0.99259259\n",
      " 1.         0.8        0.96875    0.95867769 1.         0.98181818\n",
      " 0.7037037 ]\n",
      "arr_sens: [1.         1.         0.81481481 1.         1.         1.\n",
      " 0.96666667 0.94285714 1.         1.         1.         1.\n",
      " 0.77777778 1.         0.95       1.         1.         0.98529412\n",
      " 1.         0.94444444 0.96969697 0.98387097 1.         1.\n",
      " 1.        ]\n",
      "arr_prec: [0.97619048 0.975      1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.95       1.         1.         1.\n",
      " 1.         0.94444444 0.96969697 1.         0.95833333 0.96428571\n",
      " 1.        ]\n",
      "arr_F1: [0.98795181 0.98734177 0.89795918 1.         1.         1.\n",
      " 0.98305085 0.97058824 1.         1.         1.         1.\n",
      " 0.875      1.         0.95       1.         1.         0.99259259\n",
      " 1.         0.94444444 0.96969697 0.99186992 0.9787234  0.98181818\n",
      " 1.        ]\n",
      "test_F1: [0.98795181 0.98734177 0.89795918 1.         1.         1.\n",
      " 0.98305085 0.97058824 1.         1.         1.         1.\n",
      " 0.875      1.         0.95       1.         1.         0.99259259\n",
      " 1.         0.94444444 0.96969697 0.99186992 0.9787234  0.98181818\n",
      " 1.        ]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'specificity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'specificity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-066117ba5e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msource_dpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_task_HP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'performance_source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mdann_dpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_task_HP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'performance_dann'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtarget_dpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_task_HP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'performance_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'specificity'"
     ]
    }
   ],
   "source": [
    "# debug_F1 = True\n",
    "\n",
    "dict_df_all = {}\n",
    "\n",
    "\n",
    "for task_name, dict_task in dict_task_all.items():\n",
    "    df = pd.DataFrame(columns=list(dict_task.keys()),index=['source','DANN','target'])\n",
    "    dict_df = dict( zip(metric_names,[df.copy(), df.copy(), df.copy(), df.copy(), df.copy()]))\n",
    "\n",
    "    for key in dict_task.keys():\n",
    "        dict_task_HP = dict_task[key]\n",
    "        \n",
    "        if debug_F1:\n",
    "            F1_checker_each(dict_task_HP)\n",
    "\n",
    "        for i, metric_name in enumerate(metric_names):\n",
    "            source_dpt = dict_task_HP['performance_source'][metric_name].values\n",
    "            dann_dpt = dict_task_HP['performance_dann'][metric_name].values\n",
    "            target_dpt = dict_task_HP['performance_target'][metric_name].values\n",
    "            \n",
    "            dict_df[metric_name].loc['source', key] = '{:.4f}±{:.4f}'.format(np.nanmean(source_dpt),np.nanstd(source_dpt))\n",
    "            dict_df[metric_name].loc['DANN', key] = '{:.4f}±{:.4f}'.format(np.nanmean(dann_dpt),np.nanstd(dann_dpt))\n",
    "            dict_df[metric_name].loc['target', key] = '{:.4f}±{:.4f}'.format(np.nanmean(target_dpt),np.nanstd(target_dpt))\n",
    "\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "    df_outputdir = outputdir+task_name\n",
    "    if not os.path.exists(df_outputdir):\n",
    "        os.makedirs(df_outputdir)\n",
    "        \n",
    "    writer = pd.ExcelWriter(df_outputdir+'/allmetrics.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        print(task_name, metric_name)\n",
    "        display(dict_df[metric_name])\n",
    "        dict_df[metric_name].to_excel(writer, sheet_name=metric_name)\n",
    "        \n",
    "        if debug_F1:\n",
    "            F1_checker_mean(dict_df)\n",
    "\n",
    "    writer.save()\n",
    "\n",
    "    dict_df_all[task_name] = dict_df.copy()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>PAD</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>1.936674</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.925210</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.968897</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>1.988645</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.999840</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.968978</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.987805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>1.732203</td>\n",
       "      <td>0.000783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.974279</td>\n",
       "      <td>0.001638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.950928</td>\n",
       "      <td>0.000461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974790</td>\n",
       "      <td>1.960762</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.986842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>1.888411</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.900511</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.896545</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.962264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.999689</td>\n",
       "      <td>0.001380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.978261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>1.985928</td>\n",
       "      <td>0.002320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.931640</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.987952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.724351</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.993464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>1.920717</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.889875</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.918146</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.774059</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.966216</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>1.967229</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.972072</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>1.962843</td>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>1.950282</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc  sensitivity  precision       F1      PAD     loss\n",
       "0  0.991379     0.975610   1.000000 0.987654 1.936674 0.000402\n",
       "1  0.965517     0.923077   1.000000 0.960000 1.925210 0.000692\n",
       "2  0.929577     0.814815   1.000000 0.897959 1.968897 0.001946\n",
       "3  0.983193     0.964286   1.000000 0.981818 1.988645 0.000104\n",
       "4  1.000000     1.000000   1.000000 1.000000 1.999840 0.000599\n",
       "5  0.979167     0.944444   1.000000 0.971429 1.968978 0.001018\n",
       "6  0.987805     1.000000   0.967742 0.983607 1.732203 0.000783\n",
       "7  0.977011     0.971429   0.971429 0.971429 1.974279 0.001638\n",
       "8  1.000000     1.000000   1.000000 1.000000 1.950928 0.000461\n",
       "9  0.978261     0.950820   1.000000 0.974790 1.960762 0.000087\n",
       "10 0.986842     1.000000   0.960000 0.979592 1.888411 0.000289\n",
       "11 0.940541     0.895349   0.974684 0.933333 1.900511 0.000122\n",
       "12 0.957746     0.888889   1.000000 0.941176 1.896545 0.000430\n",
       "13 0.962264     1.000000   0.920000 0.958333 1.999689 0.001380\n",
       "14 0.978261     1.000000   0.952381 0.975610 1.985928 0.002320\n",
       "15 1.000000     1.000000   1.000000 1.000000 1.931640 0.000401\n",
       "16 0.987952     1.000000   0.972222 0.985915 1.724351 0.000191\n",
       "17 0.993464     1.000000   0.985507 0.992701 1.920717 0.000107\n",
       "18 1.000000     1.000000   1.000000 1.000000 1.889875 0.000453\n",
       "19 0.931818     0.888889   0.941176 0.914286 1.918146 0.001153\n",
       "20 0.975000     0.939394   1.000000 0.968750 1.774059 0.000382\n",
       "21 0.966216     0.919355   1.000000 0.957983 1.967229 0.000143\n",
       "22 1.000000     1.000000   1.000000 1.000000 1.972072 0.000039\n",
       "23 0.950820     0.925926   0.961538 0.943396 1.962843 0.001785\n",
       "24 0.986667     1.000000   0.972222 0.985915 1.950282 0.000504"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_task_HP['performance_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = dict_df_all[task_name]['acc'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paper_tables = {}\n",
    "\n",
    "for key in dict_df.keys():\n",
    "    if key == 'PAD':\n",
    "        continue\n",
    "            \n",
    "    df_task_agg = pd.DataFrame(index=row_names)\n",
    "\n",
    "    for task_name, dict_task in dict_task_all.items():\n",
    "        dict_df = dict_df_all[task_name]\n",
    "\n",
    "        dict_df_key_task = dict_df[key].rename(columns={'HP_fixed': task_name})\n",
    "        df_task_agg = df_task_agg.join(dict_df_key_task, how='outer')\n",
    "\n",
    "    df_paper_tables[key] = df_task_agg\n",
    "\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paper_tables['acc'].to_csv ('export_dataframe.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UMAFall_chest_UMAFall_waist</th>\n",
       "      <th>UMAFall_chest_UMAFall_wrist</th>\n",
       "      <th>UMAFall_chest_UMAFall_ankle</th>\n",
       "      <th>UMAFall_waist_UMAFall_wrist</th>\n",
       "      <th>UMAFall_waist_UMAFall_ankle</th>\n",
       "      <th>UMAFall_waist_UMAFall_chest</th>\n",
       "      <th>UMAFall_wrist_UMAFall_ankle</th>\n",
       "      <th>UMAFall_wrist_UMAFall_waist</th>\n",
       "      <th>UMAFall_wrist_UMAFall_chest</th>\n",
       "      <th>UMAFall_ankle_UMAFall_chest</th>\n",
       "      <th>UMAFall_ankle_UMAFall_waist</th>\n",
       "      <th>UMAFall_ankle_UMAFall_wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>0.9764±0.0207</td>\n",
       "      <td>0.7548±0.1223</td>\n",
       "      <td>0.9023±0.0496</td>\n",
       "      <td>0.6932±0.1257</td>\n",
       "      <td>0.8341±0.1470</td>\n",
       "      <td>0.9509±0.0566</td>\n",
       "      <td>0.7957±0.0874</td>\n",
       "      <td>0.8090±0.0998</td>\n",
       "      <td>0.7462±0.0757</td>\n",
       "      <td>0.8722±0.1071</td>\n",
       "      <td>0.8523±0.1025</td>\n",
       "      <td>0.6704±0.1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.9614±0.0587</td>\n",
       "      <td>0.8998±0.0776</td>\n",
       "      <td>0.8671±0.0668</td>\n",
       "      <td>0.7989±0.1223</td>\n",
       "      <td>0.8670±0.0665</td>\n",
       "      <td>0.9449±0.0550</td>\n",
       "      <td>0.8277±0.0722</td>\n",
       "      <td>0.8025±0.1027</td>\n",
       "      <td>0.8090±0.0810</td>\n",
       "      <td>0.8854±0.0755</td>\n",
       "      <td>0.9108±0.0799</td>\n",
       "      <td>0.7131±0.1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.9852±0.0225</td>\n",
       "      <td>0.9575±0.0314</td>\n",
       "      <td>0.9409±0.0517</td>\n",
       "      <td>0.9453±0.0383</td>\n",
       "      <td>0.8333±0.1959</td>\n",
       "      <td>0.9587±0.0470</td>\n",
       "      <td>0.9018±0.0648</td>\n",
       "      <td>0.9847±0.0275</td>\n",
       "      <td>0.9684±0.0308</td>\n",
       "      <td>0.9238±0.0779</td>\n",
       "      <td>0.9486±0.0446</td>\n",
       "      <td>0.9652±0.0230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UMAFall_chest_UMAFall_waist UMAFall_chest_UMAFall_wrist  \\\n",
       "source               0.9764±0.0207               0.7548±0.1223   \n",
       "DANN                 0.9614±0.0587               0.8998±0.0776   \n",
       "target               0.9852±0.0225               0.9575±0.0314   \n",
       "\n",
       "       UMAFall_chest_UMAFall_ankle UMAFall_waist_UMAFall_wrist  \\\n",
       "source               0.9023±0.0496               0.6932±0.1257   \n",
       "DANN                 0.8671±0.0668               0.7989±0.1223   \n",
       "target               0.9409±0.0517               0.9453±0.0383   \n",
       "\n",
       "       UMAFall_waist_UMAFall_ankle UMAFall_waist_UMAFall_chest  \\\n",
       "source               0.8341±0.1470               0.9509±0.0566   \n",
       "DANN                 0.8670±0.0665               0.9449±0.0550   \n",
       "target               0.8333±0.1959               0.9587±0.0470   \n",
       "\n",
       "       UMAFall_wrist_UMAFall_ankle UMAFall_wrist_UMAFall_waist  \\\n",
       "source               0.7957±0.0874               0.8090±0.0998   \n",
       "DANN                 0.8277±0.0722               0.8025±0.1027   \n",
       "target               0.9018±0.0648               0.9847±0.0275   \n",
       "\n",
       "       UMAFall_wrist_UMAFall_chest UMAFall_ankle_UMAFall_chest  \\\n",
       "source               0.7462±0.0757               0.8722±0.1071   \n",
       "DANN                 0.8090±0.0810               0.8854±0.0755   \n",
       "target               0.9684±0.0308               0.9238±0.0779   \n",
       "\n",
       "       UMAFall_ankle_UMAFall_waist UMAFall_ankle_UMAFall_wrist  \n",
       "source               0.8523±0.1025               0.6704±0.1132  \n",
       "DANN                 0.9108±0.0799               0.7131±0.1356  \n",
       "target               0.9486±0.0446               0.9652±0.0230  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper_tables['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UMAFall_chest_UMAFall_wrist</th>\n",
       "      <th>UMAFall_chest_UMAFall_waist</th>\n",
       "      <th>UMAFall_chest_UMAFall_ankle</th>\n",
       "      <th>UMAFall_wrist_UMAFall_chest</th>\n",
       "      <th>UMAFall_wrist_UMAFall_waist</th>\n",
       "      <th>UMAFall_wrist_UMAFall_ankle</th>\n",
       "      <th>UMAFall_waist_UMAFall_chest</th>\n",
       "      <th>UMAFall_waist_UMAFall_wrist</th>\n",
       "      <th>UMAFall_waist_UMAFall_ankle</th>\n",
       "      <th>UMAFall_ankle_UMAFall_chest</th>\n",
       "      <th>UMAFall_ankle_UMAFall_wrist</th>\n",
       "      <th>UMAFall_ankle_UMAFall_waist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UMAFall_chest_UMAFall_wrist, UMAFall_chest_UMAFall_waist, UMAFall_chest_UMAFall_ankle, UMAFall_wrist_UMAFall_chest, UMAFall_wrist_UMAFall_waist, UMAFall_wrist_UMAFall_ankle, UMAFall_waist_UMAFall_chest, UMAFall_waist_UMAFall_wrist, UMAFall_waist_UMAFall_ankle, UMAFall_ankle_UMAFall_chest, UMAFall_ankle_UMAFall_wrist, UMAFall_ankle_UMAFall_waist]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_empty = pd.DataFrame(columns = column_names)\n",
    "df_empty = pd.DataFrame(columns = list(dict_task_all.keys()))\n",
    "df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [source, DANN, target]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empty = pd.DataFrame(index=dict_df['acc'].index)\n",
    "df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['UMAFall_chest_UMAFall_wrist'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-ab2706342098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# bbb = dict_df['acc'].rename(columns={'HP_fixed': 'UMAFall_chest_UMAFall_wrist2'})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maaa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8108\u001b[0m         \u001b[0;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8109\u001b[0m         \"\"\"\n\u001b[0;32m-> 8110\u001b[0;31m         return self._join_compat(\n\u001b[0m\u001b[1;32m   8111\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8112\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8133\u001b[0m                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8134\u001b[0m                 )\n\u001b[0;32m-> 8135\u001b[0;31m             return merge(\n\u001b[0m\u001b[1;32m   8136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8137\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"columns overlap but no suffix specified: {to_rename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['UMAFall_chest_UMAFall_wrist'], dtype='object')"
     ]
    }
   ],
   "source": [
    "aaa = dict_df['key'].rename(columns={'HP_fixed': 'UMAFall_chest_UMAFall_wrist'})\n",
    "# bbb = dict_df['acc'].rename(columns={'HP_fixed': 'UMAFall_chest_UMAFall_wrist2'})\n",
    "\n",
    "df_empty = df_empty.join(aaa, how='outer')\n",
    "df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5f249e9cf9d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_empty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# df_empty = df_empty['bcc'].append(dict_df['acc'].values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# df_empty.append(dict_df['acc'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "df_empty = df_empty['acc'].append(dict_df['acc'].values)\n",
    "\n",
    "# df_empty = df_empty['bcc'].append(dict_df['acc'].values)\n",
    "# df_empty.append(dict_df['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HP_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>0.7548±0.1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.8998±0.0776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.9575±0.0314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             HP_fixed\n",
       "source  0.7548±0.1223\n",
       "DANN    0.8998±0.0776\n",
       "target  0.9575±0.0314"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HP_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>0.7548±0.1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.8998±0.0776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.9575±0.0314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             HP_fixed\n",
       "source  0.7548±0.1223\n",
       "DANN    0.8998±0.0776\n",
       "target  0.9575±0.0314"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df_all['UMAFall_chest_UMAFall_wrist']['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpLLbTjGTbZ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9U8wu607JSd_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGazHVhBVcgi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9043,
     "status": "ok",
     "timestamp": 1583160936030,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "T-tecuc6VeSO",
    "outputId": "cb7a97f6-e894-4a5f-f6bf-46665460f9a2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1582718354886,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "HV0r2Gh0Vykf",
    "outputId": "cfb26497-8ab0-4b67-ba06-19b92c9bab5b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnK88jJ3kXd3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTuPZryA0XDr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BIaUPJ-0XBz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWcFYNkc1S12"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOgrts3TNOi6xV9nChueHe9",
   "collapsed_sections": [
    "bQTp--k3JmHs",
    "fomnNHfFG02o",
    "bfJv1bL3G38c"
   ],
   "name": "stage3_model_eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mienv",
   "language": "python",
   "name": "mienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
