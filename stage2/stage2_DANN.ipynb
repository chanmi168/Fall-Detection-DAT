{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD6EM010PDWn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwW5pmvqVMhg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get user inputs\n",
    "In ipython notebook, these are hardcoded. In production python code, use parsers to provide these inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FD_DAT')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--extractor_type', metavar='extractor_type', help='extractor_type',\n",
    "                    default='CNN')\n",
    "parser.add_argument('--num_epochs', type=int, metavar='num_epochs', help='number of epochs',\n",
    "                    default='5')\n",
    "parser.add_argument('--CV_n', type=int, metavar='CV_n', help='CV folds',\n",
    "                    default='2')\n",
    "parser.add_argument('--rep_n', type=int, metavar='rep_n', help='number of repitition',\n",
    "                    default='5')\n",
    "parser.add_argument('--cuda_i', type=int, metavar='cuda_i', help='cuda index',\n",
    "                    default='1')\n",
    "parser.add_argument('--tasks_list', metavar='tasks_list', help='a list of all tasks',\n",
    "                    default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "parser.add_argument('--show_diagnosis_plt', metavar='show_diagnosis_plt', help='show diagnosis plt or not',\n",
    "                    default='False')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split_mode = 'LOO'\n",
    "# split_mode = '5fold'\n",
    "\n",
    "# checklist 2: comment first line, uncomment second line seizures_FN\n",
    "args = parser.parse_args(['--input_folder', '../../data_mic/stage1/preprocessed_18hz_5fold', \n",
    "                          '--output_folder', '../../data_mic/stage2/test',\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage1/preprocessed_WithoutNormal_18hz_5fold', \n",
    "#                           '--output_folder', '../../data_mic/stage2/modeloutput_WithoutNormal_18hz_5fold',\n",
    "                          '--extractor_type', 'CNN',\n",
    "                          '--num_epochs', '5',\n",
    "#                           '--CV_n', '2',\n",
    "#                           '--rep_n', '2',\n",
    "#                           '--cuda_i', '2',\n",
    "                          '--show_diagnosis_plt', 'True',\n",
    "                          '--tasks_list', 'UPFall_wrist-UMAFall_ankle',])\n",
    "#                           '--tasks_list', 'UMAFall_waist-UMAFall_wrist UPFall_wrist-UMAFall_ankle',])\n",
    "                          \n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = home+'/project_FDDAT/'\n",
    "input_folder = args.input_folder\n",
    "output_folder = args.output_folder\n",
    "extractor_type = args.extractor_type\n",
    "num_epochs = args.num_epochs\n",
    "CV_n = args.CV_n\n",
    "rep_n = args.rep_n\n",
    "show_diagnosis_plt = bool(args.show_diagnosis_plt)\n",
    "\n",
    "with open('../../repo/falldetect/params.json') as json_file:\n",
    "    falldetect_params = json.load(json_file)\n",
    "cuda_i = falldetect_params['cuda_i']\n",
    "\n",
    "tasks_list = []\n",
    "for item in args.tasks_list.split(' '):\n",
    "    tasks_list.append((item.split('-')[0], item.split('-')[1]))\n",
    "    \n",
    "inputdir = input_folder+'/'\n",
    "outputdir = output_folder+'/'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "test_mode = 'test' in outputdir.split('/')[-2]\n",
    "\n",
    "device = torch.device('cuda:{}'.format(int(cuda_i)) if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'HP_name': 'hp',\n",
    "    'classes_n': 2,\n",
    "    'CV_n': CV_n,\n",
    "    'num_epochs': num_epochs,\n",
    "    'channel_n': 4,\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 0.001,\n",
    "    'extractor_type': extractor_type,\n",
    "    'device': device,\n",
    "    'dropout': 0.5,\n",
    "    'hiddenDim_f': 3,\n",
    "    'hiddenDim_y': 3,\n",
    "    'hiddenDim_d': 3,\n",
    "    'win_size': 18,\n",
    "    'win_stride': 6,\n",
    "    'step_n': 9,\n",
    "    'show_diagnosis_plt': show_diagnosis_plt,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_CV = 1\n",
    "\n",
    "src_names = ['UPFall_neck','UPFall_wrist','UPFall_belt','UPFall_rightpocket','UPFall_ankle',\n",
    "             'UMAFall_chest','UMAFall_wrist','UMAFall_waist','UMAFall_leg','UMAFall_ankle',\n",
    "             'SFDLA_chest','SFDLA_wrist','SFDLA_waist','SFDLA_thigh','SFDLA_ankle',\n",
    "             'FARSEEING_lowback', 'FARSEEING_thigh']\n",
    "# src_names = ['FARSEEING_lowback', 'FARSEEING_thigh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch(train_loader, val_loader, model, src_name, outputdir):\n",
    "    model.eval()\n",
    "\n",
    "    data = src_train_loader.dataset.data.to(device)\n",
    "    labels = src_train_loader.dataset.labels.to(device).long()\n",
    "    feature_out, class_out, _ = model(data)\n",
    "    out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "\n",
    "    model_pred = np.argmax(out_sigmoid, 1)\n",
    "    labels_np = labels.data.detach().cpu().numpy()\n",
    "    TP = ((model_pred==1) & (labels_np==1)).sum()\n",
    "    FN = ((model_pred==0) & (labels_np==1)).sum()\n",
    "    train_sensitivity = TP/(TP+FN)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 5), dpi=120)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(out_sigmoid[:,1],'.b', label='src_class_sigmoid', markersize=3)\n",
    "    ax1.plot(out_sigmoid[:,1].round(),'b', alpha=0.5, label='src_class_decision')\n",
    "    ax1.plot(labels.data.detach().cpu().numpy(),'r', alpha=0.5, label='src_class_labels')\n",
    "    ax1.axhline(0.5, color='k', label='threshold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_title('train', fontsize=20)\n",
    "\n",
    "    data = src_val_loader.dataset.data.to(device)\n",
    "    labels = src_val_loader.dataset.labels.to(device).long()\n",
    "    feature_out, class_out, _ = model(data)\n",
    "    out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "    \n",
    "    model_pred = np.argmax(out_sigmoid, 1)\n",
    "    labels_np = labels.data.detach().cpu().numpy()\n",
    "    TP = ((model_pred==1) & (labels_np==1)).sum()\n",
    "    FN = ((model_pred==0) & (labels_np==1)).sum()\n",
    "    val_sensitivity = TP/(TP+FN)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    ax2.plot(out_sigmoid[:,1],'.b', label='tgt_class_sigmoid', markersize=3)\n",
    "    ax2.plot(out_sigmoid[:,1].round(),'b', alpha=0.5, label='tgt_class_decision')\n",
    "    ax2.plot(labels.data.detach().cpu().numpy(),'r', alpha=0.5, label='tgt_class_labels')\n",
    "    ax2.axhline(0.5, color='k', label='threshold')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_title('val', fontsize=20)\n",
    "    \n",
    "    fig.suptitle('src_name: {} sensitivity ({:.3f}, {:.3f})'.format(src_name, train_sensitivity, val_sensitivity), fontsize=16)\n",
    "    fig.savefig(outputdir+'src_name.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---> 87     train_data = np.concatenate(src_feature_out.data.detach().cpu().numpy(),src_feature_out.data.detach().cpu().numpy())\n",
    "# aaa = src_feature_out.data.detach().cpu().numpy()\n",
    "# np.concatenate((aaa,aaa),axis=0).shape\n",
    "\n",
    "\n",
    "# np.concatenate((src_domain_labels,src_domain_labels)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_src_names_list = []\n",
    "results_train = {}\n",
    "results_val = {}\n",
    "    \n",
    "# for src_name in src_names:\n",
    "for task_item in tasks_list:\n",
    "    (src_name, tgt_name) = task_item\n",
    "    \n",
    "    print('\\n\\nsrc_name: ', src_name)\n",
    "    print('tgt_name: ', tgt_name)\n",
    "\n",
    "    # TODO: don't need to extract training_params\n",
    "    classes_n = training_params['classes_n']\n",
    "    CV_n = training_params['CV_n']\n",
    "    num_epochs = training_params['num_epochs']\n",
    "    channel_n = training_params['channel_n']\n",
    "    batch_size = training_params['batch_size']\n",
    "    learning_rate = training_params['learning_rate']\n",
    "    extractor_type = training_params['extractor_type']\n",
    "    device = training_params['device']\n",
    "    show_diagnosis_plt = training_params['show_diagnosis_plt']\n",
    "\n",
    "#     src_dataset_name = src_name.split('_')[0]\n",
    "#     src_sensor_loc = src_name.split('_')[1]\n",
    "\n",
    "#     src_inputdir = inputdir + '{}/{}/'.format(src_dataset_name, src_sensor_loc)\n",
    "    \n",
    "    src_dataset_name = src_name.split('_')[0]\n",
    "    src_sensor_loc = src_name.split('_')[1]\n",
    "\n",
    "    tgt_dataset_name = tgt_name.split('_')[0]\n",
    "    tgt_sensor_loc = tgt_name.split('_')[1]\n",
    "\n",
    "    src_inputdir = inputdir + '{}/{}/'.format(src_dataset_name, src_sensor_loc)\n",
    "    tgt_inputdir = inputdir + '{}/{}/'.format(tgt_dataset_name, tgt_sensor_loc)\n",
    "\n",
    "    print('------------------------------Working on i_CV {}------------------------------'.format(i_CV))\n",
    "    # 1. prepare dataset\n",
    "    src_train_loader, src_val_loader = get_data_loader(src_inputdir, i_CV, batch_size, learning_rate)\n",
    "    tgt_train_loader, tgt_val_loader = get_data_loader(tgt_inputdir, i_CV, batch_size, learning_rate)\n",
    "\n",
    "#     tgt_train_loader, tgt_val_loader = get_data_loader(tgt_inputdir, i_CV, batch_size, learning_rate)\n",
    "\n",
    "    # the model expect the same input dimension for src and tgt data\n",
    "    src_train_size = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "    src_val_size = src_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "    src_input_dim = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n",
    "\n",
    "    # 2. prepare model\n",
    "\n",
    "    total_step = len(src_train_loader)\n",
    "\n",
    "    train_performance_dict_list = list( {} for i in range(num_epochs) )\n",
    "    val_src_performance_dict_list = list( {} for i in range(num_epochs) )\n",
    "\n",
    "    if extractor_type == 'CNN':\n",
    "        model = DannModel(device, class_N=classes_n, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "#         model = DannModel(device, class_N=classes_n, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "    elif extractor_type == 'CNNLSTM':\n",
    "        dropout = training_params['dropout']\n",
    "        hiddenDim_f = training_params['hiddenDim_f']\n",
    "        hiddenDim_y = training_params['hiddenDim_y']\n",
    "        hiddenDim_d = training_params['hiddenDim_d']\n",
    "        win_size = training_params['win_size']\n",
    "        win_stride = training_params['win_stride']\n",
    "        step_n = training_params['step_n']\n",
    "        model = CnnLstm(device, class_N=classes_n, channel_n=channel_n, dropout=dropout, hiddenDim_f=hiddenDim_f, hiddenDim_y=hiddenDim_y, hiddenDim_d=hiddenDim_d, win_size=win_size, win_stride=win_stride, step_n=step_n).to(device)\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    # loss and optimizer\n",
    "    class_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "#     plot_epoch(src_train_loader, src_val_loader, model)\n",
    "    # 3. fit the model\n",
    "    for epoch in range(num_epochs):\n",
    "        train_performance_dict = train_epoch(src_train_loader, device, model, class_criterion, optimizer, epoch)\n",
    "        \n",
    "        train_performance_dict = val_epoch(src_train_loader, device, model, class_criterion, optimizer, epoch, 'src')\n",
    "        train_performance_dict_list[epoch] = train_performance_dict\n",
    "\n",
    "        val_src_performance_dict = val_epoch(src_val_loader, device, model, class_criterion, optimizer, epoch, 'src')\n",
    "        val_src_performance_dict_list[epoch] = val_src_performance_dict\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    def get_PAD(src_train_loader, tgt_train_loader, src_val_loader, tgt_val_loader, model, c=3000):\n",
    "#         start_time = time.time()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        data = src_train_loader.dataset.data.to(device)\n",
    "        src_domain_labels = np.zeros(data.shape[0])\n",
    "        src_feature_out, _, _ = model(data)\n",
    "\n",
    "        data = tgt_train_loader.dataset.data.to(device)\n",
    "        tgt_domain_labels = np.ones(data.shape[0])\n",
    "        tgt_feature_out, _, _ = model(data)\n",
    "\n",
    "        train_data = np.concatenate((src_feature_out.data.detach().cpu().numpy(),tgt_feature_out.data.detach().cpu().numpy()),axis=0)\n",
    "        train_label = np.concatenate((src_domain_labels,tgt_domain_labels))\n",
    "\n",
    "        print(train_data.shape, train_label.shape)\n",
    "\n",
    "        svm_model = svm.SVC(C=c, probability=True, verbose=2)\n",
    "        svm_model.fit(train_data, train_label)\n",
    "\n",
    "        data = src_val_loader.dataset.data.to(device)\n",
    "        src_domain_labels = np.zeros(data.shape[0])\n",
    "        src_feature_out, _, _ = model(data)\n",
    "\n",
    "        data = tgt_val_loader.dataset.data.to(device)\n",
    "        tgt_domain_labels = np.ones(data.shape[0])\n",
    "        tgt_feature_out, _, _ = model(data)\n",
    "\n",
    "        val_data = np.concatenate((src_feature_out.data.detach().cpu().numpy(),tgt_feature_out.data.detach().cpu().numpy()),axis=0)\n",
    "        val_label = np.concatenate((src_domain_labels,tgt_domain_labels))\n",
    "\n",
    "        svm_out = svm_model.predict_proba(val_data)\n",
    "        mse = mean_squared_error(val_label, svm_out[:,1])\n",
    "        PAD = 2. * (1. - 2. * mse)\n",
    "        print('\\nmse=', mse)\n",
    "        print('PAD=', PAD)\n",
    "\n",
    "#         time_elapsed = time.time() - start_time\n",
    "#         print('time elapsed:', time.strftime(\"%H:%M:%S\", time.gmtime(time_elapsed)))\n",
    "\n",
    "#         sys.exit()\n",
    "        \n",
    "        return PAD\n",
    "    \n",
    "    val_PAD = get_PAD(src_train_loader, tgt_train_loader, src_val_loader, tgt_val_loader, model, c=3000)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    plot_epoch(src_train_loader, src_val_loader, model, src_name, outputdir)\n",
    "    \n",
    "\n",
    "    print(src_name, train_performance_dict_list[epoch]['src_sensitivity'])\n",
    "    results_train[src_name] =  train_performance_dict_list[epoch]['src_sensitivity']\n",
    "    results_val[src_name] =  val_src_performance_dict_list[epoch]['src_sensitivity']\n",
    "    \n",
    "    if train_performance_dict_list[epoch]['src_sensitivity'] < 0.7:\n",
    "        print('{} is bad src'.format(src_name))\n",
    "        bad_src_names_list.append(src_name)\n",
    "        \n",
    "#     sys.exit()\n",
    "\n",
    "        \n",
    "print(bad_src_names_list)\n",
    "print('train results')\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results_train)\n",
    "print('val results')\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(svm_out[:,1])\n",
    "plt.plot(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amhwi5lZJA5V"
   },
   "source": [
    "# functions developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BIaUPJ-0XBz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWcFYNkc1S12"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOn/a8GYIoFJV7tUKKo5tXT",
   "collapsed_sections": [
    "amhwi5lZJA5V"
   ],
   "name": "stage2_ArchDesignStudio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (FD_DAT)",
   "language": "python",
   "name": "fd_dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
