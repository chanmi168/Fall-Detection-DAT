{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Isjqqa84yJv-"
   },
   "source": [
    "**stage2_DANN_rep_n**. This notebook perform DANN training on optimal hyperparameters for rep_n times.\n",
    "\n",
    "**Edit**<br/>\n",
    "\n",
    "**TODO**<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dR0gs1Ya0xmy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (eval_util.py, line 408)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/mchan2020/miniconda3/envs/FD_DAT/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-2-9805b8119283>\"\u001b[0m, line \u001b[1;32m18\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from falldetect.training_util import *\n",
      "\u001b[0;36m  File \u001b[0;32m\"../falldetect/training_util.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from falldetect.eval_util import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../falldetect/eval_util.py\"\u001b[0;36m, line \u001b[0;32m408\u001b[0m\n\u001b[0;31m    return df_performance_table_agg\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD6EM010PDWn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBArMSJl7xee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get user inputs\n",
    "In ipython notebook, these are hardcoded. In production python code, use parsers to provide these inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FD_DAT')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--extractor_type', metavar='extractor_type', help='extractor_type',\n",
    "                    default='CNN')\n",
    "parser.add_argument('--num_epochs', type=int, metavar='num_epochs', help='number of epochs',\n",
    "                    default='5')\n",
    "parser.add_argument('--CV_n', type=int, metavar='CV_n', help='CV folds',\n",
    "                    default='2')\n",
    "parser.add_argument('--rep_n', type=int, metavar='rep_n', help='number of repitition',\n",
    "                    default='5')\n",
    "parser.add_argument('--tasks_list', metavar='tasks_list', help='a list of all tasks',\n",
    "                    default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "\n",
    "\n",
    "\n",
    "# split_mode = 'LOO'\n",
    "# split_mode = '5fold'\n",
    "\n",
    "# checklist 2: comment first line, uncomment second line seizures_FN\n",
    "args = parser.parse_args(['--input_folder', 'stage1_preprocessed_18hz_5fold', \n",
    "                          '--output_folder', 'stage2_modeloutput_18hz_5fold',\n",
    "                          '--extractor_type', 'CNN',\n",
    "                          '--num_epochs', '2',\n",
    "                          '--CV_n', '2',\n",
    "                          '--rep_n', '2',\n",
    "                          '--tasks_list', 'UMAFall_ankle-UPFall_ankle UPFall_rightpocket-UMAFall_leg',])\n",
    "#                           '--tasks_list', 'UMAFall_waist-UPFall_belt UPFall_wrist-UMAFall_ankle',])\n",
    "                          \n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = home+'/project_FDDAT/'\n",
    "input_folder = args.input_folder\n",
    "output_folder = args.output_folder\n",
    "extractor_type = args.extractor_type\n",
    "num_epochs = args.num_epochs\n",
    "CV_n = args.CV_n\n",
    "rep_n = args.rep_n\n",
    "\n",
    "tasks_list = []\n",
    "for item in args.tasks_list.split(' '):\n",
    "    tasks_list.append((item.split('-')[0], item.split('-')[1]))\n",
    "    \n",
    "inputdir = home_dir + 'data_mic/{}/'.format(input_folder)\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DEMl8O6SZsw6"
   },
   "outputs": [],
   "source": [
    "tasks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7qSJXzNSMCJ"
   },
   "source": [
    "# Repeat 10 times experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep_stats_2(df_performance_table_agg, rep_n):\n",
    "    df_acc = df_performance_table_agg.loc[ ['source', 'DANN', 'target', 'domain'] , ]\n",
    "    df_params = df_performance_table_agg.loc[ ['channel_n', 'batch_size', 'learning_rate', 'time_elapsed', 'num_params'], ]\n",
    "\n",
    "    # accs\n",
    "    df_performance_table_all_mean = df_acc.applymap(get_mean)\n",
    "    df_performance_table_means = df_performance_table_all_mean.mean(axis=1)\n",
    "    df_performance_table_stds = df_performance_table_all_mean.std(axis=1)\n",
    "    df_performance_table_all_mean['mean'] = df_performance_table_means\n",
    "    df_performance_table_all_mean['std'] = df_performance_table_stds\n",
    "    df_performance_table_all_mean['rep'] = df_performance_table_all_mean[['mean', 'std']].apply(lambda x : '{:.3f}±{:.3f}'.format(x[0],x[1]), axis=1)\n",
    "\n",
    "    # params\n",
    "    df_params_means = df_params.mean(axis=1)\n",
    "\n",
    "    df_performance_table_agg['rep_avg'] = ''\n",
    "    df_performance_table_agg.loc[ ['source', 'DANN', 'target', 'domain'] , ['rep_avg']] = df_performance_table_all_mean.loc[:, ['rep']]\n",
    "    df_performance_table_agg.loc[ ['channel_n', 'batch_size', 'learning_rate', 'time_elapsed', 'num_params'] , ['rep_avg']] = df_params_means\n",
    "\n",
    "    return df_performance_table_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_params_list = []\n",
    "for task in tasks_list:\n",
    "    tasks_params_list.append(  \n",
    "        {'HP_name': 'rep',\n",
    "         'task': task,\n",
    "         'classes_n': 2,\n",
    "         'CV_n': CV_n,\n",
    "         'num_epochs': num_epochs,\n",
    "         'channel_n': 4,\n",
    "         'batch_size': 4,\n",
    "         'learning_rate': 0.0001,\n",
    "         'extractor_type': extractor_type,\n",
    "         'device': device}, )\n",
    "print(tasks_params_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLThspTpRn6Q"
   },
   "outputs": [],
   "source": [
    "for tasks_params in tasks_params_list:\n",
    "\n",
    "    (src_name, tgt_name) = tasks_params['task']\n",
    "\n",
    "#     if 'rightpocket' in src_name or 'leg' in tgt_name or 'rightpocket' in tgt_name or 'leg' in src_name:\n",
    "#         tasks_params['CV_n'] = 15\n",
    "#     else:\n",
    "#         tasks_params['CV_n'] = 17\n",
    "\n",
    "\n",
    "    task_outputdir = home_dir + 'data_mic/{}/{}_{}/'.format(output_folder, src_name, tgt_name)\n",
    "\n",
    "    if not os.path.exists(task_outputdir):\n",
    "        os.makedirs(task_outputdir)\n",
    "    print('outputdir for stage2 output:', task_outputdir)\n",
    "    \n",
    "    df_performance_table_agg = pd.DataFrame('', index=['channel_n', 'batch_size', 'learning_rate', \n",
    "                                                      'source', 'DANN', 'target', 'domain', 'time_elapsed', 'num_params'], columns=[])\n",
    "\n",
    "    \n",
    "    for i in range(0,rep_n):\n",
    "        df_performance_table = performance_table(src_name, tgt_name, tasks_params, inputdir, task_outputdir)\n",
    "        df_performance_table_agg['rep_i{}'.format(i)] = df_performance_table\n",
    "\n",
    "    df_outputdir = task_outputdir+'repetitive_results/'\n",
    "    if not os.path.exists(df_outputdir):\n",
    "        os.makedirs(df_outputdir)\n",
    "    print('df_performance_table_rep_agg saved at', df_outputdir)\n",
    "\n",
    "    # Serialize data into file:\n",
    "    json.dump({key:val for key, val in tasks_params.items() if key != 'device'}, open(df_outputdir+'optimal_training_params.json', 'w'))\n",
    "\n",
    "    df_performance_table_agg = get_rep_stats(df_performance_table_agg, rep_n)\n",
    "    df_performance_table_agg.to_csv(df_outputdir+'df_performance_table_rep{}_agg.csv'.format(rep_n, i), encoding='utf-8')\n",
    "\n",
    "    display(df_performance_table_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_rep_stats_2(df_performance_table_agg, rep_n):\n",
    "#     df_acc = df_performance_table_agg.loc[ ['source', 'DANN', 'target', 'domain'] , ].copy()\n",
    "#     df_params = df_performance_table_agg.loc[ ['channel_n', 'batch_size', 'learning_rate', 'time_elapsed', 'num_params'], ].copy()\n",
    "\n",
    "#     # accs\n",
    "#     df_performance_table_all_mean = df_acc.applymap(get_mean)\n",
    "#     df_performance_table_means = df_performance_table_all_mean.mean(axis=1)\n",
    "#     df_performance_table_stds = df_performance_table_all_mean.std(axis=1)\n",
    "#     df_performance_table_all_mean['mean'] = df_performance_table_means\n",
    "#     df_performance_table_all_mean['std'] = df_performance_table_stds\n",
    "#     df_performance_table_all_mean['rep'] = df_performance_table_all_mean[['mean', 'std']].apply(lambda x : '{:.3f}±{:.3f}'.format(x[0],x[1]), axis=1)\n",
    "\n",
    "#     # params\n",
    "#     df_params_means = df_params.mean(axis=1)\n",
    "\n",
    "#     df_performance_table_agg['rep_avg'] = ''\n",
    "#     df_performance_table_agg.loc[ ['source', 'DANN', 'target', 'domain'] , ['rep_avg']] = df_performance_table_all_mean.loc[:, 'rep']\n",
    "#     df_performance_table_agg.loc[ ['channel_n', 'batch_size', 'learning_rate', 'time_elapsed', 'num_params'] , ['rep_avg']] = df_params_means\n",
    "# return df_performance_table_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQ56uBqEG1ls"
   },
   "outputs": [],
   "source": [
    "# del df_performance_table_agg['rep_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_params_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_performance_table_all_mean.loc[:, 'rep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P-u1QqXBG1jj"
   },
   "outputs": [],
   "source": [
    "# df_params_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzYcMe0YG1eI"
   },
   "outputs": [],
   "source": [
    "# aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpafyRhmhiR4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOJNycV53BCy3BmN3hzefoo",
   "collapsed_sections": [],
   "name": "stage2_DANN_rep10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (FD_DAT)",
   "language": "python",
   "name": "fd_dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
