{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Isjqqa84yJv-"
   },
   "source": [
    "**stage2_DANN**. This notebook is the initial attempt to train a DANN with UMAFall_waist as source data and UPFall_waist as target data.\n",
    "\n",
    "**Edit**<br/>\n",
    "\n",
    "**TODO**<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1034520,
     "status": "ok",
     "timestamp": 1585233941741,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "dR0gs1Ya0xmy",
    "outputId": "b9089a6c-a803-4be8-e598-66f81a8fdd71"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD6EM010PDWn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBArMSJl7xee"
   },
   "outputs": [],
   "source": [
    "gpu_id = 1\n",
    "device = torch.device('cuda:{}'.format(gpu_id) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajkRQ49LxqSf"
   },
   "source": [
    "### model unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1057718,
     "status": "ok",
     "timestamp": 1585233964974,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "a-uoK1gyv8Ca",
    "outputId": "e121bd7b-ea25-4ef9-d676-cf3362691ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show GPU device name: TITAN Xp\n",
      "FeatureExtractor_total_params: 1824\n",
      "show model_1 output size: torch.Size([8, 576])\n",
      "show model_2 output size: torch.Size([8, 2])\n",
      "show model_3 output size: torch.Size([8, 2])\n",
      "model_4 output size torch.Size([8, 2])\n",
      "FeatureExtractor_total_params: 240\n",
      "DannModel_total_params: 964\n",
      "dann output size torch.Size([8, 180]) torch.Size([8, 2]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "print('show GPU device name:', torch.cuda.get_device_name(0))\n",
    "model_1 = FeatureExtractor(input_dim=66).to(device).float()\n",
    "\n",
    "test_input = torch.randn((8, 3, 66), dtype=torch.double)\n",
    "\n",
    "test_input = test_input.to(device)\n",
    "    # labels = labels.to(device).long()\n",
    "\n",
    "feature_out = model_1(test_input)\n",
    "print('show model_1 output size:', feature_out.size())\n",
    "\n",
    "feature_out.data.detach().cpu().numpy()\n",
    "\n",
    "feature_out_dim =  feature_out.size()[1]\n",
    "model_2 = ClassClassifier(num_classes=2, input_dim=feature_out_dim).to(device).float()\n",
    "model_3 = DomainClassifier(num_classes=2, input_dim=feature_out_dim).to(device).float()\n",
    "\n",
    "model_2_out = model_2(feature_out)\n",
    "print('show model_2 output size:', model_2_out.size())\n",
    "\n",
    "model_3_out = model_3(feature_out, 1)\n",
    "print('show model_3 output size:', model_3_out.size())\n",
    "\n",
    "model_4 = CascadedModel(model_1, model_2)\n",
    "# model_4 = nn.Sequential(model_1, model_2)\n",
    "\n",
    "print('model_4 output size', model_4(test_input).size())\n",
    "\n",
    "dann = DannModel(device, class_N=2, domain_N=2, channel_n=5, input_dim=66).to(device).float()\n",
    "feature_out, class_output, domain_output = dann(test_input)\n",
    "print('dann output size', feature_out.size(), class_output.size(), domain_output.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XztGPm3E0DMM"
   },
   "source": [
    "# Exporting function for model performance, notebook parameters, and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkElU-DQIjWr"
   },
   "source": [
    "### performance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnZ1gBBy7aC3"
   },
   "outputs": [],
   "source": [
    "# def performance_table(df_performance_table, src_name, tgt_name, training_params, inputdir, outputdir):\n",
    "#   task_name = src_name+'_'+tgt_name\n",
    "#   # df_performance_table[task_name] = ''\n",
    "\n",
    "#   start_time = time.time()\n",
    "#   # print('========================transferring knowledge from source({}) to target({})========================'.format(src_name, tgt_name))\n",
    "#   print('\\n==========================================================================================================================')\n",
    "#   print('======================  train on source, val on target(source={} to target={})  ======================'.format(src_name, tgt_name))\n",
    "#   print('==========================================================================================================================\\n')\n",
    "#   source_outputs = BaselineModel_fitting(training_params, src_name, tgt_name, inputdir, outputdir+'source/')\n",
    "#   print('\\n==========================================================================================================================')\n",
    "#   print('======================  train on target, val on target(source={} to target={})  ======================'.format(src_name, tgt_name))\n",
    "#   print('==========================================================================================================================\\n')\n",
    "#   target_outputs = BaselineModel_fitting(training_params, tgt_name, src_name, inputdir, outputdir+'target/')\n",
    "#   print('\\n==========================================================================================================================')\n",
    "#   print('======================  DANN training transferring knowledge(source={} to target={})  ======================'.format(src_name, tgt_name))\n",
    "#   print('==========================================================================================================================\\n')\n",
    "  \n",
    "#   # print('========================DANN training transferring knowledge from source({}) to target({})========================'.format(src_name, tgt_name))\n",
    "#   dann_outputs = DannModel_fitting(training_params, src_name, tgt_name, inputdir, outputdir+'dann/')\n",
    "\n",
    "#   elapsed_time = time.time() - start_time\n",
    "#   print('time elapsed:', time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "#   (val_tgt_class_acc_mean, val_tgt_class_acc_std), (val_domain_acc_mean, val_domain_acc_std) = dann_outputs\n",
    "#   (_,_), (source_tgt_acc_mean, source_tgt_acc_std) = source_outputs\n",
    "#   (target_tgt_acc_mean, target_tgt_acc_std), (_,_) = target_outputs\n",
    "\n",
    "#   df_performance_table.loc['source',task_name] = '{:.3f}±{:.3f}'.format(source_tgt_acc_mean, source_tgt_acc_std)\n",
    "#   df_performance_table.loc['DANN',task_name] = '{:.3f}±{:.3f}'.format(val_tgt_class_acc_mean, val_tgt_class_acc_std)\n",
    "#   df_performance_table.loc['target',task_name] = '{:.3f}±{:.3f}'.format(target_tgt_acc_mean, target_tgt_acc_std)\n",
    "#   df_performance_table.loc['domain',task_name] = '{:.3f}±{:.3f}'.format(val_domain_acc_mean, val_domain_acc_std)\n",
    "\n",
    "#   return df_performance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRhy-A9TNFE6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9oGUEu4NFMQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMd1cjTu2QNF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOBgdptINRDH"
   },
   "source": [
    "# ADDA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFMQOkO_NFKo"
   },
   "outputs": [],
   "source": [
    "# class AddaModel(nn.Module):\n",
    "#   def __init__(self, device, class_N=2, domain_N=2, channel_n=16, input_dim=10):\n",
    "#     super(AddaModel, self).__init__()\n",
    "#     self.feature_extractor = FeatureExtractor(input_dim=input_dim, channel_n=channel_n).to(device).float()\n",
    "#     cnn_layer1_dim = (input_dim+2*2-1*(3-1)-1)+1\n",
    "#     pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#     cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n",
    "#     pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#     feature_out_dim = int(pool_layer2_dim*channel_n*2)\n",
    "\n",
    "#     self.class_classfier = ClassClassifier(num_classes=class_N, input_dim=feature_out_dim).to(device).float()\n",
    "#     self.domain_classifier = DomainClassifier(num_classes=domain_N, input_dim=feature_out_dim).to(device).float()\n",
    "      \n",
    "#   def forward(self, x):\n",
    "#     feature_out = self.feature_extractor(x)\n",
    "#     class_output = self.class_classfier(feature_out)\n",
    "#     domain_output = self.domain_classifier(feature_out, 1)\n",
    "#     return feature_out, class_output, domain_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-CESaTgYGar"
   },
   "outputs": [],
   "source": [
    "# # fine-tuning\n",
    "# tasks_list = [('UMAFall_waist', 'UPFall_belt')]\n",
    "\n",
    "# # training_params = {\n",
    "# #     'classes_n': 2,\n",
    "# #     'CV_n': 17,\n",
    "# #     'num_epochs': 10,\n",
    "# #     'channel_n': 4,\n",
    "# #     'batch_size': 64,\n",
    "# #     'learning_rate': 0.01,\n",
    "# #     'extractor_type': 'CNN'}\n",
    "\n",
    "# training_params =\n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 16,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': 'CNN'}\n",
    "\n",
    "# start_time = time.time()\n",
    "# df_performance_table = pd.DataFrame('', index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "\n",
    "# for task_item in tasks_list:\n",
    "#   (src_name, tgt_name) = task_item\n",
    "\n",
    "#   inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz_LOO/'\n",
    "#   outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO/{}_{}/'.format(src_name, tgt_name)\n",
    "#   if not os.path.exists(outputdir):\n",
    "#       os.makedirs(outputdir)\n",
    "#   print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "#   df_performance_table = performance_table(df_performance_table, src_name, tgt_name, training_params, inputdir, outputdir)\n",
    "#   # display(df_performance_table)\n",
    "\n",
    "# time_elapsed = time.time() - start_time\n",
    "# print('time elapsed:', time_elapsed)\n",
    "# df_performance_table.loc['time_elapsed'] = time_elapsed\n",
    "# display(df_performance_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-d0jD-VYYs1w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tESfB1iuNFH-"
   },
   "outputs": [],
   "source": [
    "# df_performance_table\n",
    "\n",
    "# df_outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/hyperparameter_ft/{}_{}/'.format(src_name, tgt_name)\n",
    "\n",
    "# if not os.path.exists(df_outputdir):\n",
    "#   os.makedirs(df_outputdir)\n",
    "# df_performance_table.to_csv(df_outputdir+'df_performance_table_learning_rate{}.csv'.format(training_params['learning_rate']), encoding='utf-8')\n",
    "\n",
    "\n",
    "# df_outputdir+'df_performance_table_learning_rate{}.csv'.format(training_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LX-641qIpd33"
   },
   "source": [
    "# optimal hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unuHYyZyASWB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1lm_fSg4MuxV7GajyTTrYtYX_BoqiURla"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 699015,
     "status": "ok",
     "timestamp": 1584629541368,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "rwbs2kQupbdn",
    "outputId": "69fd6755-7ac2-4910-e066-280bf45c4726"
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bb38bd8021c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0moutputdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO_testing/{}_{}/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputdir for stage2 output:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FD_DAT/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FD_DAT/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FD_DAT/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FD_DAT/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FD_DAT/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FD_DAT/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FD_DAT/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/content'"
     ]
    }
   ],
   "source": [
    "# optimal\n",
    "\n",
    "# tasks_list = [('UMAFall_waist', 'UPFall_belt')]\n",
    "tasks_list = [('UPFall_belt', 'UMAFall_waist')]\n",
    "# tasks_list = [('UMAFall_ankle', 'UPFall_ankle')]\n",
    "# tasks_list = [('UMAFall_wrist', 'UPFall_wrist')]\n",
    "# tasks_list = [('UMAFall_leg', 'UPFall_rightpocket')]\n",
    "\n",
    "# optimal_training_params = {\n",
    "#   'classes_n': 2,\n",
    "#   'CV_n': 17,\n",
    "#   'num_epochs': 10,\n",
    "#   'channel_n': 4,\n",
    "#   'batch_size': 4,\n",
    "#   'learning_rate': 0.01,\n",
    "#   'extractor_type': 'CNN'}\n",
    "\n",
    "tasks_list = [('UMAFall_waist', 'UPFall_wrist')]\n",
    "\n",
    "extractor_type = 'CNN'\n",
    "num_epochs = 10\n",
    "CV_n = 17\n",
    "rep_n = 10\n",
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "training_params = {\n",
    "    'HP_name': 'HP_i6',\n",
    "    'classes_n': 2,\n",
    "    'CV_n': CV_n,\n",
    "    'num_epochs': num_epochs,\n",
    "    'channel_n': 4,\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 0.0001,\n",
    "    'extractor_type': extractor_type,\n",
    "    'device': device,\n",
    "    'dropout': 0.5,\n",
    "    'hiddenDim_f': 3,\n",
    "    'hiddenDim_y': 3,\n",
    "    'hiddenDim_d': 3,\n",
    "    'win_size': 18,\n",
    "    'win_stride': 6,\n",
    "    'step_n': 9,\n",
    "  }\n",
    "\n",
    "# for i, training_params in enumerate(training_params_list):\n",
    "df_performance_table = pd.DataFrame('', index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "\n",
    "for task_item in tasks_list:\n",
    "  start_time = time.time()\n",
    "\n",
    "  (src_name, tgt_name) = task_item\n",
    "\n",
    "# outputdir = home_dir + 'data_mic/stage1_preprocessed_18hz_{}/{}/{}/'.format(split_mode, dataset_name, sensor_loc)\n",
    "#     inputdir = home_dir + 'data_mic/stage1_preprocessed_18hz_{}/'.format(split_mode)\n",
    "\n",
    "  inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz_LOO/'\n",
    "  outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO_testing/{}_{}/'.format(src_name, tgt_name)\n",
    "  if not os.path.exists(outputdir):\n",
    "      os.makedirs(outputdir)\n",
    "  print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "  df_performance_table = performance_table_v2(df_performance_table, src_name, tgt_name, optimal_training_params, inputdir, outputdir)\n",
    "  # df_performance_table = performance_table_v2(df_performance_table, get_UMAFall_loader, get_UPFall_loader, src_name, tgt_name, optimal_training_params, inputdir, outputdir)\n",
    "\n",
    "  time_elapsed = time.time() - start_time\n",
    "  print('time elapsed:', time_elapsed)\n",
    "  df_performance_table.loc['time_elapsed'] = time_elapsed\n",
    "\n",
    "  df_outputdir = outputdir\n",
    "\n",
    "  print('df_performance_table saved at', df_outputdir)\n",
    "  df_performance_table.to_csv(df_outputdir+'df_performance_table_optimal.csv', encoding='utf-8')\n",
    "\n",
    "  display(df_performance_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1Gq_9tgZtIY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mj0AqSiIChBG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnTE0_m3ZtGI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62FVgtebZtEq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XdKQrqwjZt-V"
   },
   "source": [
    "## hyperparameter testing for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XlHlSQ8DZtAE"
   },
   "outputs": [],
   "source": [
    "# # fine-tuning\n",
    "# tasks_list = [('UMAFall_ankle', 'UPFall_ankle')]\n",
    "\n",
    "# training_params_list = [\n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 16,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': 'CNN'}, \n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': 'CNN'}, \n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 64,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': 'CNN'}, \n",
    "    \n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 16,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': 'CNN'}, \n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 32,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': 'CNN'}, \n",
    "\n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'extractor_type': 'CNN'}, \n",
    "#   {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 17,\n",
    "#     'num_epochs': 10,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.0001,\n",
    "#     'extractor_type': 'CNN'}, ]\n",
    "\n",
    "# for i, training_params in enumerate(training_params_list):\n",
    "#   start_time = time.time()\n",
    "#   df_performance_table = pd.DataFrame('', index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "\n",
    "#   for task_item in tasks_list:\n",
    "#     (src_name, tgt_name) = task_item\n",
    "\n",
    "#     # inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "#     # outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "\n",
    "#     inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz_LOO/'\n",
    "#     outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO/{}_{}/'.format(src_name, tgt_name)\n",
    "#     if not os.path.exists(outputdir):\n",
    "#         os.makedirs(outputdir)\n",
    "#     print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "#     df_performance_table = performance_table(df_performance_table, src_name, tgt_name, training_params, inputdir, outputdir)\n",
    "#     # display(df_performance_table)\n",
    "\n",
    "#   time_elapsed = time.time() - start_time\n",
    "#   print('time elapsed:', time_elapsed)\n",
    "#   df_performance_table.loc['time_elapsed'] = time_elapsed\n",
    "#   display(df_performance_table)\n",
    "\n",
    "#   df_outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO/hyperparameter_ft/{}_{}/'.format(src_name, tgt_name)\n",
    "#   if not os.path.exists(df_outputdir):\n",
    "#     os.makedirs(df_outputdir)\n",
    "#   df_performance_table.to_csv(df_outputdir+'df_performance_table_i{}.csv'.format(i), encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZ28VOuXZs9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TP8mnbCMZs3T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DEMl8O6SZsw6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3B6xF-AO0UiV"
   },
   "outputs": [],
   "source": [
    "# df_performance_table = pd.DataFrame(0, index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "# tasks_list = [('UMAFall_waist', 'UPFall_belt'), ('UMAFall_ankle', 'UPFall_ankle'), ('UMAFall_wrist', 'UPFall_wrist'), ('UMAFall_leg', 'UPFall_rightpocket'), ('UMAFall_all', 'UPFall_all')]\n",
    "\n",
    "# optimal_training_params = {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 5,\n",
    "#     'num_epochs': 3,\n",
    "#     'channel_n': 32,\n",
    "#     'batch_size': 1,\n",
    "#     'learning_rate': 0.01}\n",
    "\n",
    "# for task_item in tasks_list:\n",
    "#   (src_name, tgt_name) = task_item\n",
    "\n",
    "#   # inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed/'\n",
    "#   # outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput/{}_{}/'.format(src_name, tgt_name)\n",
    "#   inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "#   outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "#   if not os.path.exists(outputdir):\n",
    "#       os.makedirs(outputdir)\n",
    "#   print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "#   performance_table(src_name, tgt_name, optimal_training_params, df_performance_table, inputdir, outputdir)\n",
    "#   display(df_performance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7xe_LHOwIfA"
   },
   "source": [
    "# \"remove one sensor at a time\" experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsVelXEWwHk_"
   },
   "outputs": [],
   "source": [
    "df_performance_table = pd.DataFrame(0, index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "tasks_list = [('UMAFall_allbutwrist', 'UPFall_allbutwrist'), ('UMAFall_allbutwaist', 'UPFall_allbutwaist'), ('UMAFall_allbutleg', 'UPFall_allbutleg'), ('UMAFall_allbutankle', 'UPFall_allbutankle'), ('UMAFall_allbutfifth', 'UPFall_allbutfifth')]\n",
    "# tasks_list = [('UMAFall_allbutwrist', 'UPFall_allbutwrist'), ('UMAFall_ankle', 'UPFall_ankle'), ('UMAFall_wrist', 'UPFall_wrist'), ('UMAFall_leg', 'UPFall_rightpocket'), ('UMAFall_all', 'UPFall_all')]\n",
    "\n",
    "optimal_training_params = {\n",
    "    'classes_n': 2,\n",
    "    'CV_n': 5,\n",
    "    'num_epochs': 3,\n",
    "    'channel_n': 32,\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 0.01}\n",
    "\n",
    "for task_item in tasks_list:\n",
    "  (src_name, tgt_name) = task_item\n",
    "\n",
    "  # inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed/'\n",
    "  # outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput/{}_{}/'.format(src_name, tgt_name)\n",
    "  inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "  outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "  if not os.path.exists(outputdir):\n",
    "      os.makedirs(outputdir)\n",
    "  print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "  performance_table(src_name, tgt_name, optimal_training_params, df_performance_table, inputdir, outputdir)\n",
    "  display(df_performance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7qSJXzNSMCJ"
   },
   "source": [
    "# Repeat 10 times experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDKDIcO0SQ8Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Km67SbGBAnIp"
   },
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "for i in range(1,5):\n",
    "  start_time = time.time()\n",
    "\n",
    "  df_performance_table = pd.DataFrame(0, index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "  # tasks_list = [('UMAFall_waist', 'UPFall_belt'), ('UMAFall_ankle', 'UPFall_ankle'), ('UMAFall_wrist', 'UPFall_wrist'), ('UMAFall_leg', 'UPFall_rightpocket'), ('UMAFall_all', 'UPFall_all')]\n",
    "  tasks_list = [('UMAFall_waist', 'UPFall_belt'), ('UMAFall_ankle', 'UPFall_ankle'), ('UMAFall_wrist', 'UPFall_wrist'), ('UMAFall_leg', 'UPFall_rightpocket')]\n",
    "\n",
    "  # optimal_training_params = {\n",
    "  #     'classes_n': 2,\n",
    "  #     'CV_n': 5,\n",
    "  #     'num_epochs': 3,\n",
    "  #     'channel_n': 32,\n",
    "  #     'batch_size': 1,\n",
    "  #     'learning_rate': 0.01}\n",
    "\n",
    "  optimal_training_params = {\n",
    "      'classes_n': 2,\n",
    "      'CV_n': 10,\n",
    "      'num_epochs': 10,\n",
    "      'channel_n': 4,\n",
    "      'batch_size': 4,\n",
    "      'learning_rate': 0.01,\n",
    "      'extractor_type': 'CNN'}\n",
    "\n",
    "  for task_item in tasks_list:\n",
    "    (src_name, tgt_name) = task_item\n",
    "\n",
    "\n",
    "    # inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "    # outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "    inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz_LOO/'\n",
    "    outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO/{}_{}/'.format(src_name, tgt_name)\n",
    "    if not os.path.exists(outputdir):\n",
    "        os.makedirs(outputdir)\n",
    "    print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "    # performance_table(src_name, tgt_name, optimal_training_params, df_performance_table, inputdir, outputdir)\n",
    "    df_performance_table = performance_table(df_performance_table, src_name, tgt_name, optimal_training_params, inputdir, outputdir)\n",
    "    display(df_performance_table)\n",
    "\n",
    "  # df_outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/repetitive_results/'\n",
    "  df_outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO/repetitive_results/'\n",
    "  if not os.path.exists(df_outputdir):\n",
    "    os.makedirs(df_outputdir)\n",
    "  df_performance_table.to_csv(df_outputdir+'df_performance_table_trial{}.csv'.format(i), encoding='utf-8')\n",
    "\n",
    "  elapsed_time = time.time() - start_time\n",
    "  print('time elapsed:', elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PT0nxNaGqxim"
   },
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "# # for i in range(0,1):\n",
    "#   start_time = time.time()\n",
    "\n",
    "#   df_performance_table = pd.DataFrame(0, index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "#   tasks_list = [('UMAFall_waist', 'UPFall_belt'), ('UMAFall_ankle', 'UPFall_ankle'), ('UMAFall_wrist', 'UPFall_wrist'), ('UMAFall_leg', 'UPFall_rightpocket'), ('UMAFall_all', 'UPFall_all')]\n",
    "#   # tasks_list = [('UMAFall_waist', 'UPFall_belt'), ('UMAFall_ankle', 'UPFall_ankle'), ('UMAFall_wrist', 'UPFall_wrist'), ('UMAFall_leg', 'UPFall_rightpocket')]\n",
    "\n",
    "#   # optimal_training_params = {\n",
    "#   #     'classes_n': 2,\n",
    "#   #     'CV_n': 5,\n",
    "#   #     'num_epochs': 3,\n",
    "#   #     'channel_n': 32,\n",
    "#   #     'batch_size': 1,\n",
    "#   #     'learning_rate': 0.01}\n",
    "\n",
    "#   optimal_training_params = {\n",
    "#       'classes_n': 2,\n",
    "#       'CV_n': 10,\n",
    "#       'num_epochs': 5,\n",
    "#       'channel_n': 4,\n",
    "#       'batch_size': 4,\n",
    "#       'learning_rate': 0.01,\n",
    "#       'extractor_type': 'CNN'}\n",
    "\n",
    "#   for task_item in tasks_list:\n",
    "#     (src_name, tgt_name) = task_item\n",
    "\n",
    "\n",
    "#     # inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "#     # outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "#     inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz_LOO/'\n",
    "#     outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO/{}_{}/'.format(src_name, tgt_name)\n",
    "#     if not os.path.exists(outputdir):\n",
    "#         os.makedirs(outputdir)\n",
    "#     print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "#     # performance_table(src_name, tgt_name, optimal_training_params, df_performance_table, inputdir, outputdir)\n",
    "#     df_performance_table = performance_table(df_performance_table, src_name, tgt_name, optimal_training_params, inputdir, outputdir)\n",
    "#     display(df_performance_table)\n",
    "\n",
    "#   # df_outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/repetitive_results/'\n",
    "#   df_outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz_LOO/repetitive_results/'\n",
    "#   if not os.path.exists(df_outputdir):\n",
    "#     os.makedirs(df_outputdir)\n",
    "#   df_performance_table.to_csv(df_outputdir+'df_performance_table_trial{}.csv'.format(i), encoding='utf-8')\n",
    "\n",
    "#   elapsed_time = time.time() - start_time\n",
    "#   print('time elapsed:', elapsed_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpP2Uo4sXXdL"
   },
   "source": [
    "# fill in the rest of performance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwpICWaRXXx0"
   },
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "df_performance_table = pd.DataFrame(0, index=['source', 'DANN', 'target', 'domain'], columns=[])\n",
    "tasks_list = [('UPFall_belt', 'UMAFall_waist'), ('UPFall_ankle', 'UMAFall_ankle'), ('UPFall_wrist', 'UMAFall_wrist'), ('UPFall_rightpocket', 'UMAFall_leg'), ('UPFall_neck', 'UMAFall_chest'), ('UMAFall_all', 'UPFall_all')]\n",
    "\n",
    "optimal_training_params = {\n",
    "    'classes_n': 2,\n",
    "    'CV_n': 5,\n",
    "    'num_epochs': 3,\n",
    "    'channel_n': 32,\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 0.01}\n",
    "\n",
    "for task_item in tasks_list:\n",
    "  (src_name, tgt_name) = task_item\n",
    "\n",
    "  inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "  outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "  if not os.path.exists(outputdir):\n",
    "      os.makedirs(outputdir)\n",
    "  print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "  performance_table(src_name, tgt_name, optimal_training_params, df_performance_table, inputdir, outputdir)\n",
    "  display(df_performance_table)\n",
    "\n",
    "  # df_outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput_18hz/repetitive_results/'\n",
    "  # if not os.path.exists(df_outputdir):\n",
    "  #   os.makedirs(df_outputdir)\n",
    "  # df_performance_table.to_csv(df_outputdir+'df_performance_table_trial{}.csv'.format(i), encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "364qjj67EDmH"
   },
   "source": [
    "# Feature space clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnK88jJ3kXd3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K05nGUkKRU0S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTuPZryA0XDr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BIaUPJ-0XBz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWcFYNkc1S12"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPxhqDd4KW+pIUodl6eh0xA",
   "collapsed_sections": [
    "d7xe_LHOwIfA"
   ],
   "name": "stage2_DANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (FD_DAT)",
   "language": "python",
   "name": "fd_dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
