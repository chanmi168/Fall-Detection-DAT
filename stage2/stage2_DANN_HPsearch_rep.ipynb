{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Isjqqa84yJv-"
   },
   "source": [
    "**stage2_DANN_HPsearch.ipynb**. This notebook attempts to search the hyperparameter that yields the optimal validation performance.\n",
    "\n",
    "**Edit**<br/>\n",
    "\n",
    "**TODO**<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dR0gs1Ya0xmy"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD6EM010PDWn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get user inputs\n",
    "In ipython notebook, these are hardcoded. In production python code, use parsers to provide these inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FD_DAT')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--extractor_type', metavar='extractor_type', help='extractor_type',\n",
    "                    default='CNN')\n",
    "parser.add_argument('--num_epochs', type=int, metavar='num_epochs', help='number of epochs',\n",
    "                    default='5')\n",
    "parser.add_argument('--CV_n', type=int, metavar='CV_n', help='CV folds',\n",
    "                    default='2')\n",
    "parser.add_argument('--rep_n', type=int, metavar='rep_n', help='number of repitition',\n",
    "                    default='5')\n",
    "# parser.add_argument('--cuda_i', type=int, metavar='cuda_i', help='cuda index',\n",
    "#                     default='1')\n",
    "parser.add_argument('--tasks_list', metavar='tasks_list', help='a list of all tasks',\n",
    "                    default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "parser.add_argument('--show_diagnosis_plt', metavar='show_diagnosis_plt', help='show diagnosis plt or not',\n",
    "                    default='False')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split_mode = 'LOO'\n",
    "# split_mode = '5fold'\n",
    "\n",
    "# checklist 2: comment first line, uncomment second line seizures_FN\n",
    "args = parser.parse_args(['--input_folder', '../../data_mic/stage1_preprocessed_NormalforAllAxes_18hz_5fold', \n",
    "                          '--output_folder', '../../data_mic/stage2_modeloutput_NormalforAllAxes_18hz_5fold',\n",
    "                          '--extractor_type', 'CNN',\n",
    "                          '--num_epochs', '10',\n",
    "                          '--CV_n', '2',\n",
    "                          '--rep_n', '2',\n",
    "                          '--show_diagnosis_plt', 'True',\n",
    "                          '--tasks_list', 'UPFall_wrist-UMAFall_wrist',])\n",
    "#                           '--tasks_list', 'UMAFall_waist-UMAFall_wrist UPFall_wrist-UMAFall_ankle',])\n",
    "                          \n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(CV_n=2, extractor_type='CNN', input_folder='../../data_mic/stage1_preprocessed_NormalforAllAxes_18hz_5fold', num_epochs=10, output_folder='../../data_mic/stage2_modeloutput_NormalforAllAxes_18hz_5fold', rep_n=2, show_diagnosis_plt='True', tasks_list='UPFall_wrist-UMAFall_wrist')\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = home+'/project_FDDAT/'\n",
    "input_folder = args.input_folder\n",
    "output_folder = args.output_folder\n",
    "extractor_type = args.extractor_type\n",
    "num_epochs = args.num_epochs\n",
    "CV_n = args.CV_n\n",
    "rep_n = args.rep_n\n",
    "show_diagnosis_plt = bool(args.show_diagnosis_plt)\n",
    "\n",
    "with open('../../repo/falldetect/params.json') as json_file:\n",
    "    falldetect_params = json.load(json_file)\n",
    "\n",
    "cuda_i = falldetect_params['cuda_i']\n",
    "\n",
    "tasks_list = []\n",
    "for item in args.tasks_list.split(' '):\n",
    "    tasks_list.append((item.split('-')[0], item.split('-')[1]))\n",
    "    \n",
    "inputdir = input_folder+'/'\n",
    "outputdir = output_folder+'/'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "test_mode = 'test' in outputdir.split('/')[-2]\n",
    "\n",
    "device = torch.device('cuda:{}'.format(int(cuda_i)) if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RdfojPmJEB-"
   },
   "source": [
    "# new arch HP search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params_list = [\n",
    "#   {\n",
    "#     'HP_name': 'HP_i0',\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': CV_n,\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 16,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': extractor_type,\n",
    "# #     'device': device,\n",
    "#     'dropout': 0.5,\n",
    "#     'hiddenDim_f': 3,\n",
    "#     'hiddenDim_y': 3,\n",
    "#     'hiddenDim_d': 3,\n",
    "#     'win_size': 18,\n",
    "#     'win_stride': 6,\n",
    "#     'step_n': 9,\n",
    "#     'show_diagnosis_plt': show_diagnosis_plt,\n",
    "#   },\n",
    "\n",
    "#   {\n",
    "#     'HP_name': 'HP_i1',\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': CV_n,\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': extractor_type,\n",
    "# #     'device': device,\n",
    "#     'dropout': 0.5,\n",
    "#     'hiddenDim_f': 3,\n",
    "#     'hiddenDim_y': 3,\n",
    "#     'hiddenDim_d': 3,\n",
    "#     'win_size': 18,\n",
    "#     'win_stride': 6,\n",
    "#     'step_n': 9,\n",
    "#     'show_diagnosis_plt': show_diagnosis_plt,\n",
    "#   },\n",
    "\n",
    "#   {\n",
    "#     'HP_name': 'HP_i2',\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': CV_n,\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 64,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': extractor_type,\n",
    "# #     'device': device,\n",
    "#     'dropout': 0.5,\n",
    "#     'hiddenDim_f': 3,\n",
    "#     'hiddenDim_y': 3,\n",
    "#     'hiddenDim_d': 3,\n",
    "#     'win_size': 18,\n",
    "#     'win_stride': 6,\n",
    "#     'step_n': 9,\n",
    "#     'show_diagnosis_plt': show_diagnosis_plt,\n",
    "#   },\n",
    "    \n",
    "#   {\n",
    "#     'HP_name': 'HP_i3',\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': CV_n,\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'channel_n': 16,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': extractor_type,\n",
    "# #     'device': device,\n",
    "#     'dropout': 0.5,\n",
    "#     'hiddenDim_f': 3,\n",
    "#     'hiddenDim_y': 3,\n",
    "#     'hiddenDim_d': 3,\n",
    "#     'win_size': 18,\n",
    "#     'win_stride': 6,\n",
    "#     'step_n': 9,\n",
    "#     'show_diagnosis_plt': show_diagnosis_plt,\n",
    "#   },\n",
    "\n",
    "#   {\n",
    "#     'HP_name': 'HP_i4',\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': CV_n,\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'channel_n': 32,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'extractor_type': extractor_type,\n",
    "# #     'device': device,\n",
    "#     'dropout': 0.5,\n",
    "#     'hiddenDim_f': 3,\n",
    "#     'hiddenDim_y': 3,\n",
    "#     'hiddenDim_d': 3,\n",
    "#     'win_size': 18,\n",
    "#     'win_stride': 6,\n",
    "#     'step_n': 9,\n",
    "#     'show_diagnosis_plt': show_diagnosis_plt,\n",
    "#   },\n",
    "\n",
    "#   {\n",
    "#     'HP_name': 'HP_i5',\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': CV_n,\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'extractor_type': extractor_type,\n",
    "# #     'device': device,\n",
    "#     'dropout': 0.5,\n",
    "#     'hiddenDim_f': 3,\n",
    "#     'hiddenDim_y': 3,\n",
    "#     'hiddenDim_d': 3,\n",
    "#     'win_size': 18,\n",
    "#     'win_stride': 6,\n",
    "#     'step_n': 9,\n",
    "#     'show_diagnosis_plt': show_diagnosis_plt,\n",
    "#   },\n",
    "\n",
    "#   {\n",
    "#     'HP_name': 'HP_i6',\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': CV_n,\n",
    "#     'num_epochs': num_epochs,\n",
    "#     'channel_n': 4,\n",
    "#     'batch_size': 4,\n",
    "#     'learning_rate': 0.0001,\n",
    "#     'extractor_type': extractor_type,\n",
    "# #     'device': device,\n",
    "#     'dropout': 0.5,\n",
    "#     'hiddenDim_f': 3,\n",
    "#     'hiddenDim_y': 3,\n",
    "#     'hiddenDim_d': 3,\n",
    "#     'win_size': 18,\n",
    "#     'win_stride': 6,\n",
    "#     'step_n': 9,\n",
    "#     'show_diagnosis_plt': show_diagnosis_plt,\n",
    "#   }, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('aaa.json', 'w') as fout:\n",
    "#     json.dump(training_params_list, fout, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    with open('test_params_list.json') as json_file:\n",
    "        training_params_list = json.load(json_file)\n",
    "else:\n",
    "    with open('training_params_list.json') as json_file:\n",
    "        training_params_list = json.load(json_file)\n",
    "    \n",
    "for training_params in training_params_list:\n",
    "    training_params['CV_n'] = CV_n\n",
    "    training_params['num_epochs'] = num_epochs\n",
    "    training_params['extractor_type'] = extractor_type\n",
    "    training_params['device'] = device\n",
    "    training_params['show_diagnosis_plt'] = show_diagnosis_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rc2TiHRJIOu"
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchan2020/miniconda3/envs/FD_DAT/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning\n",
    "\n",
    "df_metric_keys = ['df_acc', 'df_sensitivity', 'df_precision', 'df_F1']\n",
    "\n",
    "for task_item in tasks_list:\n",
    "    (src_name, tgt_name) = task_item\n",
    "\n",
    "    task_outputdir = '{}{}_{}/'.format(outputdir, src_name, tgt_name)\n",
    "#     task_outputdir = home_dir + 'data_mic/{}/{}_{}/'.format(output_folder, src_name, tgt_name)\n",
    "    if not os.path.exists(task_outputdir):\n",
    "        os.makedirs(task_outputdir)\n",
    "    print('outputdir for stage2 {} output: {}'.format(task_item, task_outputdir))\n",
    "\n",
    "\n",
    "    df_sample = pd.DataFrame('', index=['channel_n', 'batch_size', 'learning_rate', \n",
    "                                              'source', 'DANN', 'target', 'domain', 'time_elapsed', 'num_params'], columns=[])\n",
    "    df_dict_agg_HP = dict( zip(df_metric_keys,[df_sample.copy(), df_sample.copy(), df_sample.copy(), df_sample.copy()]))\n",
    "\n",
    "\n",
    "  # 1. try all HP\n",
    "    for i, training_params in enumerate(training_params_list):\n",
    "\n",
    "        df_dict = performance_table(src_name, tgt_name, training_params, inputdir, task_outputdir)\n",
    "#         df_performance_table_sensitivity = df_dict['df_sensitivity']\n",
    "#         df_performance_table_agg_HP[training_params['HP_name']] = df_performance_table_sensitivity\n",
    "        \n",
    "        for df_name in df_dict_agg_HP.keys():\n",
    "            print('show', df_name)\n",
    "            df_dict_agg_HP[df_name][training_params['HP_name']] = df_dict[df_name].copy()\n",
    "            display(df_dict_agg_HP[df_name])\n",
    "        \n",
    "    # 2. agg all HP\n",
    "#     df_performance_table_agg_HP['HP_i3_1'] = df_performance_table_agg_HP['HP_i1']\n",
    "#     df_performance_table_agg_HP['HP_i5_1'] = df_performance_table_agg_HP['HP_i1']\n",
    "    \n",
    "    if test_mode:\n",
    "        pass\n",
    "    else:\n",
    "        for df_name in df_dict_agg_HP.keys():\n",
    "            df_dict_agg_HP[df_name]['HP_i3_1'] = df_dict_agg_HP[df_name]['HP_i1']\n",
    "            df_dict_agg_HP[df_name]['HP_i5_1'] = df_dict_agg_HP[df_name]['HP_i1']\n",
    "            display(df_dict_agg_HP[df_name])\n",
    "\n",
    "#     input()\n",
    "    \n",
    "    # 3. run optimal param for a task (based on dann sens.)\n",
    "    training_params_optimal = training_params.copy()\n",
    "    training_params_optimal['HP_name'] = 'HP_optimal'\n",
    "    if test_mode:\n",
    "        training_params_optimal['batch_size'] = 64\n",
    "        training_params_optimal['channel_n'] = 4\n",
    "        training_params_optimal['learning_rate'] = 0.01\n",
    "    else:\n",
    "        batch_size_optimal, channel_n_optimal, learning_rate_optimal = get_optimal(df_dict_agg_HP['df_sensitivity'])\n",
    "        training_params_optimal['batch_size'] = batch_size_optimal\n",
    "        training_params_optimal['channel_n'] = channel_n_optimal\n",
    "        training_params_optimal['learning_rate'] = learning_rate_optimal\n",
    "\n",
    "#     df_performance_table = performance_table(src_name, tgt_name, training_params_optimal, inputdir, task_outputdir)\n",
    "#     df_performance_table_agg_HP[training_params_optimal['HP_name']] = df_performance_table\n",
    "    df_dict = performance_table(src_name, tgt_name, training_params_optimal, inputdir, task_outputdir)\n",
    "#     df_performance_table_sensitivity = df_dict['df_sensitivity']\n",
    "#     df_performance_table_agg_HP[training_params_optimal['HP_name']] = df_performance_table_sensitivity\n",
    "\n",
    "    for df_name in df_dict_agg_HP.keys():\n",
    "        df_dict_agg_HP[df_name][training_params_optimal['HP_name']] = df_dict[df_name].copy()\n",
    "    \n",
    "#     df_performance_table_agg_HP = df_performance_table_agg_HP[['HP_i0','HP_i1','HP_i2','HP_i3','HP_i3_1','HP_i4','HP_i5','HP_i5_1','HP_i6','HP_optimal']]\n",
    "    if test_mode:\n",
    "        for df_name in df_dict_agg_HP.keys():\n",
    "            df_dict_agg_HP[df_name] = df_dict_agg_HP[df_name][['test_i0','test_i1']]\n",
    "    else:\n",
    "        for df_name in df_dict_agg_HP.keys():\n",
    "            df_dict_agg_HP[df_name] = df_dict_agg_HP[df_name][['HP_i0','HP_i1','HP_i2','HP_i3','HP_i3_1','HP_i4','HP_i5','HP_i5_1','HP_i6','HP_optimal']]\n",
    "\n",
    "\n",
    "\n",
    "    df_outputdir = task_outputdir+'HP_search/'\n",
    "    if not os.path.exists(df_outputdir):\n",
    "        os.makedirs(df_outputdir)\n",
    "    print('HP df_performance_table_agg saved at', df_outputdir)\n",
    "#     df_performance_table_agg_HP.to_csv(df_outputdir+'df_performance_table_agg_HP.csv', encoding='utf-8')\n",
    "    for df_name in df_dict_agg_HP.keys():\n",
    "        df_dict_agg_HP[df_name].to_csv(df_outputdir+'df_performance_table_agg_HP_{}.csv'.format(df_name.split('_')[1]), encoding='utf-8')\n",
    "\n",
    "\n",
    "    # Serialize data into file:\n",
    "    json.dump({key:val for key, val in training_params_optimal.items() if key != 'device'}, open(df_outputdir+'training_params_optimal.json', 'w'))\n",
    "\n",
    "#     display(df_performance_table_agg_HP)\n",
    "    for df_name in df_dict_agg_HP.keys():\n",
    "        print('show', df_name)\n",
    "        display(df_dict_agg_HP[df_name])\n",
    "    \n",
    "    df_sample = pd.DataFrame('', index=['channel_n', 'batch_size', 'learning_rate', \n",
    "                                        'source', 'DANN', 'target', 'domain', 'time_elapsed', 'num_params'], columns=[])\n",
    "    df_dict_agg_rep = dict( zip(df_metric_keys,[df_sample.copy(), df_sample.copy(), df_sample.copy(), df_sample.copy()]))\n",
    "\n",
    "    for i in range(0,rep_n):\n",
    "#         df_performance_table = performance_table(src_name, tgt_name, training_params_optimal, inputdir, task_outputdir)\n",
    "#         df_performance_table_agg_rep['rep_i{}'.format(i)] = df_performance_table\n",
    "        df_dict = performance_table(src_name, tgt_name, training_params_optimal, inputdir, task_outputdir)\n",
    "        for df_name in df_dict_agg_rep.keys():\n",
    "            df_dict_agg_rep[df_name]['rep_i{}'.format(i)] = df_dict[df_name].copy()\n",
    "\n",
    "    df_outputdir = task_outputdir+'repetitive_results/'\n",
    "    if not os.path.exists(df_outputdir):\n",
    "        os.makedirs(df_outputdir)\n",
    "    print('df_performance_table_agg_rep saved at', df_outputdir)\n",
    "\n",
    "#     sys.exit()\n",
    "#     df_performance_table_agg_rep.to_csv(df_outputdir+'df_performance_table_agg_rep.csv', encoding='utf-8')\n",
    "    for df_name in df_dict_agg_rep.keys():\n",
    "        df_dict_agg_rep[df_name] = get_rep_stats(df_dict_agg_rep[df_name], rep_n)\n",
    "        df_dict_agg_rep[df_name].to_csv(df_outputdir+'df_performance_table_agg_rep_{}.csv'.format(df_name.split('_')[1]), encoding='utf-8')\n",
    "\n",
    "    # Serialize data into file:\n",
    "    json.dump({key:val for key, val in training_params_optimal.items() if key != 'device'}, open(df_outputdir+'training_params_optimal.json', 'w'))\n",
    "\n",
    "#     display(df_performance_table_agg_rep)\n",
    "    for df_name in df_dict_agg_rep.keys():\n",
    "        print('show', df_name)\n",
    "        display(df_dict_agg_rep[df_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMUHTmGSnPEG+rEpBubjphB",
   "collapsed_sections": [],
   "name": "stage2_DANN_HPsearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (FD_DAT)",
   "language": "python",
   "name": "fd_dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
