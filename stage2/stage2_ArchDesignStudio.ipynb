{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27374,
     "status": "ok",
     "timestamp": 1586171966921,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "dR0gs1Ya0xmy",
    "outputId": "1c4a4193-695c-4447-ed1f-a6389500d78b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD6EM010PDWn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "# sys.path.append('~/project_FDDAT/repo/')\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "from falldetect.utilities import *\n",
    "from falldetect.models import *\n",
    "from falldetect.dataset_util import *\n",
    "from falldetect.training_util import *\n",
    "from falldetect.eval_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Plotting\n",
    "# checklist 1: comment inline, uncomment Agg\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwW5pmvqVMhg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get user inputs\n",
    "In ipython notebook, these are hardcoded. In production python code, use parsers to provide these inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FD_DAT')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--extractor_type', metavar='extractor_type', help='extractor_type',\n",
    "                    default='CNN')\n",
    "parser.add_argument('--num_epochs', type=int, metavar='num_epochs', help='number of epochs',\n",
    "                    default='5')\n",
    "parser.add_argument('--CV_n', type=int, metavar='CV_n', help='CV folds',\n",
    "                    default='2')\n",
    "parser.add_argument('--rep_n', type=int, metavar='rep_n', help='number of repitition',\n",
    "                    default='5')\n",
    "parser.add_argument('--cuda_i', type=int, metavar='cuda_i', help='cuda index',\n",
    "                    default='1')\n",
    "parser.add_argument('--tasks_list', metavar='tasks_list', help='a list of all tasks',\n",
    "                    default='UMAFall_waist_UPFall_belt UPFall_wrist_UMAFall_ankle')\n",
    "parser.add_argument('--show_diagnosis_plt', metavar='show_diagnosis_plt', help='show diagnosis plt or not',\n",
    "                    default='False')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split_mode = 'LOO'\n",
    "# split_mode = '5fold'\n",
    "\n",
    "# checklist 2: comment first line, uncomment second line seizures_FN\n",
    "# args = parser.parse_args(['--input_folder', '../../data_mic/stage1/preprocessed_WithoutNormal_18hz_5fold_aug', \n",
    "#                           '--output_folder', '../../data_mic/stage2/test',\n",
    "args = parser.parse_args(['--input_folder', '../../data_mic/stage1/preprocessed_WithoutNormal_18hz_5fold', \n",
    "                          '--output_folder', '../../data_mic/stage2/test',\n",
    "                          '--extractor_type', 'CNN',\n",
    "                          '--num_epochs', '15',\n",
    "#                           '--CV_n', '2',\n",
    "#                           '--rep_n', '2',\n",
    "#                           '--cuda_i', '2',\n",
    "                          '--show_diagnosis_plt', 'True',\n",
    "                          '--tasks_list', 'UPFall_wrist-UMAFall_wrist',])\n",
    "#                           '--tasks_list', 'UMAFall_waist-UMAFall_wrist UPFall_wrist-UMAFall_ankle',])\n",
    "                          \n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = home+'/project_FDDAT/'\n",
    "input_folder = args.input_folder\n",
    "output_folder = args.output_folder\n",
    "extractor_type = args.extractor_type\n",
    "num_epochs = args.num_epochs\n",
    "CV_n = args.CV_n\n",
    "rep_n = args.rep_n\n",
    "show_diagnosis_plt = bool(args.show_diagnosis_plt)\n",
    "\n",
    "with open('../../repo/falldetect/params.json') as json_file:\n",
    "    falldetect_params = json.load(json_file)\n",
    "cuda_i = falldetect_params['cuda_i']\n",
    "\n",
    "tasks_list = []\n",
    "for item in args.tasks_list.split(' '):\n",
    "    tasks_list.append((item.split('-')[0], item.split('-')[1]))\n",
    "    \n",
    "inputdir = input_folder+'/'\n",
    "outputdir = output_folder+'/'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "test_mode = 'test' in outputdir.split('/')[-2]\n",
    "\n",
    "device = torch.device('cuda:{}'.format(int(cuda_i)) if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'HP_name': 'hp',\n",
    "    'classes_n': 2,\n",
    "    'CV_n': CV_n,\n",
    "    'num_epochs': num_epochs,\n",
    "    'channel_n': 4,\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 0.001,\n",
    "    'extractor_type': extractor_type,\n",
    "    'device': device,\n",
    "    'dropout': 0.5,\n",
    "    'hiddenDim_f': 3,\n",
    "    'hiddenDim_y': 3,\n",
    "    'hiddenDim_d': 3,\n",
    "    'win_size': 18,\n",
    "    'win_stride': 6,\n",
    "    'step_n': 9,\n",
    "    'show_diagnosis_plt': show_diagnosis_plt,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Convolutional neural network (two convolutional layers)\n",
    "# class FeatureExtractor(nn.Module):\n",
    "#   def __init__(self, input_dim=50, channel_n=16):\n",
    "#       super(FeatureExtractor, self).__init__()\n",
    "#       self.layer1 = nn.Sequential(\n",
    "#           nn.Conv1d(3, channel_n, kernel_size=3, stride=1, padding=2),\n",
    "#           nn.BatchNorm1d(channel_n),\n",
    "#           nn.ReLU(),\n",
    "#           nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "#       self.layer2 = nn.Sequential(\n",
    "#           nn.Conv1d(channel_n, channel_n*2, kernel_size=3, stride=1, padding=2),\n",
    "#           nn.BatchNorm1d(channel_n*2),\n",
    "#           nn.ReLU(),\n",
    "#           nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "#       self.layer3 = nn.Sequential(\n",
    "#           nn.Conv1d(channel_n*2, channel_n*4, kernel_size=3, stride=1, padding=2),\n",
    "#           nn.BatchNorm1d(channel_n*4),\n",
    "#           nn.ReLU(),\n",
    "#           nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "      \n",
    "#       cnn_layer1_dim = (input_dim+2*2-1*(3-1)-1)+1\n",
    "#       pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#       cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n",
    "#       pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n",
    "        \n",
    "#       cnn_layer3_dim = (pool_layer2_dim+2*2-1*(3-1)-1)+1\n",
    "#       pool_layer3_dim = (cnn_layer3_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "# #       self.feature_out_dim = pool_layer2_dim*channel_n*2\n",
    "#       self.feature_out_dim = pool_layer3_dim*channel_n*2\n",
    "#       pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "#       print('FeatureExtractor_total_params:', pytorch_total_params)\n",
    "      \n",
    "#   def forward(self, x):\n",
    "#     out1 = self.layer1(x.float())\n",
    "#     out2 = self.layer2(out1)\n",
    "#     out2 = self.layer3(out2)\n",
    "#     out2 = out2.reshape(out2.size(0), -1)\n",
    "#     return out2\n",
    "\n",
    "\n",
    "# HIDDEN_DIM = 50\n",
    "# # fall classifier neural network (fc layers)\n",
    "# class ClassClassifier(nn.Module):\n",
    "#   def __init__(self, num_classes=10, input_dim=50):\n",
    "#       super(ClassClassifier, self).__init__()\n",
    "#       self.fc1 = nn.Linear(input_dim, HIDDEN_DIM)\n",
    "#       self.fc2 = nn.Linear(HIDDEN_DIM, num_classes)\n",
    "#       self.drop = nn.Dropout(p=0.5)\n",
    "#       self.relu = nn.ReLU()\n",
    "    \n",
    "#   def forward(self, x):\n",
    "# #     out1 = self.drop(self.relu(self.fc1(x.float())))\n",
    "#     out1 = self.relu(self.fc1(x.float()))\n",
    "#     out2 = self.fc2(out1)\n",
    "#     return out2\n",
    "\n",
    "# # domain classifier neural network (fc layers)\n",
    "# class DomainClassifier(nn.Module):\n",
    "#   def __init__(self, num_classes=10, input_dim=50):\n",
    "#       super(DomainClassifier, self).__init__()\n",
    "# #       self.fc = nn.Linear(input_dim, num_classes)\n",
    "#       self.fc1 = nn.Linear(input_dim, HIDDEN_DIM)\n",
    "#       self.fc2 = nn.Linear(HIDDEN_DIM, num_classes)\n",
    "#       self.drop = nn.Dropout(p=0.5)\n",
    "#       self.relu = nn.ReLU()\n",
    "      \n",
    "#   def forward(self, x, constant):\n",
    "#     out1 = GradReverse.grad_reverse(x.float(), constant)\n",
    "# #     out1 = self.drop(self.relu(self.fc1(out1)))\n",
    "#     out1 = self.relu(self.fc1(out1))\n",
    "#     out2 = self.fc2(out1)\n",
    "#     return out2\n",
    "#     # out2 = F.relu(self.fc(out1))\n",
    "# #     out2 = self.fc(out1)\n",
    "# #     return out2\n",
    "\n",
    "\n",
    "# class DannModel2(nn.Module):\n",
    "#   def __init__(self, device, class_N=2, domain_N=2, channel_n=16, input_dim=10):\n",
    "#     super(DannModel2, self).__init__()\n",
    "#     self.feature_extractor = FeatureExtractor(input_dim=input_dim, channel_n=channel_n).to(device).float()\n",
    "#     cnn_layer1_dim = (input_dim+2*2-1*(3-1)-1)+1\n",
    "#     pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#     cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n",
    "#     pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#     cnn_layer3_dim = (pool_layer2_dim+2*2-1*(3-1)-1)+1\n",
    "#     pool_layer3_dim = (cnn_layer3_dim-1*(2-1)-1)/2+1\n",
    "    \n",
    "#     feature_out_dim = int(pool_layer3_dim*channel_n*4)\n",
    "# #     feature_out_dim = int(pool_layer2_dim*channel_n*2)\n",
    "#     self.class_classfier = ClassClassifier(num_classes=class_N, input_dim=feature_out_dim).to(device).float()\n",
    "#     self.domain_classifier = DomainClassifier(num_classes=domain_N, input_dim=feature_out_dim).to(device).float()\n",
    "\n",
    "#     pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "#     print('DannModel_total_params:', pytorch_total_params)\n",
    "    \n",
    "\n",
    "#   def forward(self, x):\n",
    "#     feature_out = self.feature_extractor(x)\n",
    "#     class_output = self.class_classfier(feature_out)\n",
    "#     domain_output = self.domain_classifier(feature_out, 1)\n",
    "#     return feature_out, class_output, domain_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_CV = 0\n",
    "i_rep = 'rep0'\n",
    "# src_names = ['FARSEEING_lowback', 'FARSEEING_thigh']\n",
    "# src_names = ['UPFall_neck','UPFall_wrist','UPFall_belt','UPFall_rightpocket','UPFall_ankle',\n",
    "#              'UMAFall_chest','UMAFall_wrist','UMAFall_waist','UMAFall_leg','UMAFall_ankle',\n",
    "#              'SFDLA_chest','SFDLA_wrist','SFDLA_waist','SFDLA_thigh','SFDLA_ankle',\n",
    "#              'FARSEEING_lowback', 'FARSEEING_thigh']\n",
    "src_names = ['UPFall_neck','UPFall_wrist','UPFall_belt','UPFall_rightpocket','UPFall_ankle',\n",
    "             'UMAFall_chest','UMAFall_wrist','UMAFall_waist','UMAFall_leg','UMAFall_ankle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch(train_loader, val_loader, model, src_name, outputdir):\n",
    "    model.eval()\n",
    "\n",
    "    data = src_train_loader.dataset.data.to(device)\n",
    "    labels = src_train_loader.dataset.labels.to(device).long()\n",
    "    feature_out, class_out, _ = model(data)\n",
    "    out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "\n",
    "    model_pred = np.argmax(out_sigmoid, 1)\n",
    "    labels_np = labels.data.detach().cpu().numpy()\n",
    "    TP = ((model_pred==1) & (labels_np==1)).sum()\n",
    "    FN = ((model_pred==0) & (labels_np==1)).sum()\n",
    "    train_sensitivity = TP/(TP+FN)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 5), dpi=120)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(out_sigmoid[:,1],'.b', label='src_class_sigmoid', markersize=3)\n",
    "    ax1.plot(out_sigmoid[:,1].round(),'b', alpha=0.5, label='src_class_decision')\n",
    "    ax1.plot(labels.data.detach().cpu().numpy(),'r', alpha=0.5, label='src_class_labels')\n",
    "    ax1.axhline(0.5, color='k', label='threshold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_title('train', fontsize=20)\n",
    "\n",
    "    data = src_val_loader.dataset.data.to(device)\n",
    "    labels = src_val_loader.dataset.labels.to(device).long()\n",
    "    feature_out, class_out, _ = model(data)\n",
    "    out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "    \n",
    "    model_pred = np.argmax(out_sigmoid, 1)\n",
    "    labels_np = labels.data.detach().cpu().numpy()\n",
    "    TP = ((model_pred==1) & (labels_np==1)).sum()\n",
    "    FN = ((model_pred==0) & (labels_np==1)).sum()\n",
    "    val_sensitivity = TP/(TP+FN)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    ax2.plot(out_sigmoid[:,1],'.b', label='tgt_class_sigmoid', markersize=3)\n",
    "    ax2.plot(out_sigmoid[:,1].round(),'b', alpha=0.5, label='tgt_class_decision')\n",
    "    ax2.plot(labels.data.detach().cpu().numpy(),'r', alpha=0.5, label='tgt_class_labels')\n",
    "    ax2.axhline(0.5, color='k', label='threshold')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_title('val', fontsize=20)\n",
    "    \n",
    "    fig.suptitle('src_name: {} sensitivity ({:.3f}, {:.3f})'.format(src_name, train_sensitivity, val_sensitivity), fontsize=16)\n",
    "    fig.savefig(outputdir+'src_name.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_src_names_list = []\n",
    "results_train = {}\n",
    "results_val = {}\n",
    "    \n",
    "for src_name in src_names:\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('\\n\\nsrc_name: ', src_name)\n",
    "\n",
    "    # TODO: don't need to extract training_params\n",
    "    classes_n = training_params['classes_n']\n",
    "    CV_n = training_params['CV_n']\n",
    "    num_epochs = training_params['num_epochs']\n",
    "    channel_n = training_params['channel_n']\n",
    "    batch_size = training_params['batch_size']\n",
    "    learning_rate = training_params['learning_rate']\n",
    "    extractor_type = training_params['extractor_type']\n",
    "    device = training_params['device']\n",
    "    show_diagnosis_plt = training_params['show_diagnosis_plt']\n",
    "\n",
    "    src_dataset_name = src_name.split('_')[0]\n",
    "    src_sensor_loc = src_name.split('_')[1]\n",
    "\n",
    "\n",
    "    src_inputdir = inputdir + '{}/{}/{}/'.format(src_dataset_name, src_sensor_loc, i_rep)\n",
    "#     src_inputdir = inputdir + '{}/{}/{}/'.format('2_1.5', src_dataset_name, src_sensor_loc)\n",
    "#     tgt_inputdir = inputdir + '{}/{}/'.format(tgt_dataset_name, tgt_sensor_loc)\n",
    "\n",
    "\n",
    "    print('------------------------------Working on i_CV {}------------------------------'.format(i_CV))\n",
    "    # 1. prepare dataset\n",
    "    src_train_loader, src_val_loader = get_data_loader(src_inputdir, i_CV, batch_size, learning_rate)\n",
    "#     tgt_train_loader, tgt_val_loader = get_data_loader(tgt_inputdir, i_CV, batch_size, learning_rate)\n",
    "\n",
    "    # the model expect the same input dimension for src and tgt data\n",
    "    src_train_size = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "    src_val_size = src_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "\n",
    "    src_input_dim = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n",
    "\n",
    "    # 2. prepare model\n",
    "\n",
    "    total_step = len(src_train_loader)\n",
    "\n",
    "    train_performance_dict_list = list( {} for i in range(num_epochs) )\n",
    "    val_src_performance_dict_list = list( {} for i in range(num_epochs) )\n",
    "\n",
    "    if extractor_type == 'CNN':\n",
    "        model = DannModel(device, class_N=classes_n, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "#         model = DannModel(device, class_N=classes_n, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "    elif extractor_type == 'CNNLSTM':\n",
    "        dropout = training_params['dropout']\n",
    "        hiddenDim_f = training_params['hiddenDim_f']\n",
    "        hiddenDim_y = training_params['hiddenDim_y']\n",
    "        hiddenDim_d = training_params['hiddenDim_d']\n",
    "        win_size = training_params['win_size']\n",
    "        win_stride = training_params['win_stride']\n",
    "        step_n = training_params['step_n']\n",
    "        model = CnnLstm(device, class_N=classes_n, channel_n=channel_n, dropout=dropout, hiddenDim_f=hiddenDim_f, hiddenDim_y=hiddenDim_y, hiddenDim_d=hiddenDim_d, win_size=win_size, win_stride=win_stride, step_n=step_n).to(device)\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    # loss and optimizer\n",
    "    class_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "#     plot_epoch(src_train_loader, src_val_loader, model)\n",
    "    # 3. fit the model\n",
    "    for epoch in range(num_epochs):\n",
    "        train_performance_dict = train_epoch(src_train_loader, device, model, class_criterion, optimizer, epoch)\n",
    "                \n",
    "        train_performance_dict = val_epoch(src_train_loader, device, model, class_criterion, optimizer, epoch, 'src')\n",
    "        train_performance_dict_list[epoch] = train_performance_dict\n",
    "\n",
    "        val_src_performance_dict = val_epoch(src_val_loader, device, model, class_criterion, optimizer, epoch, 'src')\n",
    "        val_src_performance_dict_list[epoch] = val_src_performance_dict\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    plot_epoch(src_train_loader, src_val_loader, model, src_name, outputdir)\n",
    "    \n",
    "\n",
    "    print(src_name, train_performance_dict_list[epoch]['src_sensitivity'])\n",
    "    results_train[src_name] =  train_performance_dict_list[epoch]['src_sensitivity']\n",
    "    results_val[src_name] =  val_src_performance_dict_list[epoch]['src_sensitivity']\n",
    "    \n",
    "    if train_performance_dict_list[epoch]['src_sensitivity'] < 0.7:\n",
    "        print('{} is bad src'.format(src_name))\n",
    "        bad_src_names_list.append(src_name)\n",
    "        \n",
    "    time_elapsed = time.time() - start_time\n",
    "\n",
    "    print('time elapsed:', time.strftime(\"%H:%M:%S\", time.gmtime(time_elapsed)))\n",
    "\n",
    "#     if src_name == 'UPFall_wrist':\n",
    "#         sys.exit()\n",
    "\n",
    "        \n",
    "print('bad_src_names_list:', bad_src_names_list)\n",
    "print('train results')\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results_train)\n",
    "print('val results')\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amhwi5lZJA5V"
   },
   "source": [
    "# functions developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpitQXMDlURn"
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# # device = torch.device('cpu')\n",
    "# print('show GPU device name:', torch.cuda.get_device_name(0))\n",
    "# model_1 = FeatureExtractor(input_dim=66).to(device).float()\n",
    "\n",
    "# # test_input = torch.randn((8, 3, 66), dtype=torch.double)\n",
    "\n",
    "# # test_input = test_input.to(device)\n",
    "#     # labels = labels.to(device).long()\n",
    "\n",
    "# feature_out = model_1(test_input)\n",
    "# print('show model_1 output size:', feature_out.size())\n",
    "\n",
    "# feature_out.data.detach().cpu().numpy()\n",
    "\n",
    "# feature_out_dim =  feature_out.size()[1]\n",
    "# model_2 = ClassClassifier(num_classes=2, input_dim=feature_out_dim).to(device).float()\n",
    "# model_3 = DomainClassifier(num_classes=2, input_dim=feature_out_dim).to(device).float()\n",
    "\n",
    "# model_2_out = model_2(feature_out)\n",
    "# print('show model_2 output size:', model_2_out.size())\n",
    "\n",
    "# model_3_out = model_3(feature_out, 1)\n",
    "# print('show model_3 output size:', model_3_out.size())\n",
    "\n",
    "# model_4 = CascadedModel(model_1, model_2)\n",
    "# # model_4 = nn.Sequential(model_1, model_2)\n",
    "\n",
    "# print('model_4 output size', model_4(test_input).size())\n",
    "\n",
    "# dann = DannModel(device, class_N=2, domain_N=2, channel_n=5, input_dim=66).to(device).float()\n",
    "# feature_out, class_output, domain_output = dann(test_input)\n",
    "# print('dann output size', feature_out.size(), class_output.size(), domain_output.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ah2MW37CCWtR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1avdeEhyCWrS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNIrQ3McJFn0"
   },
   "source": [
    "\n",
    "# testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eUtQpb4JRCy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEJIJK9wJRAs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tbn2zdvRJQ96"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvZq_sZhJQ6y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "soPxNFfuJRx3"
   },
   "source": [
    "# fixing DannModel_fitting WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGUsfWNDCWkq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oy_4AJnWCWiR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1e5p1K_-pVsH"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torchvision.models\n",
    "# import collections\n",
    "# import math\n",
    "# import sys\n",
    "\n",
    "# class lstmnet(nn.Module):\n",
    "#     r\"\"\"lstmnet is a simple recurrent neural network that contains one \n",
    "#     hidden layer of 64 nodes with 3 time steps by default. It expects \n",
    "#     an input of 3D tensor with a dimension (batch, time_step, \n",
    "#     input_size). The output will be a 2D tensor with a dimension (N, 2).\n",
    "\n",
    "#     Args:\n",
    "#         - None. The variables used for each sub-layer are hard-coded\n",
    "#     Shape:\n",
    "#         - Input: :math:`(batch, time_step, input_size)`\n",
    "#         - Output: :math:`(batch, output_size)`\n",
    "#     Examples::\n",
    "#         >>> m = lstmnet()\n",
    "#         >>> batchSize = 16\n",
    "#         >>> featDim = 10\n",
    "#         >>> timeStep = 3\n",
    "#         >>> input = torch.randn(batchSize, timeStep, featDim)\n",
    "#         >>> output = m(input)\n",
    "#         >>> output.size()\n",
    "#             (16, 2)\n",
    "#     \"\"\"\n",
    "#     def __init__(self, inputDim=10, hiddenDim=64, outputDim=2, ):\n",
    "#         super(lstmnet, self).__init__()\n",
    "#         self.outputDim = outputDim\n",
    "\n",
    "#         self.lstm = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "#             input_size=int((inputDim-2)/3),\n",
    "#             hidden_size=hiddenDim,         # rnn hidden unit\n",
    "#             num_layers=2,           # number of rnn layer\n",
    "#             batch_first=True,       # input & output will has batch size as 1st dimension. e.g. (batch, time_step, input_size)\n",
    "#             bidirectional=True,\n",
    "#             dropout=0.5\n",
    "#         )\n",
    "\n",
    "#         self.fc1 = nn.Linear(hiddenDim*2+2, 25)\n",
    "#         self.fc2 = nn.Linear(25, outputDim)\n",
    "#         self.relu = nn.ReLU(inplace=False)\n",
    "#         self.lsm = nn.LogSoftmax(dim=1)\n",
    "# #         self.bn = nn.BatchNorm1d(10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#       # x shape (time_step, batch, input_size, channel_n), float tensor\n",
    "#       # r_out shape (time_step, batch, lstm_output_size)\n",
    "#       # h_n shape (n_layers, batch, hidden_size)\n",
    "#       # h_c shape (n_layers, batch, hidden_size)\n",
    "#       # out shape (batch, output_size)\n",
    "#       x = x.float()\n",
    "\n",
    "#       timestep_n = x.size()[0]\n",
    "#       batch_n = x.size()[1]\n",
    "#       input_size = x.size()[2]\n",
    "#       out1_size = x.size()[2]\n",
    "#       channel_n =  x.size()[3]\n",
    "      \n",
    "#       out1 = torch.randn(timestep_n, , , dtype=torch.double)\n",
    "\n",
    "#       # None represents zero initial hidden state, so don't have to implement initHidden\n",
    "#       for timestep in range(timestep_n:\n",
    "#         out1[timestep,:,:,:] = self.layer1(x[timestep,:,:,:])\n",
    "\n",
    "\n",
    "#         out_freq_x, (h_n, h_c) = self.lstm(x[:,:,:], None)\n",
    "#         out_freq_y, (h_n, h_c) = self.lstm(x[:,:,100:200], None)\n",
    "#         out_freq_z, (h_n, h_c) = self.lstm(x[:,:,200:300], None)\n",
    "        \n",
    "#         out_flstm = out_freq_x + out_freq_y + out_freq_z # torch.Size([16, 5, 128])\n",
    "# #         print('size of out_flstm is ', out_flstm.size())\n",
    "\n",
    "#         out_cat = torch.cat((out_flstm, x[:,:,-2:]), 2)\n",
    "# #         out_cat = out_flstm\n",
    "\n",
    "#         out = torch.randn(x.size()[0], x.size()[1], self.outputDim, dtype=torch.double)\n",
    "\n",
    "#         # in this implementation, outputs from all timesteps are used for loss and back prop\n",
    "#         for timestep in range(out_cat.size()[1]):\n",
    "#             out_step = self.relu(self.fc1(out_cat[:, timestep, :]))\n",
    "#             out_step = self.fc2(out_step)\n",
    "# #             out_step = self.fc(out_cat[timestep, :, :])\n",
    "#             out[:, timestep, :] = self.lsm(out_step)\n",
    "            \n",
    "#         debug = False\n",
    "#         if debug == True:\n",
    "#             print('-----------------------------')\n",
    "#             print('size of x is ', x.size())\n",
    "#             print('size of out_freq_x is ', out_freq_x.size())\n",
    "#             print('size of h_n is ', h_n.size())\n",
    "#             print('size of h_c is ', h_c.size())\n",
    "#             print('size of out_cat is ', out_cat.size())\n",
    "#             print('size of out_step is ', out_step.size())\n",
    "#             print('size of out is ', out.size())\n",
    "#             print('-----------------------------')\n",
    "#             sys.exit()\n",
    "\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQXX-AwxpTuf"
   },
   "outputs": [],
   "source": [
    "# # Convolutional neural network (two convolutional layers)\n",
    "# class ConvNet2(nn.Module):\n",
    "#     def __init__(self, class_N=2, channel_n=16, input_dim=10, p=0.5):\n",
    "#         super(ConvNet2, self).__init__()\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv1d(3, channel_n, kernel_size=3, stride=1, padding=2),\n",
    "#             nn.BatchNorm1d(channel_n),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv1d(channel_n, channel_n, kernel_size=3, stride=1, padding=2),\n",
    "#             nn.BatchNorm1d(channel_n),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "#         # self.layer3 = nn.Sequential(\n",
    "#         #     nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=2),\n",
    "#         #     nn.BatchNorm1d(64),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "#         cnn_layer1_dim = (input_dim+2*2-1*(3-1)-1)+1\n",
    "#         pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#         # cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n",
    "#         # pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#         # cnn_layer3_dim = (pool_layer2_dim+2*2-1*(3-1)-1)+1\n",
    "#         # pool_layer3_dim = (cnn_layer3_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#         # print('cnn_layer1_dim:', cnn_layer1_dim)\n",
    "#         # print('pool_layer1_dim:', pool_layer1_dim)\n",
    "#         # print('cnn_layer2_dim:', cnn_layer2_dim)\n",
    "#         # print('pool_layer2_dim:', pool_layer2_dim)\n",
    "#         # print('cnn_layer3_dim:', cnn_layer3_dim)\n",
    "#         # print('pool_layer3_dim:', pool_layer3_dim)\n",
    "#         # fc_dim = int(((((input_dim)+2*2-1)/2+2*2-1)/2+2*2-1)/2*64)\n",
    "#         self.fc1 = nn.Linear(int(pool_layer1_dim)*channel_n, 50)\n",
    "#         self.drop_out = nn.Dropout(p=0)\n",
    "#         self.fc2 = nn.Linear(50, class_N)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#       out1 = self.layer1(x.float())\n",
    "#       # print('out1 size:', out1.size())\n",
    "#       # out2 = self.layer2(out1)\n",
    "#       # print('out2 size:', out2.size())\n",
    "#       # out3 = self.layer3(out2)\n",
    "#       # print('out3 size:', out3.size())\n",
    "#       # print('out2 size:', out2.size())\n",
    "#       out1 = out1.reshape(out1.size(0), -1)\n",
    "#       # print('out2 size:', out2.size())\n",
    "#       out1 = self.drop_out(out1)\n",
    "#       out2 = self.fc1(out1)\n",
    "#       out3 = self.fc2(out2)\n",
    "#       # print('x, out1, out2, out 3, out4 size',  x.size(), out1.size(), out2.size(), out3.size(), out4.size())\n",
    "#       return out1, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLJNv0EXEfH-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuLbnqA6Xwgm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yCS6WL4kSGL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqlC22yVW6hp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5zQmLdUGkBw"
   },
   "outputs": [],
   "source": [
    "# def train_epoch(train_loader, train_size, device, model, criterion, optimizer, epoch):\n",
    "#   total_train_loss = 0\n",
    "#   train_TPTF = 0\n",
    "#   debug = False\n",
    "#   for i, (data, labels) in enumerate(train_loader):\n",
    "\n",
    "#     data = data.to(device)\n",
    "#     labels = labels.to(device).long()\n",
    "\n",
    "#     # Forward pass\n",
    "#     # feature_out, class_out = model(data)\n",
    "#     feature_out, class_out, _ = model(data)\n",
    "\n",
    "#     train_loss = criterion(class_out, labels)\n",
    "\n",
    "#     # Backward and optimize\n",
    "#     optimizer.zero_grad()\n",
    "#     train_loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # total_train_loss += train_loss.data.numpy()\n",
    "#     total_train_loss += train_loss.data.detach().cpu().numpy()\n",
    "#     out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "#     train_pred = np.argmax(out_sigmoid, 1)\n",
    "#     train_TPTF += (train_pred==labels.data.detach().cpu().numpy()).sum()\n",
    "\n",
    "#     #######################\n",
    "#     if debug:\n",
    "#       print('Epoch [{}/{}] Step [{}/{}]:'\n",
    "#             'train_loss={:.5f} train_acc={:.5f}'\n",
    "#             .format(epoch + 1,\n",
    "#                     20,\n",
    "#                     i + 1,\n",
    "#                     len(train_loader),\n",
    "#                     train_loss,\n",
    "#                     (train_pred==labels.data.detach().cpu().numpy()).sum()))\n",
    "#     #######################\n",
    "                \n",
    "#   train_loss = total_train_loss/train_size\n",
    "#   train_acc = train_TPTF/train_size\n",
    "\n",
    "#   return train_loss, train_acc\n",
    "\n",
    "# def val_epoch(val_loader, val_size, device, model, criterion, optimizer, epoch):\n",
    "#   total_val_loss = 0\n",
    "#   val_TPTF = 0\n",
    "#   debug = False\n",
    "  \n",
    "#   for i, (data, labels) in enumerate(val_loader):\n",
    "#     data = data.to(device)\n",
    "#     labels = labels.to(device).long()\n",
    "    \n",
    "#     #Forward pass\n",
    "#     # feature_out, class_out = model(data)\n",
    "#     feature_out, class_out, _ = model(data)\n",
    "#     val_loss = criterion(class_out, labels)\n",
    "    \n",
    "#     total_val_loss += val_loss.data.detach().cpu().numpy()\n",
    "#     out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "#     val_pred = np.argmax(out_sigmoid, 1)\n",
    "#     val_TPTF += (val_pred==labels.data.detach().cpu().numpy()).sum()\n",
    "\n",
    "#     #######################\n",
    "#     if debug:\n",
    "#       print('Epoch [{}/{}] Step [{}/{}]:'\n",
    "#             'val_loss={:.5f} val_acc={:.5f}'\n",
    "#             .format(epoch + 1,\n",
    "#                     20,\n",
    "#                     i + 1,\n",
    "#                     len(val_loader),\n",
    "#                     val_loss,\n",
    "#                     (val_pred==labels.data.detach().cpu().numpy()).sum()))\n",
    "#     #######################\n",
    "\n",
    "#   val_loss = total_val_loss/val_size\n",
    "#   val_acc = val_TPTF/val_size\n",
    "\n",
    "#   return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3-u-rG8Gj_d"
   },
   "outputs": [],
   "source": [
    "# def ConvNet2Model_fitting(training_params, src_name, tgt_name, inputdir, outputdir): \n",
    "#   show_train_log = False\n",
    "\n",
    "#   if not os.path.exists(outputdir):\n",
    "#       os.makedirs(outputdir)\n",
    "      \n",
    "#   classes_n = training_params['classes_n']\n",
    "#   CV_n = training_params['CV_n']\n",
    "#   num_epochs = training_params['num_epochs']\n",
    "#   channel_n = training_params['channel_n']\n",
    "#   batch_size = training_params['batch_size']\n",
    "#   learning_rate = training_params['learning_rate']\n",
    "#   dropout_p = training_params['dropout_p']\n",
    "\n",
    "#   df_performance = pd.DataFrame(columns=['i_CV',\n",
    "#                                           'train_loss','train_acc','val_loss','val_acc', 'tgt_val_loss', 'tgt_val_acc'])\n",
    "\n",
    "#   src_dataset_name = src_name.split('_')[0]\n",
    "#   src_sensor_loc = src_name.split('_')[1]\n",
    "\n",
    "#   tgt_dataset_name = tgt_name.split('_')[0]\n",
    "#   tgt_sensor_loc = tgt_name.split('_')[1]\n",
    "\n",
    "#   src_inputdir = inputdir + '{}/{}/'.format(src_dataset_name, src_sensor_loc)\n",
    "#   tgt_inputdir = inputdir + '{}/{}/'.format(tgt_dataset_name, tgt_sensor_loc)\n",
    "\n",
    "\n",
    "#   for i_CV in range(CV_n):\n",
    "#     # 1. prepare dataset\n",
    "#     src_train_loader, src_val_loader = get_UMAFall_loader(src_inputdir, i_CV, batch_size, learning_rate)\n",
    "#     tgt_train_loader, tgt_val_loader = get_UPFall_loader(tgt_inputdir, i_CV, batch_size, learning_rate)\n",
    "\n",
    "#     # the model expect the same input dimension for src and tgt data\n",
    "#     src_train_size = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "#     src_val_size = src_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "\n",
    "#     tgt_train_size = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "#     tgt_val_size = tgt_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "\n",
    "#     src_input_dim = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n",
    "#     tgt_input_dim = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n",
    "\n",
    "#     # 2. prepare model\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     # loss and optimizer\n",
    "#     # criterion = nn.CrossEntropyLoss()\n",
    "#     class_criterion = nn.CrossEntropyLoss()\n",
    "#     # domain_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#     # 3. fit the model\n",
    "#     total_step = len(src_train_loader)\n",
    "\n",
    "#     train_loss_avg_epochs = np.zeros(num_epochs)\n",
    "#     train_class_acc_epochs = np.zeros(num_epochs)\n",
    "#     val_src_loss_avg_epochs = np.zeros(num_epochs)\n",
    "#     val_src_class_acc_epochs = np.zeros(num_epochs)\n",
    "#     val_tgt_loss_avg_epochs = np.zeros(num_epochs)\n",
    "#     val_tgt_class_acc_epochs = np.zeros(num_epochs)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "\n",
    "#       # if training_mode == 'source':\n",
    "#       # model = BaselineModel(device, class_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "#       # model = ConvNet2(class_N=2, channel_n=16, input_dim=66, p=dropout_p).to(device).float()\n",
    "#       model = DannModel(device, class_N=2, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "#       model_name = model.__class__.__name__\n",
    "#       optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "#       # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#       train_loss, train_acc = train_epoch(src_train_loader, src_train_size, device, model, class_criterion, optimizer, epoch)\n",
    "#       train_loss_avg_epochs[epoch] = train_loss\n",
    "#       train_class_acc_epochs[epoch] = train_acc\n",
    "\n",
    "#       val_loss, val_acc = val_epoch(src_val_loader, src_val_size, device, model, class_criterion, optimizer, epoch)\n",
    "#       val_src_loss_avg_epochs[epoch] = val_loss\n",
    "#       val_src_class_acc_epochs[epoch] = val_acc\n",
    "\n",
    "#       tgt_val_loss, tgt_val_acc = val_epoch(tgt_val_loader, tgt_val_size, device, model, class_criterion, optimizer, epoch)\n",
    "#       val_tgt_loss_avg_epochs[epoch] = tgt_val_loss\n",
    "#       val_tgt_class_acc_epochs[epoch] = tgt_val_acc\n",
    "\n",
    "#       if show_train_log:\n",
    "#         print('Epoch {}'.format(epoch))\n",
    "#         print('Train Loss: {:.6f}, Train ACC: {:.6f}, Val loss = {:.6f}, Val ACC: {:.6f}'.\n",
    "#               format(train_loss, train_acc, val_loss, val_acc))\n",
    "#         print('Target Val loss = {:.6f}, Val ACC: {:.6f}'.format(tgt_val_loss, tgt_val_acc))\n",
    "\n",
    "#       # 4. store the performance of the model at the last epoch\n",
    "#       df_performance.loc[i_CV] = [i_CV, train_loss, train_acc, val_loss, val_acc, tgt_val_loss, tgt_val_acc]\n",
    "    \n",
    "#     fig = plt.figure(figsize=(10, 3), dpi=80)\n",
    "#     ax1 = fig.add_subplot(1, 2, 1)\n",
    "#     ax1.set_title('loss_avg_epochs')\n",
    "#     ax1.set_xlabel('epoch')\n",
    "#     ax1.plot(np.arange(num_epochs), train_loss_avg_epochs, color='blue', label='train')\n",
    "#     ax1.plot(np.arange(num_epochs), val_src_loss_avg_epochs, color='red', label='val_src')\n",
    "#     ax1.plot(np.arange(num_epochs), val_tgt_loss_avg_epochs, color='green', label='val_tgt')\n",
    "#     ax1.legend(loc=\"upper right\")\n",
    "#     ax2 = fig.add_subplot(1, 2, 2)\n",
    "#     ax2.set_title('class_acc_epochs')\n",
    "#     ax2.set_xlabel('epoch')\n",
    "#     ax2.plot(np.arange(num_epochs), train_class_acc_epochs, color='blue', label='train')\n",
    "#     ax2.plot(np.arange(num_epochs), val_src_class_acc_epochs, color='red', label='val_src')\n",
    "#     ax2.plot(np.arange(num_epochs), val_tgt_class_acc_epochs, color='green', label='val_tgt')\n",
    "#     ax2.legend(loc=\"upper right\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     print('=================Exporting pytorch model=================')\n",
    "#     # loaded_model = ConvNet2(class_N=2, channel_n=16, input_dim=66, p=dropout_p).to(device).float()\n",
    "#     loaded_model = DannModel(device, class_N=2, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "#     export_model(model, loaded_model, outputdir+'model_CV{}'.format(i_CV))\n",
    "#     print('=========================================================')\n",
    "\n",
    "#   # 5. export model performance as df\n",
    "#   print('===============Exporting model performance===============')\n",
    "#   export_perofmance(df_performance, CV_n, outputdir)\n",
    "\n",
    "#   print('src val loss: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_loss'], df_performance.loc['std']['val_loss']))\n",
    "#   print('src val acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_acc'], df_performance.loc['std']['val_acc']))\n",
    "  \n",
    "#   print('tgt val loss: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['tgt_val_loss'], df_performance.loc['std']['tgt_val_loss']))\n",
    "#   print('tgt val acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['tgt_val_acc'], df_performance.loc['std']['tgt_val_acc']))\n",
    "\n",
    "#   print('=========================================================')\n",
    "\n",
    "#   # 6. export notebook parameters as dict\n",
    "#   # datetime object containing current date and time\n",
    "#   print('==============Exporting notebook parameters==============')\n",
    "#   now = datetime.now()\n",
    "#   dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "#   samples_n = src_train_size + src_val_size\n",
    "\n",
    "#   param_dict = {\n",
    "#       'CV_n': CV_n,\n",
    "#       'samples_n': samples_n,\n",
    "#       'classes_n': classes_n,\n",
    "#       'model_name': model_name,\n",
    "#       'dataset_name': src_dataset_name,\n",
    "#       'sensor_loc': src_sensor_loc,\n",
    "#       'date': dt_string,\n",
    "#       'batch_size': batch_size,\n",
    "#       'input_dim': (batch_size, src_train_loader.dataset.data.size()[1], src_train_loader.dataset.data.size()[2]),\n",
    "#       'output_dim': src_train_loader.dataset.labels[0:batch_size].data.detach().cpu().numpy().shape,\n",
    "#       'label_dim': CV_n,\n",
    "#   }\n",
    "#   print(param_dict)\n",
    "\n",
    "#   with open(outputdir+'notebook_param.json', 'w') as fp:\n",
    "#     json.dump(param_dict, fp)\n",
    "#   print('=========================================================')\n",
    "\n",
    "#   return (df_performance.loc['mean']['val_acc'], df_performance.loc['std']['val_acc']), (df_performance.loc['mean']['tgt_val_acc'], df_performance.loc['std']['tgt_val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gfQua3gGj83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwNPLlA8HoWr"
   },
   "outputs": [],
   "source": [
    "# # tasks_list = [('UMAFall_wrist', 'UPFall_wrist')]\n",
    "# tasks_list = [('UMAFall_waist', 'UPFall_belt')]\n",
    "\n",
    "# # optimal_training_params = {\n",
    "# #     'classes_n': 2,\n",
    "# #     'CV_n': 5,\n",
    "# #     'num_epochs': 3,\n",
    "# #     'channel_n': 32,\n",
    "# #     'batch_size': 1,\n",
    "# #     'learning_rate': 0.01}\n",
    "\n",
    "# training_params = {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 5,\n",
    "#     'num_epochs': 20,\n",
    "#     'channel_n': 2,\n",
    "#     'batch_size': 1,\n",
    "#     'learning_rate': 0.01,\n",
    "#     'dropout_p': 0.2}\n",
    "\n",
    "# for task_item in tasks_list:\n",
    "#   (src_name, tgt_name) = task_item\n",
    "\n",
    "#   inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "#   outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_archdesign_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "#   if not os.path.exists(outputdir):\n",
    "#       os.makedirs(outputdir)\n",
    "#   print('outputdir for stage2 output:', outputdir)\n",
    "  \n",
    "#   source_outputs = ConvNet2Model_fitting(training_params, src_name, tgt_name, inputdir, outputdir+'source/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FUoXUwbHoS4"
   },
   "outputs": [],
   "source": [
    "# source_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A66bXfcDHoP8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mfs_IpRkHoLm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRx6_kUvHoIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDVBXu0i4ZNB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2Z4tKb2_0Nq"
   },
   "source": [
    "# Start CV training and validation in a big phat loop (to be deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZlGwYngxAhw"
   },
   "outputs": [],
   "source": [
    "# def model_fitting(CV_n, classes_n, sensor_loc, dataset_name, inputdir): \n",
    "#   # it's big phat loop i don't like it qq\n",
    "#   df_performance = pd.DataFrame(columns=['i_CV','train_loss','train_acc','val_loss','val_acc'])\n",
    "\n",
    "#   for i_CV in range(CV_n):\n",
    "#     # 1. prepare dataset\n",
    "#     train_inputdir = inputdir+'/CV{}/train'.format(i_CV)\n",
    "#     val_inputdir = inputdir+'/CV{}/val'.format(i_CV)\n",
    "\n",
    "#     train_data = data_loader('data', train_inputdir).transpose(2,1,0)\n",
    "#     val_data = data_loader('data', val_inputdir).transpose(2,1,0)\n",
    "\n",
    "#     train_labels = data_loader('labels', train_inputdir)\n",
    "#     val_labels = data_loader('labels', val_inputdir)\n",
    "\n",
    "#     train_i_sub = data_loader('i_sub', train_inputdir)\n",
    "#     val_i_sub = data_loader('i_sub', val_inputdir)\n",
    "\n",
    "#     print('train_data shape:', train_data.shape)\n",
    "#     print('val_data shape:', val_data.shape)\n",
    "\n",
    "#     train_size = train_labels.shape[0]\n",
    "#     val_size = val_labels.shape[0]\n",
    "#     input_dim = train_data.shape[2]\n",
    "\n",
    "#     # convert labels from multi-class activities to binary (fall/ADL)\n",
    "#     train_labels_binary = ((train_labels==10)|(train_labels==11)|(train_labels==12)).astype(int)\n",
    "#     val_labels_binary = ((val_labels==10)|(val_labels==11)|(val_labels==12)).astype(int)\n",
    "\n",
    "#     train_dataset = FallDataset(train_data, train_labels_binary)\n",
    "#     val_dataset = FallDataset(val_data, val_labels_binary)\n",
    "#     # data loader\n",
    "#     batch_size = 4\n",
    "#     learning_rate = 0.001\n",
    "\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                               batch_size=batch_size, \n",
    "#                                               shuffle=True)\n",
    "\n",
    "#     val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "#                                               batch_size=batch_size, \n",
    "#                                               shuffle=False)\n",
    "\n",
    "#     # 2. prepare model\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     model = ConvNet(num_classes=classes_n, input_dim=input_dim).to(device).float()\n",
    "\n",
    "#     # loss and optimizer\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # test model on a batch\n",
    "#     try:\n",
    "#       out = model(train_dataset.data[0:batch_size,:,:])\n",
    "#       model_outdim = out.data.numpy().shape\n",
    "#     except:\n",
    "#       print('Warning: model cannot read input')\n",
    "\n",
    "#     print('{} model architecture: '.format(model.__class__.__name__))\n",
    "#     print(model)\n",
    "\n",
    "\n",
    "#     # 3. fit the model\n",
    "#     num_epochs = 10\n",
    "#     total_step = len(train_loader)\n",
    "#     for epoch in range(num_epochs):\n",
    "#       total_train_loss = 0\n",
    "#       train_TPTF = 0\n",
    "#       for i, (data, labels) in enumerate(train_loader):\n",
    "#         data = data.to(device)\n",
    "#         labels = labels.to(device).long()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(data)\n",
    "#         train_loss = criterion(outputs, labels)\n",
    "#         total_train_loss += train_loss.data.numpy()\n",
    "        \n",
    "#         out_sigmoid = torch.sigmoid(outputs).data.numpy()\n",
    "#         train_pred = np.argmax(out_sigmoid, 1)\n",
    "#         train_TPTF += (train_pred==labels.data.numpy()).sum()\n",
    "#         # train_pred = print(np.argmax(F.sigmoid(outputs))\n",
    "\n",
    "\n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # if (i+1) % 5 == 0:\n",
    "#         #     print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.8f}' \n",
    "#         #             .format(epoch+1, num_epochs, i+1, total_step, train_loss.data.numpy()/labels.size()[0]))\n",
    "\n",
    "#       total_val_loss = 0\n",
    "#       val_TPTF = 0\n",
    "#       for i, (data, labels) in enumerate(val_loader):\n",
    "#         data = data.to(device)\n",
    "#         labels = labels.to(device).long()\n",
    "        \n",
    "#         #Forward pass\n",
    "#         val_outputs = model(data)\n",
    "#         val_loss = criterion(val_outputs, labels)\n",
    "#         total_val_loss += val_loss.data.numpy()\n",
    "\n",
    "#         out_sigmoid = torch.sigmoid(val_outputs).data.numpy()\n",
    "#         val_pred = np.argmax(out_sigmoid, 1)\n",
    "#         val_TPTF += (val_pred==labels.data.numpy()).sum()\n",
    "#         # print(val_TPTF, len(val_loader))\n",
    "          \n",
    "#       train_loss = total_train_loss/train_size\n",
    "#       train_acc = train_TPTF/train_size\n",
    "#       val_loss = total_val_loss/val_size\n",
    "#       val_acc = val_TPTF/val_size\n",
    "\n",
    "\n",
    "#       print('Epoch {}'.format(epoch+1))\n",
    "#       print('Train Loss: {:.6f}, Train ACC: {:.6f}, Val loss = {:.6f}, Val ACC: {:.6f}'.\n",
    "#             format(train_loss, train_acc, val_loss, val_acc))\n",
    "    \n",
    "#     # 4. store the performance of the model at the last epoch\n",
    "#     df_performance.loc[i_CV] = [i_CV, train_loss, train_acc, val_loss, val_acc]\n",
    "\n",
    "#   outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput/{}/{}/'.format(dataset_name, sensor_loc)\n",
    "#   if not os.path.exists(outputdir):\n",
    "#       os.makedirs(outputdir)\n",
    "#   print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "#   # 5. export model performance as df\n",
    "#   export_perofmance(df_performance, CV_n, outputdir)\n",
    "\n",
    "#   # 6. export notebook parameters as dict\n",
    "#   # datetime object containing current date and time\n",
    "#   now = datetime.now()\n",
    "#   dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "#   samples_n = train_size + val_size\n",
    "\n",
    "#   param_dict = {\n",
    "#       'CV_n': CV_n,\n",
    "#       'samples_n': samples_n,\n",
    "#       'classes_n': classes_n,\n",
    "#       'model_name': model.__class__.__name__,\n",
    "#       'dataset_name': dataset_name,\n",
    "#       'sensor_loc': sensor_loc,\n",
    "#       'date': dt_string,\n",
    "#       'batch_size': batch_size,\n",
    "#       'input_dim': (batch_size, train_dataset.data.size()[1], train_dataset.data.size()[2]),\n",
    "#       'output_dim': train_dataset.labels[0:batch_size].data.numpy().shape,\n",
    "#       'label_dim': CV_n,\n",
    "#   }\n",
    "#   print(param_dict)\n",
    "\n",
    "#   with open(outputdir+'notebook_param.json', 'w') as fp:\n",
    "#     json.dump(param_dict, fp)\n",
    "\n",
    "#   export_model(model, classes_n, input_dim, device, outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me8Xckeynq79"
   },
   "outputs": [],
   "source": [
    "# datasets_sensor_dict = {\n",
    "#     'UMAFall': ['waist', 'wrist', 'leg', 'chest', 'ankle'],\n",
    "#     'UPFall': ['wrist', 'rightpocket', 'neck', 'belt', 'ankle']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuNFe4Q_oOyE"
   },
   "outputs": [],
   "source": [
    "# inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed/{}/{}/'.format(dataset_name, sensor_loc)\n",
    "# classes_n = 2\n",
    "# CV_n = 5\n",
    "\n",
    "# for key in datasets_sensor_dict.keys():\n",
    "#   dataset_name = key\n",
    "#   for sensor_loc in datasets_sensor_dict[dataset_name]:\n",
    "#     model_fitting(CV_n, classes_n, sensor_loc, dataset_name, inputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4I2Bn31oZ0l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PT0nxNaGqxim"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnK88jJ3kXd3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTuPZryA0XDr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BIaUPJ-0XBz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWcFYNkc1S12"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOn/a8GYIoFJV7tUKKo5tXT",
   "collapsed_sections": [
    "amhwi5lZJA5V"
   ],
   "name": "stage2_ArchDesignStudio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (FD_DAT)",
   "language": "python",
   "name": "fd_dat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
