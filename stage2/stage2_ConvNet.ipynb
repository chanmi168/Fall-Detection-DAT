{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nswy3ke-TUyA"
   },
   "source": [
    "# Import packages and get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20090,
     "status": "ok",
     "timestamp": 1583247660985,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "dR0gs1Ya0xmy",
    "outputId": "33b4bf6c-a87b-4871-d027-8ba7721b56d7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD6EM010PDWn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import display\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/中研院/repo/')\n",
    "\n",
    "from utilities import *\n",
    "from models import *\n",
    "from dataset_util import *\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwxN85X7YeSx"
   },
   "outputs": [],
   "source": [
    "# def data_saver(data, name, outputdir):\n",
    "#     \"\"\" usage: data_saver(df_merged_interp_alldicts, 'data', outputdir)\"\"\"\n",
    "#     outputdir_data = os.path.join(outputdir, name+'.npz')\n",
    "#     print('outputdir for {}:'.format(name), outputdir_data)\n",
    "#     np.savez(outputdir_data, data=data, allow_pickle=True)\n",
    "#     loaded_data = np.load(outputdir_data, allow_pickle=True)['data']\n",
    "# #     loaded_data = np.load(outputdir_data, allow_pickle=True)['data']\n",
    "#     print('Are {} save and loadded correctly? '.format(name), np.array_equal(loaded_data, data))\n",
    "#     print('')\n",
    "    \n",
    "# def data_loader(name, inputdir):\n",
    "#     \"\"\" usage: data = data_loader('data', outputdir)\"\"\"\n",
    "#     inputdir_data = os.path.join(inputdir, name+'.npz')\n",
    "#     data = np.load(inputdir_data, allow_pickle=True)['data']\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1e5p1K_-pVsH"
   },
   "outputs": [],
   "source": [
    "# class FallDataset(Dataset):\n",
    "#   def __init__(self, data, labels):\n",
    "#       self.data = torch.FloatTensor(data)\n",
    "#       self.labels = torch.FloatTensor(labels)\n",
    "#       # self.data = torch.LongTensor(data)\n",
    "#       # self.labels = torch.LongTensor(labels)\n",
    "\n",
    "#   def __getitem__(self, index):\n",
    "#       x = self.data[index,:,:]\n",
    "#       y = self.labels[index]\n",
    "#       return x, y\n",
    "\n",
    "#   def __len__(self):\n",
    "#       return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQXX-AwxpTuf"
   },
   "outputs": [],
   "source": [
    "# # Convolutional neural network (two convolutional layers)\n",
    "# class ConvNet2(nn.Module):\n",
    "#     def __init__(self, class_N=2, channel_n=16, input_dim=10, p=0.5):\n",
    "#         super(ConvNet2, self).__init__()\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv1d(3, channel_n, kernel_size=3, stride=1, padding=2),\n",
    "#             nn.BatchNorm1d(channel_n),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv1d(channel_n, channel_n, kernel_size=3, stride=1, padding=2),\n",
    "#             nn.BatchNorm1d(channel_n),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "#         # self.layer3 = nn.Sequential(\n",
    "#         #     nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=2),\n",
    "#         #     nn.BatchNorm1d(64),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        \n",
    "#         cnn_layer1_dim = (input_dim+2*2-1*(3-1)-1)+1\n",
    "#         pool_layer1_dim = (cnn_layer1_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#         # cnn_layer2_dim = (pool_layer1_dim+2*2-1*(3-1)-1)+1\n",
    "#         # pool_layer2_dim = (cnn_layer2_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#         # cnn_layer3_dim = (pool_layer2_dim+2*2-1*(3-1)-1)+1\n",
    "#         # pool_layer3_dim = (cnn_layer3_dim-1*(2-1)-1)/2+1\n",
    "\n",
    "#         # print('cnn_layer1_dim:', cnn_layer1_dim)\n",
    "#         # print('pool_layer1_dim:', pool_layer1_dim)\n",
    "#         # print('cnn_layer2_dim:', cnn_layer2_dim)\n",
    "#         # print('pool_layer2_dim:', pool_layer2_dim)\n",
    "#         # print('cnn_layer3_dim:', cnn_layer3_dim)\n",
    "#         # print('pool_layer3_dim:', pool_layer3_dim)\n",
    "#         # fc_dim = int(((((input_dim)+2*2-1)/2+2*2-1)/2+2*2-1)/2*64)\n",
    "#         self.fc1 = nn.Linear(int(pool_layer1_dim)*channel_n, 50)\n",
    "#         self.drop_out = nn.Dropout(p=0)\n",
    "#         self.fc2 = nn.Linear(50, class_N)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#       out1 = self.layer1(x.float())\n",
    "#       # print('out1 size:', out1.size())\n",
    "#       # out2 = self.layer2(out1)\n",
    "#       # print('out2 size:', out2.size())\n",
    "#       # out3 = self.layer3(out2)\n",
    "#       # print('out3 size:', out3.size())\n",
    "#       # print('out2 size:', out2.size())\n",
    "#       out1 = out1.reshape(out1.size(0), -1)\n",
    "#       # print('out2 size:', out2.size())\n",
    "#       out1 = self.drop_out(out1)\n",
    "#       out2 = self.fc1(out1)\n",
    "#       out3 = self.fc2(out2)\n",
    "#       # print('x, out1, out2, out 3, out4 size',  x.size(), out1.size(), out2.size(), out3.size(), out4.size())\n",
    "#       return out1, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLJNv0EXEfH-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1583248012649,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "QuLbnqA6Xwgm",
    "outputId": "678fe61c-2584-4922-81ba-a3afe0990bd6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('show GPU device name:', torch.cuda.get_device_name(0))\n",
    "# model_1 = ConvNet2(class_N=2, channel_n=4, input_dim=66, p=0.5).to(device).float()\n",
    "dann = DannModel(device, class_N=2, domain_N=2, channel_n=5, input_dim=66).to(device).float()\n",
    "test_input = torch.randn((8, 3, 66), dtype=torch.double).to(device)\n",
    "feature_out, class_output, domain_output = dann(test_input)\n",
    "print(dann)\n",
    "print('show feature_out, class_output, domain_output size:', feature_out.size(), class_output.size(), domain_output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqlC22yVW6hp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5zQmLdUGkBw"
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, train_size, device, model, criterion, optimizer, epoch):\n",
    "  total_train_loss = 0\n",
    "  train_TPTF = 0\n",
    "  debug = False\n",
    "  for i, (data, labels) in enumerate(train_loader):\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device).long()\n",
    "\n",
    "    # Forward pass\n",
    "    # feature_out, class_out = model(data)\n",
    "    feature_out, class_out, _ = model(data)\n",
    "\n",
    "    train_loss = criterion(class_out, labels)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # total_train_loss += train_loss.data.numpy()\n",
    "    total_train_loss += train_loss.data.detach().cpu().numpy()\n",
    "    out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "    train_pred = np.argmax(out_sigmoid, 1)\n",
    "    train_TPTF += (train_pred==labels.data.detach().cpu().numpy()).sum()\n",
    "\n",
    "    #######################\n",
    "    if debug:\n",
    "      print('Epoch [{}/{}] Step [{}/{}]:'\n",
    "            'train_loss={:.5f} train_acc={:.5f}'\n",
    "            .format(epoch + 1,\n",
    "                    20,\n",
    "                    i + 1,\n",
    "                    len(train_loader),\n",
    "                    train_loss,\n",
    "                    (train_pred==labels.data.detach().cpu().numpy()).sum()))\n",
    "    #######################\n",
    "                \n",
    "  train_loss = total_train_loss/train_size\n",
    "  train_acc = train_TPTF/train_size\n",
    "\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def val_epoch(val_loader, val_size, device, model, criterion, optimizer, epoch):\n",
    "  total_val_loss = 0\n",
    "  val_TPTF = 0\n",
    "  debug = False\n",
    "  \n",
    "  for i, (data, labels) in enumerate(val_loader):\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device).long()\n",
    "    \n",
    "    #Forward pass\n",
    "    # feature_out, class_out = model(data)\n",
    "    feature_out, class_out, _ = model(data)\n",
    "    val_loss = criterion(class_out, labels)\n",
    "    \n",
    "    total_val_loss += val_loss.data.detach().cpu().numpy()\n",
    "    out_sigmoid = torch.sigmoid(class_out).data.detach().cpu().numpy()\n",
    "    val_pred = np.argmax(out_sigmoid, 1)\n",
    "    val_TPTF += (val_pred==labels.data.detach().cpu().numpy()).sum()\n",
    "\n",
    "    #######################\n",
    "    if debug:\n",
    "      print('Epoch [{}/{}] Step [{}/{}]:'\n",
    "            'val_loss={:.5f} val_acc={:.5f}'\n",
    "            .format(epoch + 1,\n",
    "                    20,\n",
    "                    i + 1,\n",
    "                    len(val_loader),\n",
    "                    val_loss,\n",
    "                    (val_pred==labels.data.detach().cpu().numpy()).sum()))\n",
    "    #######################\n",
    "\n",
    "  val_loss = total_val_loss/val_size\n",
    "  val_acc = val_TPTF/val_size\n",
    "\n",
    "  return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3-u-rG8Gj_d"
   },
   "outputs": [],
   "source": [
    "def ConvNet2Model_fitting(training_params, src_name, tgt_name, inputdir, outputdir): \n",
    "  show_train_log = False\n",
    "\n",
    "  if not os.path.exists(outputdir):\n",
    "      os.makedirs(outputdir)\n",
    "      \n",
    "  classes_n = training_params['classes_n']\n",
    "  CV_n = training_params['CV_n']\n",
    "  num_epochs = training_params['num_epochs']\n",
    "  channel_n = training_params['channel_n']\n",
    "  batch_size = training_params['batch_size']\n",
    "  learning_rate = training_params['learning_rate']\n",
    "  dropout_p = training_params['dropout_p']\n",
    "\n",
    "  df_performance = pd.DataFrame(columns=['i_CV',\n",
    "                                          'train_loss','train_acc','val_loss','val_acc', 'tgt_val_loss', 'tgt_val_acc'])\n",
    "\n",
    "  src_dataset_name = src_name.split('_')[0]\n",
    "  src_sensor_loc = src_name.split('_')[1]\n",
    "\n",
    "  tgt_dataset_name = tgt_name.split('_')[0]\n",
    "  tgt_sensor_loc = tgt_name.split('_')[1]\n",
    "\n",
    "  src_inputdir = inputdir + '{}/{}/'.format(src_dataset_name, src_sensor_loc)\n",
    "  tgt_inputdir = inputdir + '{}/{}/'.format(tgt_dataset_name, tgt_sensor_loc)\n",
    "\n",
    "\n",
    "  for i_CV in range(CV_n):\n",
    "    # 1. prepare dataset\n",
    "    src_train_loader, src_val_loader = get_UMAFall_loader(src_inputdir, i_CV, batch_size, learning_rate)\n",
    "    tgt_train_loader, tgt_val_loader = get_UPFall_loader(tgt_inputdir, i_CV, batch_size, learning_rate)\n",
    "\n",
    "    # the model expect the same input dimension for src and tgt data\n",
    "    src_train_size = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "    src_val_size = src_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "\n",
    "    tgt_train_size = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "    tgt_val_size = tgt_val_loader.dataset.data.data.detach().cpu().numpy().shape[0]\n",
    "\n",
    "    src_input_dim = src_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n",
    "    tgt_input_dim = tgt_train_loader.dataset.data.data.detach().cpu().numpy().shape[2]\n",
    "\n",
    "    # 2. prepare model\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # loss and optimizer\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    class_criterion = nn.CrossEntropyLoss()\n",
    "    # domain_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    # 3. fit the model\n",
    "    total_step = len(src_train_loader)\n",
    "\n",
    "    train_loss_avg_epochs = np.zeros(num_epochs)\n",
    "    train_class_acc_epochs = np.zeros(num_epochs)\n",
    "    val_src_loss_avg_epochs = np.zeros(num_epochs)\n",
    "    val_src_class_acc_epochs = np.zeros(num_epochs)\n",
    "    val_tgt_loss_avg_epochs = np.zeros(num_epochs)\n",
    "    val_tgt_class_acc_epochs = np.zeros(num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "      # if training_mode == 'source':\n",
    "      # model = BaselineModel(device, class_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "      # model = ConvNet2(class_N=2, channel_n=16, input_dim=66, p=dropout_p).to(device).float()\n",
    "      model = DannModel(device, class_N=2, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "      model_name = model.__class__.__name__\n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "      # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "      train_loss, train_acc = train_epoch(src_train_loader, src_train_size, device, model, class_criterion, optimizer, epoch)\n",
    "      train_loss_avg_epochs[epoch] = train_loss\n",
    "      train_class_acc_epochs[epoch] = train_acc\n",
    "\n",
    "      val_loss, val_acc = val_epoch(src_val_loader, src_val_size, device, model, class_criterion, optimizer, epoch)\n",
    "      val_src_loss_avg_epochs[epoch] = val_loss\n",
    "      val_src_class_acc_epochs[epoch] = val_acc\n",
    "\n",
    "      tgt_val_loss, tgt_val_acc = val_epoch(tgt_val_loader, tgt_val_size, device, model, class_criterion, optimizer, epoch)\n",
    "      val_tgt_loss_avg_epochs[epoch] = tgt_val_loss\n",
    "      val_tgt_class_acc_epochs[epoch] = tgt_val_acc\n",
    "\n",
    "      if show_train_log:\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        print('Train Loss: {:.6f}, Train ACC: {:.6f}, Val loss = {:.6f}, Val ACC: {:.6f}'.\n",
    "              format(train_loss, train_acc, val_loss, val_acc))\n",
    "        print('Target Val loss = {:.6f}, Val ACC: {:.6f}'.format(tgt_val_loss, tgt_val_acc))\n",
    "\n",
    "      # 4. store the performance of the model at the last epoch\n",
    "      df_performance.loc[i_CV] = [i_CV, train_loss, train_acc, val_loss, val_acc, tgt_val_loss, tgt_val_acc]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 3), dpi=80)\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('loss_avg_epochs')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.plot(np.arange(num_epochs), train_loss_avg_epochs, color='blue', label='train')\n",
    "    ax1.plot(np.arange(num_epochs), val_src_loss_avg_epochs, color='red', label='val_src')\n",
    "    ax1.plot(np.arange(num_epochs), val_tgt_loss_avg_epochs, color='green', label='val_tgt')\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.set_title('class_acc_epochs')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.plot(np.arange(num_epochs), train_class_acc_epochs, color='blue', label='train')\n",
    "    ax2.plot(np.arange(num_epochs), val_src_class_acc_epochs, color='red', label='val_src')\n",
    "    ax2.plot(np.arange(num_epochs), val_tgt_class_acc_epochs, color='green', label='val_tgt')\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print('=================Exporting pytorch model=================')\n",
    "    # loaded_model = ConvNet2(class_N=2, channel_n=16, input_dim=66, p=dropout_p).to(device).float()\n",
    "    loaded_model = DannModel(device, class_N=2, domain_N=2, channel_n=channel_n, input_dim=src_input_dim).to(device).float()\n",
    "    export_model(model, loaded_model, outputdir+'model_CV{}'.format(i_CV))\n",
    "    print('=========================================================')\n",
    "\n",
    "  # 5. export model performance as df\n",
    "  print('===============Exporting model performance===============')\n",
    "  export_perofmance(df_performance, CV_n, outputdir)\n",
    "\n",
    "  print('src val loss: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_loss'], df_performance.loc['std']['val_loss']))\n",
    "  print('src val acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['val_acc'], df_performance.loc['std']['val_acc']))\n",
    "  \n",
    "  print('tgt val loss: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['tgt_val_loss'], df_performance.loc['std']['tgt_val_loss']))\n",
    "  print('tgt val acc: {:.4f}±{:.4f}'.format(df_performance.loc['mean']['tgt_val_acc'], df_performance.loc['std']['tgt_val_acc']))\n",
    "\n",
    "  print('=========================================================')\n",
    "\n",
    "  # 6. export notebook parameters as dict\n",
    "  # datetime object containing current date and time\n",
    "  print('==============Exporting notebook parameters==============')\n",
    "  now = datetime.now()\n",
    "  dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "  samples_n = src_train_size + src_val_size\n",
    "\n",
    "  param_dict = {\n",
    "      'CV_n': CV_n,\n",
    "      'samples_n': samples_n,\n",
    "      'classes_n': classes_n,\n",
    "      'model_name': model_name,\n",
    "      'dataset_name': src_dataset_name,\n",
    "      'sensor_loc': src_sensor_loc,\n",
    "      'date': dt_string,\n",
    "      'batch_size': batch_size,\n",
    "      'input_dim': (batch_size, src_train_loader.dataset.data.size()[1], src_train_loader.dataset.data.size()[2]),\n",
    "      'output_dim': src_train_loader.dataset.labels[0:batch_size].data.detach().cpu().numpy().shape,\n",
    "      'label_dim': CV_n,\n",
    "  }\n",
    "  print(param_dict)\n",
    "\n",
    "  with open(outputdir+'notebook_param.json', 'w') as fp:\n",
    "    json.dump(param_dict, fp)\n",
    "  print('=========================================================')\n",
    "\n",
    "  return (df_performance.loc['mean']['val_acc'], df_performance.loc['std']['val_acc']), (df_performance.loc['mean']['tgt_val_acc'], df_performance.loc['std']['tgt_val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gfQua3gGj83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164705,
     "status": "ok",
     "timestamp": 1583248657930,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "wwNPLlA8HoWr",
    "outputId": "0826b8a8-c3e1-4f1b-ce03-71221706a186"
   },
   "outputs": [],
   "source": [
    "# tasks_list = [('UMAFall_wrist', 'UPFall_wrist')]\n",
    "tasks_list = [('UMAFall_waist', 'UPFall_belt')]\n",
    "\n",
    "# optimal_training_params = {\n",
    "#     'classes_n': 2,\n",
    "#     'CV_n': 5,\n",
    "#     'num_epochs': 3,\n",
    "#     'channel_n': 32,\n",
    "#     'batch_size': 1,\n",
    "#     'learning_rate': 0.01}\n",
    "\n",
    "training_params = {\n",
    "    'classes_n': 2,\n",
    "    'CV_n': 5,\n",
    "    'num_epochs': 20,\n",
    "    'channel_n': 2,\n",
    "    'batch_size': 1,\n",
    "    'learning_rate': 0.01,\n",
    "    'dropout_p': 0.2}\n",
    "\n",
    "for task_item in tasks_list:\n",
    "  (src_name, tgt_name) = task_item\n",
    "\n",
    "  inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed_18hz/'\n",
    "  outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_archdesign_18hz/{}_{}/'.format(src_name, tgt_name)\n",
    "  if not os.path.exists(outputdir):\n",
    "      os.makedirs(outputdir)\n",
    "  print('outputdir for stage2 output:', outputdir)\n",
    "  \n",
    "  source_outputs = ConvNet2Model_fitting(training_params, src_name, tgt_name, inputdir, outputdir+'source/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 183981,
     "status": "ok",
     "timestamp": 1582972391136,
     "user": {
      "displayName": "MICHAEL CHAN",
      "photoUrl": "",
      "userId": "10621351606155040584"
     },
     "user_tz": -480
    },
    "id": "3FUoXUwbHoS4",
    "outputId": "e95bebfd-9317-407c-8fd9-c64fd337d54c"
   },
   "outputs": [],
   "source": [
    "source_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A66bXfcDHoP8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mfs_IpRkHoLm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRx6_kUvHoIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDVBXu0i4ZNB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2Z4tKb2_0Nq"
   },
   "source": [
    "# Start CV training and validation in a big phat loop (to be deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZlGwYngxAhw"
   },
   "outputs": [],
   "source": [
    "# def model_fitting(CV_n, classes_n, sensor_loc, dataset_name, inputdir): \n",
    "#   # it's big phat loop i don't like it qq\n",
    "#   df_performance = pd.DataFrame(columns=['i_CV','train_loss','train_acc','val_loss','val_acc'])\n",
    "\n",
    "#   for i_CV in range(CV_n):\n",
    "#     # 1. prepare dataset\n",
    "#     train_inputdir = inputdir+'/CV{}/train'.format(i_CV)\n",
    "#     val_inputdir = inputdir+'/CV{}/val'.format(i_CV)\n",
    "\n",
    "#     train_data = data_loader('data', train_inputdir).transpose(2,1,0)\n",
    "#     val_data = data_loader('data', val_inputdir).transpose(2,1,0)\n",
    "\n",
    "#     train_labels = data_loader('labels', train_inputdir)\n",
    "#     val_labels = data_loader('labels', val_inputdir)\n",
    "\n",
    "#     train_i_sub = data_loader('i_sub', train_inputdir)\n",
    "#     val_i_sub = data_loader('i_sub', val_inputdir)\n",
    "\n",
    "#     print('train_data shape:', train_data.shape)\n",
    "#     print('val_data shape:', val_data.shape)\n",
    "\n",
    "#     train_size = train_labels.shape[0]\n",
    "#     val_size = val_labels.shape[0]\n",
    "#     input_dim = train_data.shape[2]\n",
    "\n",
    "#     # convert labels from multi-class activities to binary (fall/ADL)\n",
    "#     train_labels_binary = ((train_labels==10)|(train_labels==11)|(train_labels==12)).astype(int)\n",
    "#     val_labels_binary = ((val_labels==10)|(val_labels==11)|(val_labels==12)).astype(int)\n",
    "\n",
    "#     train_dataset = FallDataset(train_data, train_labels_binary)\n",
    "#     val_dataset = FallDataset(val_data, val_labels_binary)\n",
    "#     # data loader\n",
    "#     batch_size = 4\n",
    "#     learning_rate = 0.001\n",
    "\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "#                                               batch_size=batch_size, \n",
    "#                                               shuffle=True)\n",
    "\n",
    "#     val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "#                                               batch_size=batch_size, \n",
    "#                                               shuffle=False)\n",
    "\n",
    "#     # 2. prepare model\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#     model = ConvNet(num_classes=classes_n, input_dim=input_dim).to(device).float()\n",
    "\n",
    "#     # loss and optimizer\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # test model on a batch\n",
    "#     try:\n",
    "#       out = model(train_dataset.data[0:batch_size,:,:])\n",
    "#       model_outdim = out.data.numpy().shape\n",
    "#     except:\n",
    "#       print('Warning: model cannot read input')\n",
    "\n",
    "#     print('{} model architecture: '.format(model.__class__.__name__))\n",
    "#     print(model)\n",
    "\n",
    "\n",
    "#     # 3. fit the model\n",
    "#     num_epochs = 10\n",
    "#     total_step = len(train_loader)\n",
    "#     for epoch in range(num_epochs):\n",
    "#       total_train_loss = 0\n",
    "#       train_TPTF = 0\n",
    "#       for i, (data, labels) in enumerate(train_loader):\n",
    "#         data = data.to(device)\n",
    "#         labels = labels.to(device).long()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(data)\n",
    "#         train_loss = criterion(outputs, labels)\n",
    "#         total_train_loss += train_loss.data.numpy()\n",
    "        \n",
    "#         out_sigmoid = torch.sigmoid(outputs).data.numpy()\n",
    "#         train_pred = np.argmax(out_sigmoid, 1)\n",
    "#         train_TPTF += (train_pred==labels.data.numpy()).sum()\n",
    "#         # train_pred = print(np.argmax(F.sigmoid(outputs))\n",
    "\n",
    "\n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # if (i+1) % 5 == 0:\n",
    "#         #     print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.8f}' \n",
    "#         #             .format(epoch+1, num_epochs, i+1, total_step, train_loss.data.numpy()/labels.size()[0]))\n",
    "\n",
    "#       total_val_loss = 0\n",
    "#       val_TPTF = 0\n",
    "#       for i, (data, labels) in enumerate(val_loader):\n",
    "#         data = data.to(device)\n",
    "#         labels = labels.to(device).long()\n",
    "        \n",
    "#         #Forward pass\n",
    "#         val_outputs = model(data)\n",
    "#         val_loss = criterion(val_outputs, labels)\n",
    "#         total_val_loss += val_loss.data.numpy()\n",
    "\n",
    "#         out_sigmoid = torch.sigmoid(val_outputs).data.numpy()\n",
    "#         val_pred = np.argmax(out_sigmoid, 1)\n",
    "#         val_TPTF += (val_pred==labels.data.numpy()).sum()\n",
    "#         # print(val_TPTF, len(val_loader))\n",
    "          \n",
    "#       train_loss = total_train_loss/train_size\n",
    "#       train_acc = train_TPTF/train_size\n",
    "#       val_loss = total_val_loss/val_size\n",
    "#       val_acc = val_TPTF/val_size\n",
    "\n",
    "\n",
    "#       print('Epoch {}'.format(epoch+1))\n",
    "#       print('Train Loss: {:.6f}, Train ACC: {:.6f}, Val loss = {:.6f}, Val ACC: {:.6f}'.\n",
    "#             format(train_loss, train_acc, val_loss, val_acc))\n",
    "    \n",
    "#     # 4. store the performance of the model at the last epoch\n",
    "#     df_performance.loc[i_CV] = [i_CV, train_loss, train_acc, val_loss, val_acc]\n",
    "\n",
    "#   outputdir = '/content/drive/My Drive/中研院/data_mic/stage2_modeloutput/{}/{}/'.format(dataset_name, sensor_loc)\n",
    "#   if not os.path.exists(outputdir):\n",
    "#       os.makedirs(outputdir)\n",
    "#   print('outputdir for stage2 output:', outputdir)\n",
    "\n",
    "#   # 5. export model performance as df\n",
    "#   export_perofmance(df_performance, CV_n, outputdir)\n",
    "\n",
    "#   # 6. export notebook parameters as dict\n",
    "#   # datetime object containing current date and time\n",
    "#   now = datetime.now()\n",
    "#   dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "#   samples_n = train_size + val_size\n",
    "\n",
    "#   param_dict = {\n",
    "#       'CV_n': CV_n,\n",
    "#       'samples_n': samples_n,\n",
    "#       'classes_n': classes_n,\n",
    "#       'model_name': model.__class__.__name__,\n",
    "#       'dataset_name': dataset_name,\n",
    "#       'sensor_loc': sensor_loc,\n",
    "#       'date': dt_string,\n",
    "#       'batch_size': batch_size,\n",
    "#       'input_dim': (batch_size, train_dataset.data.size()[1], train_dataset.data.size()[2]),\n",
    "#       'output_dim': train_dataset.labels[0:batch_size].data.numpy().shape,\n",
    "#       'label_dim': CV_n,\n",
    "#   }\n",
    "#   print(param_dict)\n",
    "\n",
    "#   with open(outputdir+'notebook_param.json', 'w') as fp:\n",
    "#     json.dump(param_dict, fp)\n",
    "\n",
    "#   export_model(model, classes_n, input_dim, device, outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me8Xckeynq79"
   },
   "outputs": [],
   "source": [
    "# datasets_sensor_dict = {\n",
    "#     'UMAFall': ['waist', 'wrist', 'leg', 'chest', 'ankle'],\n",
    "#     'UPFall': ['wrist', 'rightpocket', 'neck', 'belt', 'ankle']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuNFe4Q_oOyE"
   },
   "outputs": [],
   "source": [
    "# inputdir = '/content/drive/My Drive/中研院/data_mic/stage1_preprocessed/{}/{}/'.format(dataset_name, sensor_loc)\n",
    "# classes_n = 2\n",
    "# CV_n = 5\n",
    "\n",
    "# for key in datasets_sensor_dict.keys():\n",
    "#   dataset_name = key\n",
    "#   for sensor_loc in datasets_sensor_dict[dataset_name]:\n",
    "#     model_fitting(CV_n, classes_n, sensor_loc, dataset_name, inputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4I2Bn31oZ0l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PT0nxNaGqxim"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnK88jJ3kXd3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTuPZryA0XDr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BIaUPJ-0XBz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWcFYNkc1S12"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPqDHbzSv6PLaXhaOzAqgYj",
   "collapsed_sections": [],
   "name": "stage2_ConvNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
